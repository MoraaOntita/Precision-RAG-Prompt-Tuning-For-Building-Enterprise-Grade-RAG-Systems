{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Text from Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_docx(docx_folder):\n",
    "    documents = []\n",
    "    for docx_file in os.listdir(docx_folder):\n",
    "        if docx_file.endswith(\".docx\"):\n",
    "            docx_path = os.path.join(docx_folder, docx_file)\n",
    "            doc = Document(docx_path)\n",
    "            text = \"\"\n",
    "            for paragraph in doc.paragraphs:\n",
    "                text += paragraph.text + \"\\n\"\n",
    "            documents.append({\"file_name\": docx_file, \"text\": text})\n",
    "    return documents\n",
    "\n",
    "docx_folder = \"/home/moraa/Documents/10_academy/Week-7/data\"\n",
    "extracted_documents = extract_text_from_docx(docx_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: W4 - Utilizing AI to Enhance Social Media Management and Customer Engagement.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 4\n",
      "Careers - Exercise 2\n",
      "Utilizing AI to Enhance Social Media Management and Customer Engagement \n",
      "\n",
      "\n",
      "Deadline: Saturday, 18th May 2024, 8 pm UTC\n",
      "\n",
      "\n",
      "Scenario:\n",
      "\n",
      "You have been hired as a Social Media Associate for a prominent e-commerce company specializing in fast-moving beauty products for females. The company boasts an impressive online presence, particularly on Instagram, having 7 million followers, with hundreds of daily sales attributed to its social media marketing efforts.  The company has set up an Instagram Shop to allow easy checkout for products. Every day, the account gets hundreds of activities, including likes, comments on posts, reposts, tags, and inquiries on direct messages that require you to manage. \n",
      "\n",
      "As a 10 Academy trainee, who is knowledgeable in implementing AI models, you are tasked to propose and implement AI solutions to streamline customer engagement and improve the overall efficiency of the company's social media management and customer satisfaction. The company’s specific goals are for you to:\n",
      "\n",
      "Manage a high volume of comments and inquiries on Instagram.\n",
      "Increase sales for your company\n",
      "\n",
      "\n",
      "Deliverables and Tasks to be Done\n",
      "Tasks:\n",
      "You are required to present how you’ll tackle this task to your non-technical managers. Prepare a presentation that you’ll give entailing the following:\n",
      "\n",
      "A step-by-step procedure you will follow to implement an AI bot to efficiently respond to comments on each Instagram post and direct message(DMs). You can choose to create one of your own from scratch or use an existing one from the Facebook Developer Platform to train it. This should cover the following steps:\n",
      "Data collection for training(previous chat histories, company files, emails, etc)\n",
      "Annotation and labeling process, for example, label conversations based on topics, sentiments, etc.\n",
      "Train the bot, which ML models/architectures do you plan to use and why?\n",
      "How will you monitor and evaluate your bot? What metrics will you use and why? \n",
      "Inform the client on any costs that might be incurred while setting up/running.\n",
      "How would you get your bot to interact with instagram?\n",
      "\n",
      "Reflect on any ethical implications of using AI in this context, particularly regarding customer privacy and data security. Discuss 4 strategies to ensure transparency and maintain customer trust while leveraging these chatbots. \n",
      "Outline 4 key performance indicators (KPIs) to evaluate the success of implementing AI. \n",
      "Finally, reflect on the potential impact of chatbots on the future of social media management and e-commerce. Discuss 5  advantages and limitations of using AI in this context, and how it can shape the industry moving forward. \n",
      "\n",
      "\n",
      "\n",
      "Team\n",
      "Instructors:\n",
      "Margaret Chepkirui - Careers Tutor\n",
      "Pascaline Iyodusenga - Lead Tutor\n",
      "Arun Sharma - co-founder, 10 Academy\n",
      "\n",
      "Key Dates\n",
      "Tutorial session: Thursday, 16 May 2024. \n",
      "Submission deadline: Saturday, 18 May 2024, 8:00 pm UTC.\n",
      "\n",
      "\n",
      "Submission\n",
      "\n",
      "A report answering the questions in the tasks above. \n",
      "Save your PPT as a PDF before submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Usefulness in real life\n",
      "This exercise aims to develop your understanding of applying AI to enhance social media management and customer engagement. You will gain practical insights into the power of AI in improving efficiency and the customer experience.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Useful links\n",
      "\n",
      "A real-life company implementing this - https://go.schoolofbots.co/welcome\n",
      "Youtube Podcast on Instagram DM Automation Strategy - https://www.youtube.com/watch?v=tYF_4hZ6-bY\n",
      "ChatGPT Can Now Assist With Travel Planning in the Expedia App -Expedia product for travel.\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Effective communication - W3.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 3\n",
      "Careers - Exercise 1\n",
      "\n",
      "Effective Communication\n",
      "\n",
      "Due Date: Saturday, 11th May 2024, 8P\n",
      "M UTC\n",
      "Background\n",
      "You have just been hired to coordinate a team of 5 members that are currently working on the Alpha project because their team lead recently resigned. The team has been working on the project for 4 weeks and despite being composed of highly skilled professionals, they are significantly behind schedule. They have only two weeks remaining until the project deadline. On your second day of your employment, you realized that the team has some issues that have been negatively impacting their performance.\n",
      "The team began the work without a well-defined understanding of the project's goals and its strategic plan. This led to inefficiencies as team members engaged in tasks without a clear direction or understanding of the overall project objectives.\n",
      "\n",
      "Team members have not been assigned roles that best fit their skill sets, leading to inefficiencies and frustrations.\n",
      "\n",
      "Team members do not regularly communicate their progress, challenges, or needs and this leaves some team members isolated when they encounter difficulties.\n",
      "\n",
      "Although team members are individually capable, they tend to work alone and do not share insights. This isolation not only slows down individual tasks but also prevents the team from leveraging collective knowledge to overcome complex challenges.\n",
      "Furthermore, two of the team members happen to be chronic late comers. They resume work late and are always late to schedule meetings too. And this attitude has some drawbacks on the overall team.\n",
      "\n",
      "Task\n",
      "Describe four steps you would take to ensure that all team members understand the project goals and their individual responsibilities. \n",
      "\n",
      "What three ways would you ensure that each team member is assigned a role that fits their skills?\n",
      "\n",
      "Describe three strategies you would implement to improve communication among team members?\n",
      "\n",
      "Propose three methods to foster a collaborative attitude among team members.\n",
      "\n",
      "Using the framework for effective communication, outline how you would make your concern known to the two late-comers in the team.\n",
      "\n",
      "Submission\n",
      "Create a PowerPoint presentation with 7 slides that detail your answers to the tasks written above.\n",
      "\n",
      "Rubrics\n",
      "Understanding Project Goals and Responsibilities: You are required to write steps ensuring team members understand project goals and individual responsibilities. Grading will focus on the clarity and specificity of proposed steps.\n",
      "\n",
      "Optimize Team Member Role Alignment with Skills: You should propose methods to align team members' skills with appropriate roles. Grading will consider the identification of skill sets, strategies for assessing skills, and flexibility in role assignments.\n",
      "\n",
      "Improving Team Communication: You are asked to describe strategies to enhance communication within the team. Grading criteria include the effectiveness and variety of proposed strategies.\n",
      "\n",
      "Fostering Collaborative Attitudes within the Team: Grading will look on if you proposed methods to promote a collaborative attitude among team members. \n",
      "\n",
      "Addressing Late-Comers: You should outline how to address concerns with late-comers using effective communication. Grading criteria include application of communication framework, clarity and professionalism in addressing concerns.\n",
      "\n",
      "Usefulness in life\n",
      "This activity is designed to give you a practical understanding of how communication issues can impact the workplace. By working through this scenario, you'll develop your critical thinking and problem-solving skills as you focus on improving communication strategies. This will ultimately lead to better results in your professional life.\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Procrastination - W4.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 4\n",
      "Careers - Exercise 1\n",
      "\n",
      "Procrastination\n",
      "\n",
      "Due Date: May 18, 2024. 8:00 PM UTC\n",
      "\n",
      "Background\n",
      "\n",
      "What is procrastination?\n",
      "Procrastination is the act of unnecessarily postponing decisions or actions. For example, if someone delays working on an assignment until right before its deadline for no valid reason, even though they know that it would be better for them to start earlier, that person is procrastinating.\n",
      "\n",
      "Read more about procrastination in this introductory article written by Joseph Ferrari, Professor of Psychology at DePaul University. Find the article here.  \n",
      "\n",
      "\n",
      "Why people procrastinate.\n",
      "Tasks have always been associated with schedules and deadlines. And it is very evident that one of the most important resources of all time; time, cannot be carried over or transferred to the next day, week or month. Time spent is spent! There comes a point where you feel like postponing specific tasks. With a personal intention that you’ll sit on the tasks later. This act of delaying or postponing a task that you are entirely sure that its deadline or schedule is active, is what we refer to as procrastination. Read why people procrastinate here. \n",
      "\n",
      "Inside the Mind of a Procrastinator\n",
      " Watch this TED Talk presentation entitled, 'Inside the mind of a master procrastinator by Tim Urban. \n",
      "@Tim Urban: Inside the mind of a master procrastinator | TED\n",
      "\n",
      "The witty, visual, and relatable nature of this video will help you to see procrastination through the eyes of another individual’s experience. It adds humour to the concepts which make it easy to understand and to work with as we delve deeper into what procrastination means.\n",
      "\n",
      "Task:\n",
      "As Tim shared his story in that TED talk, write your own procrastination story while at 10 academy too. Make sure it is original and it captures the essence of your own experiences. Make it yours! \n",
      "[While sharing us your story, emphasise on the following;\n",
      "\n",
      "The name that specific task/challenge you procrastinated on. \n",
      "Highlight the particular elements procrastinated in that task/challenge. \n",
      "How you felt while working on it at the very last minute?\n",
      "Were the results positive or negative? \n",
      "\n",
      "In general, what are the underlying reasons or triggers for your procrastination? Provide a list of 4 reasons with their detailed explanation.\n",
      "\n",
      "In general, Reflect on the role of distractions in your procrastination. What 5 external factors or distractions often derail your focus and contribute to procrastination? \n",
      "\n",
      "In general, List 4 excuses or justification you use to rationalise your procrastination behaviour to yourself? Be honest about the thought patterns or beliefs that enable your procrastination habits.\n",
      "\n",
      "In general, Reflect on past instances of procrastination. Were there any negative consequences or missed opportunities? Explain them. \n",
      "\n",
      "Think about times when you successfully avoided procrastination. What strategies did you use? (List as many strategies as possible.) Explain them. \n",
      "\n",
      "\n",
      "Remember, the goal of this challenge is not just to complete the task, but to gain insights into your procrastination habits and develop strategies for improvement. Take this opportunity to learn more about yourself and how you can better manage your time and responsibilities i.e staying true to set deadlines.\n",
      "Submission\n",
      "Your responses should be on a maximum of 10 slides PPT. Convert it into PDF and submit the link on Tenx.\n",
      "\n",
      "Usefulness in life\n",
      "Understanding procrastination offers valuable insights into individual behaviour and habits, fostering self-awareness and personal growth while enabling effective time management strategies. Learning about procrastination empowers individuals to break tasks into manageable steps, utilise time-blocking techniques, and maintain focus on long-term goals, ultimately increasing their likelihood of success in both personal and professional endeavours.\n",
      "\n",
      "Rubrics\n",
      "1. Originality and Personalization of Procrastination Story: Grading will focus on the originality and personalization of the procrastination story, assessing how well the trainee captures their own experiences and conveys them effectively.\n",
      "\n",
      "2. Identification and Analysis of Distractions: Evaluation will assess the trainee's ability to identify and analyze external factors or distractions contributing to procrastination. Five distractions should be listed with explanations of how they derail focus and contribute to procrastination.\n",
      "\n",
      "3. Excuses or Justifications for Procrastination: Grading will consider the honesty and depth of reflection on the excuses or justifications used to rationalize procrastination behavior. Four excuses or justifications should be listed with explanations of the thought patterns or beliefs enabling procrastination habits.\n",
      "\n",
      "4. Reflection on Negative Consequences of Procrastination: Evaluation will assess the trainee's reflection on past instances of procrastination, focusing on whether there were negative consequences or missed opportunities. Explanations should be provided to illustrate the impact of procrastination.\n",
      "\n",
      "5. Strategies for Avoiding Procrastination: Grading criteria will include the effectiveness and variety of strategies listed for avoiding procrastination. The trainees should list as many strategies as possible and provide detailed explanations of how each strategy works and how it has been successfully applied in the past.\n",
      "\n",
      "6. Overall Reflection and Self-Analysis: An overall assessment of the trainee's reflection and self-analysis regarding their procrastination habits will be conducted. The depth of reflection, self-awareness, and insights gained will be considered in the grading process.\n",
      "\n",
      "\n",
      "\n",
      "File: Instruction and Usage - API Keys.docx\n",
      "Extracted Text:\n",
      "Instruction and Usage - API Keys\n",
      "Assigned API Keys: Each group is provided with a specific API Key. These keys are to be used exclusively by the assigned group.\n",
      "Responsibility and Usage: It is the responsibility of each group to use their API Key in a responsible manner, adhering to the usage guidelines and limits set forth.\n",
      "Confidentiality: Under no circumstances should these API Keys be shared on public platforms, including but not limited to GitHub, Slack, or any other online forums or social media sites.\n",
      "Group-Specific Usage: Each group must only use their assigned API Key. Using another group's key or sharing your key with another group is strictly prohibited.\n",
      "Security: Always keep your API Key confidential. Do not include it in publicly accessible areas such as GitHub repositories, client-side code, and so forth.\n",
      "Compliance: Non-compliance with these instructions may result in the revocation of your API Key and possible further actions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For Individuals with  invalid OpenAI Key Only\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: W0 - Careers Exercise - Ideas to change the world-day4.docx\n",
      "Extracted Text:\n",
      "\n",
      "Challenge\n",
      "In your application, there was a question that said: \"tell us how you will use Generative AI to impact 5M young people in Africa in the coming 5 years. Be specific and describe how you will measure the impact of your idea, what role technology will play and where technology will play a role.”  \n",
      "\n",
      "Extend the answer you provided to that question into a Storyboard or PPT presentation form of 6 slides maximum which would be suitable for sharing with others at 10 Academy to encourage them to join you to start implementing this project.\n",
      "\n",
      "\n",
      "Make sure that your presentation answers the following questions:\n",
      "State the problem that you are addressing, why you chose that problem among many others and as well as the field/industry/sector it is in. \n",
      "Your answer should clearly explain the problem you are solving and why you have chosen to solve this problem. Illustrate, using at least 1 data source, the scale of the problem - this problem should affect at least 5 million people globally. Mention if this issue is occurring only in your country/region? If yes, identify why it is only occurring in your country/region. If no, identify the other areas in the world where it is also occurring. When you answer, ask yourself, can this problem be solved by Gen AI solutions? \n",
      "\n",
      "How would you solve this problem? What approach would you use and why? Is your proposed solution realistic in your country/region’s current economic state? Can your proposed solution be realistically implemented using Gen AI technology that already exists? \n",
      "\n",
      "What role will technology play in your proposed solution to this problem? Will this technology be sustainable, affordable, and will it be applicable to all regions/countries where this problem is occurring? Compare your proposed solution to current technology being used to combat this problem. \n",
      "\n",
      "Find past solutions to this problem and illustrate how your solution has improved on the original/previous.  Include this in your max 6 slides.\n",
      "\n",
      "If you do not receive funding from your government, identify three funding sources who you can realistically approach to fund your solution to this problem.  Include this in your max 6 slides. \n",
      "\n",
      "For this assignment, feel free to use both images and words to communicate and complete this exercise. \n",
      "\n",
      "While this exercise will challenge you to be creative about your presentation, it is important that the content you submit remain within the following parameters: \n",
      "Use bullet points, short sentences, and remember to use keywords.\n",
      "Make sure your presentation is easy to read- do not use too many different colours, or too many different fonts.\n",
      "Proofread your content before submission.. \n",
      "There are only five main points that you need to address, so do not add any irrelevant information to this presentation. \n",
      "Make sure you have a cover page, with your name.\n",
      "Each slide should be titled, to indicate which point you are addressing.\n",
      "You can use images in this presentation, but make sure everything in the presentation is relevant to the content you are delivering.   \n",
      "\n",
      "Here is a guiding template to help you organise your presentation- link\n",
      "Brainstorming and implementation of ideas slides -link \n",
      "\n",
      "Support, meeting, and tutorials:\n",
      "Links have been provided, directing you to resources that you can use to create storyboards and PPT presentations.\n",
      "Design thinking- storyboarding\n",
      "Canva- storyboarding\n",
      "PPT presentation- basics\n",
      "Creating a good ppt presentation\n",
      "Hubspot marketing- powerpoint presentation\n",
      "50 Powerpoint ideas\n",
      "How to achieve flow during a presentation. \n",
      "How to create a storyboard using Powerpoint. \n",
      "How to storyboard: Our 4 step guide to the storyboarding process. \n",
      "How to turn your essay into a Powerpoint. \n",
      "\n",
      "A tutorial session is planned on Thursday (11th April 2024)  to discuss this further and to answer any questions. Contact Margaret or Pascaline on Slack if you have any questions or concerns. \n",
      "The first hand-in will result in feedback from your tutors, when your assignments will be handed back to you. \n",
      "You are expected to listen to the feedback, and edit your assignments in an adequate response to the feedback you receive. \n",
      "Your final mark will be based on both your assignment and how you received and responded to feedback. \n",
      "\n",
      "Marking Rubric\n",
      "\n",
      "Slide structure - titles, references, slide, layout, font cohesion, wordiness  - 10%\n",
      "Quality of writing - use of English, comprehension , grammar, punctuation, tone and delivery, error free - 40 %\n",
      "Problem analysis - Has the individual analysed the problem well? Do they have a clear understanding of the problem? Is their analysis convincing? Is it logical? To what extent has the idea been thought-through?- 30%\n",
      "Overall Presentation- Does the assignment adhere to the guidelines of the exercise? Are the sentences short, and did the individual use bullet points? Has the assignment been proofread? Is it presentable ? - 20%\n",
      "\n",
      "\n",
      "Note - Individual feedback will be given. \n",
      "Usefulness in real life\n",
      "This exercise is designed to help you identify and recognize challenges that require modern day solutions. To help you develop realistic solutions to problems, and help you articulate and plan your solutions. Also to improve your writing skills, and challenge you to think critically about global issues and how they impact you. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: Reverse Engineered Brief for Existing Telegram Ads.docx\n",
      "Extracted Text:\n",
      "Reverse Engineered Brief for Existing Telegram Ads  \n",
      "\n",
      "\n",
      "DMC Real State\n",
      "Ad Copy (Content)\n",
      "Tag line - “ ቤት በ300,000 ብር ”\n",
      "Post Content - \n",
      "“ ታላቅ ቅናሽ ከዲ ኤም ሲ (DMC) ሪል እስቴት 5% ከፈለው ይመዝገቡ የሚፈልጉትን ቤት ይምረጡ \n",
      "ከ ስቲድዮ እስከ ባለ 4 መኝታ ቤቶች በተለያየ የካሬ ኣማራጭ ዘመናዊ አፓርትመንቶችን በመሸጥ ላይ ነን። \n",
      "👉Studio 56.6 ካሬ\n",
      "👉ባለ 1መኝታ 77.3ካሬ\n",
      "👉ባለ 2 መኝታ 123ካሬ\n",
      "👉ባለ 2 መኝታ 132.48ካሬ\n",
      "👉ባለ 3 መኝታ 146ካሬ - ባለ 4 መኝታ 186 ካሬ ድረስ በኣማራጭ!\n",
      "ሱቆችን ከ28 ካሬ እስከ 920ካሬ ከግራውንድ እስከ 4ተኛ \n",
      "☎️በ+251908886615 ይደዉሉ\n",
      "🚰 የከርሰ ምድር ውሃ\n",
      "👮የ24 ሰዓት የካሜራ ጥበቃ\n",
      "🎢 ሰፊ የመጫወቻ ስፍራ\n",
      "🚟 የስልክና የኢንተርኔት መስመር የተዘረጋለት\n",
      "🛗 4 ዘመናዊ አሳንሰሮች የተገጠሙለት\n",
      "🔌 🚘የኤሌክትሪክ መኪኖች ቻርጅ ማድረጊያ ቦታ የተዘጋጀለት\n",
      "⚡️ጀነሬተር ያለው\n",
      "♦️ከበቂ የመኪና ማቆሚያ ስፍራ ጋር\n",
      "💆ጂም:የውበት ሳሎን እና ሬስቶራንቶችን የያዘ\n",
      "👨‍👧‍👦 ለመኖሪያ ምቹ በሆነ አካባቢ የተገነባ እና በአቅራቢያው አስፈላጊ አቅርቦቶችን የሚያገኙበት\n",
      "👷 በዘመናዊ Aluminum Formwork Construction የግንባታ ጥበብ የሚገነባ\n",
      "ለበለጠ መረጃ \n",
      "☎️በ+251908886615 ይደዉሉ\n",
      " @dmcrealestateplc ”\n",
      "\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "DMC ሪል ስቴት ታላቅ ቅናሽ\n",
      "Background.\n",
      "የሪልስቴት ግንባታ እና ሽያጭ\n",
      "Objective\n",
      "ታላቅ ቅናሹን በመጠቀም የቤቶችን ሽያጭ ማሳደግ\n",
      "Target Audience\n",
      "በአነስተኛ ወጪ ቤት መግዛት የሚፈልግ ቤተሰቦች\n",
      "Promise\n",
      "የተሻለ አኗኗር ከተለያዩ አገልግሎቶች ጋር\n",
      "Support for your promise\n",
      "የከርሰ ምድር ውሃ\n",
      "የ24 ሰዓት የካሜራ ጥበቃ\n",
      "ሰፊ የመጫወቻ ስፍራ\n",
      " የስልክና የኢንተርኔት መስመር የተዘረጋለት\n",
      "ጂም:የውበት ሳሎን እና ሬስቶራንቶችን የያዘ\n",
      "Key message\n",
      "ከ DMC ቤት እንዲገዙ ማድረግ\n",
      "\n",
      "\n",
      "\n",
      "Safaricom M-pesa\n",
      "      Ad Content: \n",
      "Tag line - “ ተረክ በ M-pesa ” ፣\n",
      "“ ከ1 ሚሊዮን በላይ ተሸላሚዎች ”\n",
      "“ እንመዝገብ፣ እንገበያይ፣ እነሸለም ”\n",
      "Content - \n",
      "“ M-PESAን በማውረድ ፤ አዳዲስ መኪኖች፣ ባጃጆችን፣ እንዲሁም ሌሎችም ብዙ ሽልማቶችን የማሸነፍ ዕድል እናግኝ። \n",
      "እንዴት እናሸንፋለን? \n",
      "• M-PESA ላይ በመመዝገብ\n",
      "• ገንዘብ ወጪ እና ገቢ በማድረግ\n",
      "• የአየር ሰዓት እና ጥቅሎችን በመግዛት\n",
      "• ለነጋዴዎች እና ለቢዝነሶች በM-PESA በመክፈል\n",
      "• ገንዘብ በመላክ \n",
      "• ገንዘብ ከባንክ ወደ M-PESA እና ከ M-PESA ወደ ባንክ በማስተላለፍ \n",
      "• ከውጭ ሀገር በM-PESA ገንዘብ በመቀበል\n",
      "M-PESA ላይ እንመዝገብ፣ በM-PESA እንገበያይ፣ ቀጣይ እድለኛ አሸናፊዎች እንሁን።\n",
      "🔗 የM-PESA ሳፋሪኮምን መተግበሪያ በዚህ ሊንክ ያውርዱ: https://bit.ly/M-PESA_SafaricomEthiopia \n",
      "\n",
      "#MPESASafaricom #TerekBeMPESA\n",
      "#FurtherAheadTogether ”\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "ለM-pesa መተግበሪያ በመመዝገብ መሸለም\n",
      "Background\n",
      "የቴሌኮም እና የከፍያ ሲስተም \n",
      "Objective\n",
      "በሽልማት በማበረታታት ለm-pesa የሚመዘገቡ ሰዎችን መጨመር\n",
      "Target Audience\n",
      "ስማርት ስልክ ያላቸውና ገንዘብ የሚያንከሳቅሱ ሰዎች\n",
      "Promise\n",
      "ከተመዘገቡ ሽለማት ያገኛሉ፣ ፈጣን እና አስተማማኝ የገንዘብ ማዘዋወሪያ መተግበሪያ ያገኛሉ\n",
      "Key message\n",
      "ሰዎች ለ m-pesa እንዲመዘገቡ ማድረግ\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cash Go\n",
      "\t\n",
      "\tAd Content: \n",
      "\n",
      "Tag line - “ በሞባይል ስልክዎ ከውጪ ሃገር በነጻ ገንዘብ ይላኩ! ”\n",
      "Content - \n",
      "“ CashGo (ካሽ ጎ) \n",
      "ከውጭ ሀገራት ገንዘብ መላኪያ የሞባይል መተግበሪያ\n",
      "===========================\n",
      "በሞባይል ስልክዎ አማካኝነት ቪዛና ማስተር ካርድዎን በመጠቀም \n",
      "• ከውጭ ሀገር በቀጥታ ወደ ወዳጅ ዘመድዎ የኢትዮጵያ ንግድ ባንክ ሂሳብ ወይም ወደ ሲቢኢ ብር ሂሳብ መላክ ይችላሉ፣ አሊያም\n",
      "• ተቀባዩ ከ1900 በላይ በሚሆኑት የባንካችን ቅርንጫፎች መቀበል ይችላሉ!\n",
      "የCashGo ሞባይል መተግበሪያን ከ Play Store ወይም App Store በማውረድ ይጠቀሙ። \n",
      "• ለአንድሮይድ ስልኮች \n",
      "https://play.google.com/store/apps/details?id=com.bankofabyssinia.cashgo&hl=en&gl=US\n",
      "• ለአፕል ስልኮች \n",
      "https://apps.apple.com/us/app/cashgo/id1559346306 ”\n",
      "\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "በካሽ ጎ መተግበሪያ ገንዘብ መላክ\n",
      "Background\n",
      "የኦን ላይን ክፈያ\n",
      "Objective\n",
      "የካሽ ጎን መተግበሪያ ማወረድ እና ገንዘብ መላክ\n",
      "Target Audience\n",
      "ውጪ ሃገር ዘመድ ያላችው ሰዎች\n",
      "Promise\n",
      "ገነዘብ ከውጪ ሃገር በፍጥነት እና በአስተማማኝ ሁኔታ መላች\n",
      "Support for your promise\n",
      "ቪዛ እና ማስተር ካርድ በመጠቀም መስራቱ\n",
      "ከ1900 በላይ ቅርንጫፎች ገነዘብ መውሰድ መቻሉ \n",
      "Key message\n",
      "መተግበሪያውን ማወረድ፣ ገንዘብ ከውጪ መላክ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Global Bank\n",
      "\n",
      "Ad Content: \n",
      "\n",
      "Tag line - ለጋራ ስኬታችን \n",
      "Content:\n",
      "“ ወደ ሚቀርብዎ የግሎባል ባንክ ኢትዮጵያ ቅርንጫፎች ጎራ ብለው የቁጠባ ሒሳብ በመክፈት የአገልግሎቶቻችን ተጠቃሚ ይሁኑ፡፡\n",
      "በሚቀርብዎ አማራጮች ያግኙን፡ https://bit.ly/3TkrrXD\n",
      "ግሎባል ባንክ ኢትዮጵያ  \n",
      "ለጋራ ስኬታችን!\n",
      "#GlobalBankEthiopia #OurSharedSuccess #BankInEthiopia #Bank #GBE ”\n",
      "\t\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "ግሎባል ባንክ\n",
      "Background\n",
      "የባንክ አገልግሎት\n",
      "Objective\n",
      "የቁጠባ ሒሳብ ማስከፈት\n",
      "Target Audience\n",
      "18 አመት በላይ ለሆኑ ሁሉም ሰዎች\n",
      "Promise\n",
      "ፈጣን እና አስተማማኝ የባንክ አገልግሎት\n",
      "Support for your promise\n",
      "የቅርንጫፍ ብዙ መሆን\n",
      "ከ1900 በላይ ቅርንጫፎች ገነዘብ መውሰድ መቻሉ \n",
      "Key message\n",
      "አዲስ የቁጠባ ሒሳብ መክፈት\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DSTV\n",
      "\n",
      "Ad Content:\n",
      "\n",
      "Tag line - “ በማንኪያ ሲሉ በጭልፋ ፤ በጭልፋ ሲሉ በአካፋ! ”\n",
      "“ ከጥር 6 እስከ መጋቢት 22 ድረስ ከሚጠቀሙት ፓኬጅ ከፍ ካሉ በእኛ ወጪ ወደ ቀጣዩ ትልቅ ፓኬጅ ለአንድ ወር ከፍ ይላሉ! ”\n",
      "Content - \n",
      "“ #DStv\n",
      "📣 ሰምተዋል?\n",
      "በማንኪያ ሲሉ በጭልፋ ፤ በጭልፋ ሲሉ በአካፋ!\n",
      "👉 ከጥር 6 እስከ መጋቢት 22 ድረስ ከሚጠቀሙት ፓኬጅ ከፍ ካሉ በእኛ ወጪ ወደ ቀጣዩ ትልቅ ፓኬጅ ለአንድ ወር ከፍ ይላሉ! ⏰ ይህ አገልግሎት ክፍያ ከፈፀሙ ከ48 ሰዓት በኋላ ተግባራዊ ይሆናል።\n",
      "*ደንብና ሁኔታዎች ተፈፃሚነት አላቸው።\n",
      "የዲኤስቲቪ አገልግሎቶችን ለማግኘት ከታች ያለውን  \n",
      "የMyDStv Telegram ሊንክ ይጫኑ! https://bit.ly/2WDuBLk\n",
      "#ሁሉምያለውእኛጋርነው #DStvEthiopia #StepUp ”\n",
      "\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "ዲኤስ ቲቭ ፓኬጅ ሽልማት \n",
      "Background\n",
      "የመዝናኛ ቲቭ ቻናሎች ማቅረብ\n",
      "Objective\n",
      "ዲኤስ ቲቪ ፓኬጅ ከፍ ማስደረግ ካደረጉ መሽለም\n",
      "Target Audience\n",
      "ዲኤስ ቲቪ ያስገቡ ሰዎች\n",
      "Promise\n",
      "ፓኬጅ ከፍ ላደረጉ በእኛ ወጪ ወደ ቀጣዩ ትልቅ ፓኬጅ ለአንድ ወር ከፍ ይላሉ\n",
      "Key message\n",
      "ዲኤስ ቲቪ ፓኬጅ ከፍ ማስደረግ፣ ዲኤስ ቲቪ ካላስገቡ እንዲያስገቡ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Langano furniture\n",
      "\n",
      "Ad Content: \n",
      "\n",
      "Tag line - “ ለዘመናዊ የቤት እቃዎች አምሮትዎ ላንጋኖ ፈርኒቸር! ”\n",
      "Content - \n",
      "“ ለዘመናዊ የቤት እቃዎች አምሮትዎ ላንጋኖ ፈርኒቸር!\n",
      "በረጅም ጊዜ ልምድ በተሰሩ ጠንካራ እና የተመሰከረላቸው የፈርኒቸር ስራዎቻችን አሁንም በገበያው ላይ ነግሰዋል!\n",
      "የፈርኒቸር ምርቶቻችን፡-\n",
      "✔️ ሌዘርና የጨርቅ ሶፋዎች \n",
      "✔️ የአዋቂ እና የህጻን ልጅ አልጋዎች በተለያዩ መጠን እና ዲዛይን \n",
      "✔️  ቁ/ሳጥኖች በተለያዩ ዲዛይን\n",
      "✔️ የምግብ ጠረጴዛዎች በተለያየ ዲዛይን፡-በ6ወንበር,በ8ወንበር፣በ4ወንበር\n",
      "✔️ የሶፋ ጠረጴዛዎች በተለያዩ መጠንና ዲዛይን\n",
      "✔️  ዘመናዊ ኪችኖች \n",
      "✔️  የጫማ ሸልፍ በተለያዩ መጠንና ዲዛይን…..ወዘተ ሲሆን በእርስዎ ፍላት መሰረት የሚቀርቡ አዳዲስ ዲዛይኖችን ተቀብለን እናዘጋጃለን፡፡\n",
      "ልዩነታችን\n",
      "♦️ ከጊዜ በኃላ ማሳደስ ቢፈልጉ እንደ አዲስ አድርገን መሳደሳችን፣\n",
      "\n",
      "♦️ ያዘዙትን ፈርኒቸር በቁርጥ ቀጠሮ ቀን እናቀርባን፣\n",
      "♦️ ከኛ የገዙትን ዕቃዎችን ከረጅም ጊዜ በኃላ በአዲስ መለወጥ ሲፈልጉ እንቀበላለን\n",
      "♦️ መጓጓዣና ጫኝ እስከ ቤትዎ ድረስ ከኛው መሆኑ፣\n",
      "♦️ ከደንበኞች ለሚቀርቡ ቅሬታዎች አፋጣኝ ምላሽ መስጠታችን\n",
      "♦️ በማንኛውም በዓላት ወቅት 5% የዋጋ ቅናሽ የሚናደርግ መሆናችን፣\n",
      "♦️ አዲስ ደንበኛ በርሶዎ በኩል ሲመጣ ማበረታች አዘጋጅተናል\n",
      "ስለሆነም ለዘላቂ ተጠቃሚነት እና እርካታ የሀገር ውስጥ ፈርኒቸር ምርቶችን ከእኛ ይግዙ፡፡\n",
      "🛑አድራሻችን፡-ሀዋሳ\n",
      "ከሳሙኤል ገበያ አዳራሽ ተሻግሮ / ዋንዛ አደባባይ ሳይደርሱ \n",
      "በሰልክ ቁጥሮቻችን ፡0916581884 /0907212223/0944221511\n",
      "ይደውሉልን,ይጎበኙን!    \t\n",
      "ላንጋኖ ፈርኒቸር\n",
      "በሀዋሳ የአበራ ላንጋኖ ፈርኒቸር እህት ድርጅት ”\n",
      "Reconstructed Brief (Can be used as Template)\n",
      "\n",
      "Post title:-\n",
      "ልዩ የበአል ታላቅ ቅናሽ \n",
      "Background\n",
      "የፈርኒቸር ስራ እና ሽያጭ\n",
      "Objective\n",
      "የፈርኒቸር ስራዎችን ማስተዋወቅ፣ ሽያጭን ማሳደግ\n",
      "Target Audience\n",
      "18 አመት በላይ ለሆኑ ሁሉም ሰዎች\n",
      "Promise\n",
      "ጥራት ያላቸው የፈርኒቸር ምርቶች\n",
      "Support for your promise\n",
      "ሌዘርና የጨርቅ ሶፋዎች \n",
      "የአዋቂ እና የህጻን ልጅ አልጋዎች በተለያዩ መጠን እና ዲዛይን \n",
      "ቁ/ሳጥኖች በተለያዩ ዲዛይን\n",
      "Key message\n",
      "የፈርኒቸር መግዛት\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: Extra Tuition Deferral Scholarship - Cohort B.docx\n",
      "Extracted Text:\n",
      "\n",
      "Extra Tuition Deferral - Special Opportunity for Top Performers from Underrepresented Groups and Women\n",
      "At 10 Academy, we believe in rewarding exceptional talent and dedication. That’s why we offer an Extra Tuition Deferral opportunity for the top 10% of performers from underrepresented groups (Benin, Cameroon, Ghana, Kenya, Nigeria, Rwanda, Sudan, Uganda) and women during our assessment period.\n",
      "We’ll be offering the extra tuition deferral for top 2 women and top 2 men for cohort B.\n",
      "These individuals demonstrate exceptional commitment, performance, and potential during the assessment period, typically Week 0 of our selection process.\n",
      "Difference between regular deferred payment program and tuition deferral scholarship\n",
      "Evaluation Criteria\n",
      "Candidates are evaluated based on various factors, including:\n",
      "\n",
      "Submission Count: Applicants are assessed based on their completion of all required submissions.\n",
      "Task Completion: Performance on optional or bonus tasks within the weekly challenges is considered.\n",
      "Attendance Rate: An attendance rate of 80% or higher is expected to demonstrate commitment.\n",
      "Submission Quality: Quality and relevance of submissions are evaluated for their depth and applicability.\n",
      "Community Activity: Participation in program activities, such as helping peers and actively engaging in discussions, is taken into account.\n",
      "\n",
      "Payment Detail\n",
      "Through this scholarship, we empower exceptional individuals to use their full potential, regardless of financial circumstances.\n",
      "\n",
      "\n",
      "File: Week-0 Materials.docx\n",
      "Extracted Text:\n",
      "Week 0 Materials - 10 Academy\n",
      "Welcome to Week 0 (Assessment Week)  of your training at 10 Academy! Access the materials for each session through the following links:\n",
      "Day 1 - Monday\n",
      "Morning Session: Introduction to the Challenge here\n",
      "Afternoon Session: Python Environment Setup - here, Git and Github, CI/CD - here &  Project Planning & EDA - Data Science Workflow using CRISP-DM and EDA techniques - here\n",
      "Day 2 - Tuesday\n",
      "Morning Session: Data Science Component Building (Architecture Designs, Wireframing, logic flow)\n",
      "(Link to materials will be added)\n",
      "Afternoon Session: Topic Modeling, Sentiment Analysis, Time Series Analysis & ML Engineering components\n",
      "(Link to materials will be added)\n",
      "Day 3 - Wednesday\n",
      "Morning Session: Working with SQL and NOSQL\n",
      "(Link to materials will be added)\n",
      "Afternoon Session: Database schema design\n",
      "(Link to materials will be added)\n",
      "Day 4 - Thursday\n",
      "Morning Session: Building Dashboards using Streamlit\n",
      "(Link to materials will be added)\n",
      "Afternoon Session: Introduction to Fullstack programming using React and Python\n",
      "(Link to materials will be added)\n",
      "Day 5 - Friday\n",
      "Morning Session: Introduction to Cloud Computing and terminologies & Introduction to Terraform\n",
      "(Link to materials will be added)\n",
      "Afternoon Session: Introduction to Kubernetes, Serverless, and distributed docker-based deployment\n",
      "(Link to materials will be added)\n",
      "\n",
      "For any questions or support, reach out on Slack or via email rodas@10academy.org. \n",
      "\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Proactivity - W6.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 6\n",
      "Careers - Exercise 1\n",
      "\n",
      "Proactivity\n",
      "\n",
      "Due Date: Saturday, 1st June 2024, 8PM UTC\n",
      "\n",
      "Background\n",
      "To succeed in the workplace, it's essential to be proactive. This means taking the initiative, anticipating challenges, and finding solutions without being told what to do. Proactive employees are a valuable asset to any organisation, driving innovation, improving efficiency, and boosting productivity.\n",
      "Being proactive is the first habit discussed in the 7 habits of highly effective people. It is more than just taking initiative; it's about taking responsibility for our own lives and choices. We have the power to choose our responses and make things happen. Proactive individuals recognize this responsibility and don't blame external circumstances for their behaviour. Instead, they make conscious choices based on their values, not their feelings.\n",
      "In contrast, reactive individuals are often affected by their environment and the behaviour of others. They let external factors dictate their mood and performance. Proactive people, on the other hand, are driven by their values and can maintain a positive attitude and high performance regardless of the circumstances.\n",
      "Task\n",
      "You're a Data Engineer at a company that provides data analytics services. Your boss, Rachel, sends you an email about a data pipeline issue:\n",
      "\"Hi Team,\n",
      "One of our clients is experiencing issues with their data pipeline. The data is not being updated in real-time, and they're seeing delays of up to 24 hours. The client is frustrated and threatening to cancel their subscription. Additionally, the client mentioned:\n",
      "The data is incomplete, with some tables missing entirely\n",
      "The data schema has changed, but the pipeline hasn't been updated to reflect this\n",
      "The client has tried to contact the support team multiple times, but received no response\n",
      "Please investigate and resolve this issue ASAP. We can't afford to lose clients due to data pipeline issues and poor communication.\n",
      "Best,\n",
      "Rachel\"\n",
      "Reference Data:\n",
      "The data pipeline is built using Apache Beam and Google Cloud Dataflow\n",
      "The data is sourced from multiple databases and APIs\n",
      "The client's data schema changed recently, but the pipeline wasn't updated\n",
      "The support team has been overwhelmed with requests, leading to delayed responses\n",
      "Exercise:\n",
      "Assuming you're the Data Engineer, create a reactive email and a proactive email reply to Rachel.\n",
      "Write down and explain at least 4 differences you spot between your reactive email reply and your proactive email reply. \n",
      "Share a detailed story about a situation at 10 Academy where you took a proactive approach. What happened, what did you do, and how did it turn out? What three lessons did you learn from this experience that will help you continue to grow and improve in the future?\n",
      "Share a detailed story about a situation at 10 Academy where you reacted to a situation without thinking ahead. What happened, how did you respond, and what was the outcome? What lessons did you learn from this experience that will help you improve and become more proactive in the future?\n",
      "Reflect on your typical behaviour in challenging situations. Do you tend to be proactive or reactive? What are your strengths and weaknesses in this regard? What strategies can you use to improve your proactive behaviour and minimise reactive responses?\n",
      "\n",
      "\n",
      "\n",
      "Submission\n",
      "Create a PowerPoint presentation with a maximum of 12 slides that detail your answers to the tasks written above.\n",
      "\n",
      "\n",
      "\n",
      "Rubrics\n",
      "\n",
      "Usefulness in life\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Weekly Challenge_ Week 3.docx\n",
      "Extracted Text:\n",
      "p\n",
      "\n",
      "10 Academy Cohort B - Weekly Challenge: Week 3\n",
      "Redash chatbot add-on: LLM based chatbot for Advanced Data Analytics, Visualisation, and Automated Insight Extraction\n",
      "Overview\n",
      "Business Need\n",
      "Our company is seeking to significantly enhance its data analysis capabilities, specifically focusing on comprehensive YouTube data exploration. The aim of this project is to build a novel Redash chat add-on that our team members can use to extract insight from multiple Redash dashboards and from connected databases using natural language. The chat add-on enables a seamless  conversation in a question and answer format and autonomous knowledge discovery.  User queries could be about what is already displayed in the dashboard or questions that require generating SQL query using LLMs to be run against our connected databases. The end-to-end system you will help us build will empower and allow our team members to extract deep, meaningful, and actionable insights from our business intelligence (BI) platforms. \n",
      "Our company's BI dashboards are not only to give us monitoring capability of our business process, but also to help us transform the data we collect from multiple systems such as YouTube, Slack and Gmeet into actionable insights that can drive strategic decisions and offer a competitive edge in understanding digital content consumption trends.\n",
      "The scope of this project extends to developing a Redash add-on in the frontend and an intelligence backend that translates user queries into one of the following \n",
      "Summary of visualisations in the current dashboard\n",
      "Insight about data returned by existing SQL queries\n",
      "Auto generate SQL queries and visualisations \n",
      "Auto generate new Redash dashboards from existing and auto generated SQL queries and its associated visualisations.\n",
      "This tool will be a game-changer to BI and data analysis using Redash - helping translate natural language queries into complex SQL queries. This functionality is expected to democratize data analytics, allowing team members with non-technical backgrounds to easily extract and visualize data without deep knowledge of SQL. The integration of this add-on with Redash will streamline our analytical processes, making data exploration more accessible, efficient, and user-friendly.\n",
      "Additionally, the backend API you will develop could be usable in many data analysis and BI projects. \n",
      "Data\n",
      "Video metadata for all videos uploaded in our YouTube channel\n",
      "Time Series viewership metadata for all videos uploaded in our YouTube channel\n",
      "Time Series comments for all our videos uploaded in our YouTube channel\n",
      "Time Series transcribed text for selected videos uploaded in our channel\n",
      "This week data\n",
      "Expected Outcomes\n",
      "Skills:\n",
      "Data Analysis and Visualization:\n",
      "Proficiency in analysing time series data\n",
      "Proficiency in EDA techniques.\n",
      "Expertise in creating intuitive and informative dashboards.\n",
      "Programming and Development Skills:\n",
      "Proficiency in Python and Javascript (React) programming languages\n",
      "Proficiency in SQL \n",
      "Proficiency in understanding code bases for complex software packages\n",
      "Proficiency in Prompt Engineering\n",
      "Proficiency in using OpenAI API\n",
      "Experience in developing add-ons or plugins\n",
      "SQL and Database Management \n",
      "Experience in running concurrent tasks using Celery \n",
      "Experience in deploying complex software package using Docker and docker-compose\n",
      "UI/UX Design\n",
      "Knowledge:\n",
      "Natural Language Processing (NLP) Knowledge:\n",
      "Use of vector databases\n",
      "Machine Learning and AI Knowledge\n",
      "Team\n",
      "Instructors: \n",
      "Yabebal\n",
      "Emtinan\n",
      "Rehmet\n",
      "Key Dates\n",
      "Discussion on the case - 9:00 UTC time on 07 May 2024.  Use #all-week-3 to ask questions.\n",
      "Interim Submission - 8:00 PM UTC time on Wednesday 08 May 2024.\n",
      "Final Submission - 8:00 PM UTC time on Saturday 11 May 2024\n",
      "Leaderboard for the week\n",
      "There are 100 points available for the week.\n",
      "20 points - community growth and peer support. \n",
      "\t13 points - technical public and group-based RC channels\n",
      "Total number of messages (5)\n",
      "Total number of Mentions (3)\n",
      "Total number of DM connections (5) \n",
      "\t7 points - community activities\n",
      "Number of messages in non-technical channels (4)\n",
      "On-time presence in Gmeet sessions (3) \n",
      "30 points - presentation and reporting.\n",
      "\t15 points - interim submission. PDF\n",
      "    \n",
      "\t15 points for the final submission.  Blog entry or PDF with 5-8 pages.  \n",
      "50 points - Technical content\n",
      "\t20 points - Interim submission\n",
      "Github link submission (20)\n",
      "\n",
      "30 points - Final submission \n",
      "\n",
      "Github Link submission (25)   \n",
      "\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\n",
      "Visualization - the quality of visualizations, understandability, skimmability, choice of visualization\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in the future this will be CICD\n",
      "An innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\n",
      "Group Work Policy\n",
      "This week, you are expected to complete the project with your assigned group. In the table below, your name is assigned to one of the groups we formed.\n",
      "\n",
      "\n",
      "\n",
      "Late Submission Policy\n",
      "Our goal is to prepare successful learners for a global level job. At work, deadlines are sometimes very strict - either you do it before the deadline or the company loses a substantial opportunity.  Moreover, the late communication behaviour (submission in 10 Academy can be considered as progress communication to team leads), blinds team leads and CEOs and is very determinantal in hindering the success of the company.\n",
      "We have set our late submission as follows\n",
      "Submissions are accepted only within the 12 hrs window - 17:00 UTC - 7:00 UTC  of the submission deadline\n",
      "Frequently late submissions (exceeding 6 total late submissions) will disqualify a person from the list of trainees 10 Academy recommends to partner employers.\n",
      "Badges will be rewarded for the cumulative on-time appearances (gmeet calls, on-time assignment submissions, and other places where being on-time is important) \n",
      "\n",
      "\n",
      "Instructions\n",
      "The fundamental tasks in this week’s challenge are the following \n",
      "The workflow for this week's challenge is as follows\n",
      "Understand Redash and Data Exploration: Gain a comprehensive understanding of Redash's capabilities and data exploration requirements.\n",
      "Create a Database Schema: Design a schema that is well-suited for YouTube data and analytics.\n",
      "Outline implementation: Develop an implementation plan for the Redash add-on and backend systems.\n",
      "Plan Integration of Large Language Models: Design the integration approach for large language models for natural language understanding.\n",
      "Plan your work and set up a development environment to assist in completing the project\n",
      "Build frontend system\n",
      "Improve starter Redash chat add-on and make it Robust. You could try the following if you have time\n",
      "Chat window is available in Redash query editor\n",
      "Temporary chat window pops up next to any visualisation in the Redash dashboard. Context for this temporary chat window is the data and query that generated the given visualisation.\n",
      "Build Backend System Development,\n",
      "Build a system that translates Natural Language questions in English to SQL \n",
      "Allow generation of relevant visualisation from existing or auto generated SQL queries \n",
      "Allow generation of Redash dashboards from natural language query\n",
      "Set up a GitHub repo, integrate unit testing and CICD for proper code package test and deployment\n",
      "\n",
      "\n",
      "Possible Work Plan\n",
      "Stage 1: Basic Solution with Python and OpenAI API\n",
      "- Objective: Establish foundational chatbot capabilities for interpreting and translating natural language queries into SQL.\n",
      "- Python and OpenAI API: Utilize Python's robust data processing abilities and the OpenAI API for initial natural language understanding and SQL translation.\n",
      "- Implementation: Develop Python scripts for parsing YouTube data, generating SQL queries, and interfacing with Redash for visualizations. This stage addresses primary tasks like data exploration, schema creation, and basic language to SQL translation.\n",
      "\n",
      "Stage 2: Enhanced NLP with LangChain Integration\n",
      "- Objective: Improve the chatbot's NLP capabilities to process more complex queries and provide accurate SQL translations.\n",
      "- LangChain: An intuitive open-source framework that enhances the functionality of large language models (LLMs), such as OpenAI or Hugging Face, for dynamic, data-responsive applications.\n",
      "- Implementation: Embed LangChain into the Python backend, replacing basic OpenAI API usage. This will enhance natural language understanding and processing, allowing for sophisticated reasoning and context-aware interactions with data.\n",
      "\n",
      "Stage 3: Advanced Data Handling with LLamaIndex\n",
      "- Objective: Optimize data management for more efficient data retrieval and processing.\n",
      "- LLamaIndex: A data framework designed for LLM-based applications, offering tools for data ingestion, indexing, and querying, and facilitating the integration of various data sources.\n",
      "- Implementation: Implement LLamaIndex in the backend to streamline data access. It will enhance the chatbot’s efficiency in data retrieval and query processing, particularly for the diverse data types associated with YouTube analytics.\n",
      "\n",
      "Stage 4: Incorporation of Vector Databases for Semantic Search\n",
      "- Objective: Enhance the chatbot’s semantic search capabilities for more relevant and contextual data retrieval.\n",
      "- Vector Databases: Specialized databases designed to handle high-dimensional vector data, crucial for semantic searches and understanding data in terms of semantic similarities.\n",
      "- Implementation: Utilize vector databases to store and search transcribed text, comments, and metadata from YouTube. This will significantly improve the chatbot’s ability to deliver insightful responses based on semantic understanding.\n",
      "\n",
      "Task 1: Review the LLM Revolution and Plan your Work\n",
      "There has been so much development in the area of Large Language and Multi-modal (text, image, audio, video) Models. It is paramount to have a basic understanding of key developments in this space to be able complete the current project. \n",
      "\n",
      "Ensure you understand the following key topics and tools\n",
      "\n",
      "OpenAI Tools\n",
      "OpenAI Chat Completion using ChatGPT (the first tool that starts the LLM Revolution)\n",
      "OpenAI Assistants, Threads, and Run\n",
      "OpenAI Function Call\n",
      "OpenAI Advanced Data Analysis \n",
      "OpenAI Code Interpreter\n",
      "OpenAI Actions (previously called Plugins)\n",
      "\n",
      "LangChain Components\n",
      "LangChain Tools\n",
      "LangChain Agents \n",
      "LangChain Memory\n",
      "LangChain Retrievers\n",
      "LangChain Adapters\n",
      "\n",
      "LLamaIndex Components \n",
      "LLamaIndex Data connectors\n",
      "LLamaIndex Query functions\n",
      "LLamaIndex Indexing\n",
      "\n",
      "Vector Databases\n",
      "Embedding Documents (image, text, audio, video)\n",
      "Semantic Search using Vector Similarity  \n",
      "\n",
      "Browse the the following links and summarise your understanding in a report\n",
      "SQL generation using LLMs: Can LLMs Replace Data Analysts? Getting Answers Using SQL\n",
      "Openai-cookbook examples e.g Backtranslation_of_SQL_queries.py\n",
      "Experiment quickly using Flowise AI\n",
      "Paper to read: InsightPilot: An LLM-Empowered Automated Data Exploration System\n",
      "LLMs and SQL Langchain Blog\n",
      "Awesome collection of tools, models, and ideas in the LLM Arena\n",
      "Llamaindex: An Imperative For Building Context-Aware Llm-Based Apps\n",
      "\n",
      "Task 2: Tool understanding and Data exploration \n",
      "Understanding Redash and Data Exploration:\n",
      "Learn about Redash's capabilities for data visualization and analytics.\n",
      "Explore how Redash can connect to various data sources, including YouTube analytics .\n",
      "Create a Database Schema for YouTube Data and Analytics:\n",
      "Design a schema to efficiently store and query YouTube data.https://docs.google.com/spreadsheets/d/1amkmUHkU06z_UaDMr9ROm7FNreRpAti_uzvSPISMJoY/edit?usp=sharing\n",
      "Consider aspects like channel performance, user base, and video expenses.\n",
      "Task 3: Building Redash Chat Add-on\n",
      "Outline the Architecture for the Redash Add-on and Backend Systems:\n",
      "Plan the structure of the Redash add-on and how it integrates with backend systems.\n",
      "Develop and Implement the Dashboard Interface with the add-on\n",
      "Design the UI of the dashboard, focusing on user-friendliness for Redash add-on.\n",
      "Implement the design using React and integrate it with Redash.\n",
      "Develop the Backend System for Data Storage and Processing:\n",
      "Build a system to store and process data, aligning with the designed database schema.\n",
      "Ensure efficient data retrieval and processing capabilities.\n",
      "For your python backend Framework, you may use Quart - the lightweight async version of Flask \n",
      "Task 4: LLM Understanding and Integration \n",
      "Integrate Large Language Models for Natural Language Understanding:\n",
      "Incorporate language models to interpret and process natural language queries.\n",
      "Focus on translating these queries into actionable data insights.\n",
      "Integrate the Add-on to Convert Natural Language Queries into SQL\n",
      "Ensure accurate translation and compatibility with the Redash environment.\n",
      "\n",
      "Task 5: Automatic Dashboard Generation\n",
      "Implement automatic visualisation generation based on user queries, generated SQL queries, and existing visualisation context.:\n",
      "Implement creating Redash dashboards using a collection of visualisations .\n",
      "Task 6: Blog Reporting\n",
      "Write a blog-like report that details the process followed, challenges faced. dashboard building process, LLM integration and lessons learnt from this week’s challenge.\n",
      "N.B for reporting\n",
      "Your report should start with the Introduction, the overall body of your report, and then a Conclusion.\n",
      "\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Tuesday: Understanding Redash\n",
      "Here the trainees will understand the week’s challenge.\n",
      "Introduction to Week Challenge (Yabebal)\n",
      "Introduction to Building Redash Add-on using React (Rehmet)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding week’s challenge\n",
      "Understanding the ‘what is’ Redash\n",
      "Ability to reuse previous knowledge\n",
      "Wednesday: Redash source code review and setup \n",
      "Here the trainees will understand the components of chatbot and data analysis using OpenAi, LangChain, and LIDA.\n",
      "\n",
      "Prompt Engineering tools and ideas (Emtinan)\n",
      "Building chatbot Backend using LangChain (Emtinan)\n",
      "Thursday: LLM usage and Integration \n",
      "Here the trainees will understand how advanced data analysis and automatic sql query  generation .works using LLMs\n",
      "\n",
      "Asynchronous execution for OpenAI API Streaming and Redash query execution (Rehmet)\n",
      "How ADA, LIDA, AutoGPT, InsightPilot, and other LLM agents work (Rehmet)\n",
      "Friday: Concurrent execution for Robust Chatbot\n",
      "Here the trainees will understand how to do aysnc request to OpenAI API and execute SQL queries in Redash Celerey executer \n",
      "\n",
      "Vector Database Layer for RAG Bots (Emtinan)\n",
      "Submission \n",
      "Interim: Due Wednesday 08 May 20:00 UTC\n",
      "A Pdf report with an overview of your understanding of the key LLM tools and APIs\n",
      "Review of OpenAI technologies\n",
      "Review of LangChain components\n",
      "Review of Vector Databases\n",
      "Review of LLM based AI applications e.g Retrieval Augmented Generation s and Agents\n",
      "Review of Redash server, worker, and scheduler. Comment on the use/need for asynchronous computing  in chatbot development.\n",
      "A PDF report providing a concise and comprehensive analysis of the SQL query used to address Task 2, focusing on its efficiency and performance under scaling conditions. Comment on how long (time) will it take your query if the data size grows by 10x, 1000x, 100000x, 1000000x.\n",
      "\n",
      "Github link submission that demonstrates:\n",
      "Work in progress for Redash chat add-on  frontend\n",
      "Work in progress for Redash chat add-on backend\n",
      "Work in progress for prompts to help generate SQL using OpenAI APIs\n",
      "Work in progress for \n",
      "database schema design\n",
      "data loading to database\n",
      "Dockerfile and docker-compose based Redas installation\n",
      "Celery \n",
      "\n",
      "\n",
      "Feedback\n",
      "You may not receive detailed comments on your interim submission but will receive a grade.\n",
      "Interim 2: Due Saturday 11 May 20:00 UTC\n",
      "Pdf document (to be published) or a published Blog link detailing the process followed. This should include:\n",
      "The business objective of the project\n",
      "The project design \n",
      "The tech-stack used\n",
      "The methodologies followed\n",
      "The challenges faced\n",
      "Github link submission that includes the following\n",
      "Work in progress Redash Chat Add-on frontend code\n",
      "Work in progress Redash Chat Add-on backend code\n",
      "Database schema design\n",
      "Data loading to database\n",
      "Installation scripts (Dockerfile, docker-compose, bash/python/Makefile scripts to automate installation) and Readme explaining how to install and use\n",
      "Well demonstrated CI (frequent commits, multiple branches with good names, unit test and linting github actions) and CD (github actions to build docker images from PR to dev and prod branches)\n",
      "Final: Due Tuesday 14 May 20:00 UTC\n",
      "Pdf document (to be published) or a published Blog link detailing the process followed. This should include:\n",
      "The business objective of the project\n",
      "The project design \n",
      "The tech-stack used\n",
      "The methodologies followed\n",
      "The challenges faced\n",
      "The results obtained\n",
      "The lessons learned\n",
      "Limitations and future plans\n",
      "\n",
      "Github link submission that includes the following\n",
      "Redash Chat Add-on frontend code\n",
      "Redash Chat Add-on backend code\n",
      "Installation scripts (Dockerfile, docker-compose, bash/python/Makefile scripts to automate installation) and Readme explaining how to install and use\n",
      "Well demonstrated CI (frequent commits, multiple branches with good names, unit test and linting github actions) and CD (github actions to build docker images from PR to dev and prod branches)\n",
      "Demonstration of coding best practices (Following python-openai or langchain code base coding style)\n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "\n",
      "References\n",
      "Key References\n",
      "Redash ApI Usage \n",
      "Prompt engineering : Openai Prompt Engineering Guide\n",
      "promptingguide.ai: A prompt engineering guide that demonstrates many techniques.\n",
      "learnprompting.org: An introductory course to prompt engineering.\n",
      "YouTube API reference\n",
      "How to extract YouTube data \n",
      "YouTube data usage \n",
      "\n",
      "\n",
      "\n",
      "File: cB - Career Challenge - 3 Real World Jobs.docx\n",
      "Extracted Text:\n",
      "10 Academy cB: Week 1\n",
      "\n",
      "Careers Challenge - 1\n",
      "3 real world jobs \n",
      "\n",
      "Deadline: 27th April 2024, 8pm UTC\n",
      "\n",
      "Introduction\n",
      "In preparation for your transition into the professional world, it's essential to understand the expectations of employers in your chosen career track of Data Engineering, Machine Learning and Gen AI Engineering. This exercise provides practical experience in researching job opportunities, analysing employer requirements, and reflecting on your own skills.\n",
      "\n",
      "By exploring real-world job postings, you'll gain insights into the skills and qualifications sought by employers, helping you tailor your training efforts and increase your competitiveness in the job market as 10 Academy expects you to be while at the end of the training programme.\n",
      "\n",
      "\n",
      "Instructions:\n",
      "\n",
      "Your goal is to explore job opportunities in the field of DE, or ML Eng, or Gen AI Eng, and Find three (3) positions that you could potentially pursue by August 2024. Ensure that each position meets the following criteria:\n",
      "\n",
      "It is currently available and seeking placement.\n",
      "It is suitable for someone with your level of experience. \n",
      "Remote positions are encouraged. \n",
      "Each position must have an online job posting with a link to apply directly.\n",
      "\n",
      "Create a google slide or PPT of 6 slides (strictly 6 slides). The first slide should be a cover page and the following 3 should be for each job you found, and then the final 2 slides should be of the 2nd and 3rd questions written down here.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task:\n",
      "In the 3 middle slides of your PPT, provide the following details For each job you found:\n",
      "\n",
      "Link to the online job advertisement \n",
      "Name of the company\n",
      "Title of the position\n",
      "Team you would be joining\n",
      "Is the role remote or hybrid or physical? \n",
      "Physical location of the job (if applicable)\n",
      "Applications closing date (if provided)\n",
      "Skills requirements listed on the job application - (Abbreviations can be used)\n",
      "Years of experience requirements.\n",
      "Requirements on nationality, right-to-work, or related, (if any)\n",
      "Salary information (if known)  \n",
      "LinkedIn contact of the hiring manager (if available)\n",
      "Analysis of key challenges you might face in securing this role by August 2024 after completing the training. \n",
      "\n",
      "\n",
      "Write down the minimum of 3 differences between your current skills and the skills requirements of each of the  jobs you found. \n",
      "\n",
      "Write 4 lessons learned from conducting this assignment and how it has influenced your career exploration journey. \n",
      "\n",
      "\n",
      "Usefulness in life\n",
      "\n",
      "This exercise will challenge you to actively engage in the job search process, utilizing online resources to identify suitable positions, analyze job requirements, and reflect on how your own skills align with employer expectations. Through this hands-on exploration, you will not only enhance your understanding of the job market but also gain valuable insights into your own strengths and areas for growth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Weekly Challenge_ Week - 6.docx\n",
      "Extracted Text:\n",
      "\n",
      "10 Academy Cohort B\n",
      "Weekly Challenge: Week 6\n",
      "LLM Finetuning: Enabling Quality Embedding and Text Generation for Amharic, Swahili, and Yoruba Languages\n",
      "Overview\n",
      "Business Need\n",
      "AfroTech Solutions is an innovative African company that focuses on using AI to improve customer support and engagement. Our goal is to help African businesses by using new technology in AI. Our latest project is an AI-powered customer support system designed for the African market. By using advanced AI, this system aims to provide smooth, multilingual support across different platforms.\n",
      "This project aims to make our customer support services better by using AI to generate text in Amharic, Swahili, and Yoruba. We plan to create systems that can generate quick and relevant responses in these languages based on customer questions and past interactions.\n",
      "For this project to be successful, our customer support must be both efficient and meaningful to our diverse clients. To achieve this, the technology needs to have strong capabilities in text embedding and generation for Amharic, Swahili, and Yoruba. We will collect large datasets for each language and fine-tune suitable open-source LLM models based on the datasets collected in the previous week. For Amharic, we may use models like Nous Hermes Mistral 8 7B or amharic language finetuned version of  LLama 2 (Samuael/llama-2-7b-tebot-amharic or iocuydi/llama-2-amharic-3784m) -  and finetune it further to deliver the business objective. We will also select and fine-tune equivalent models for Swahili and Yoruba based on the collected data and the chosen language in the previous week to meet our business goals effectively.\n",
      "\n",
      "Inspirations \n",
      "The following works are our inspiration. We envision to collaborate with all stakeholders to create a robust quality LLM for the languages. \n",
      "Llama2-Chinese/README_EN.md at main · FlagAlpha/Llama2-Chinese (github.com) \n",
      "\n",
      "Data\n",
      "You will use the data you collected in the previous week.\n",
      "Expected Outcomes\n",
      "Skills:\n",
      "Experience working with Huggingface APIs and platform \n",
      "Fine-tuning and deploying LLMs\n",
      "Experience in using multiple GPUs for parallel training and inference  \n",
      "Working with Deep Learning Frameworks \n",
      "Amharic, Swahili, and Yoruba text processing\n",
      "Proficiency in Python programming language\n",
      "Proficiency in Prompt Engineering\n",
      "Knowledge:\n",
      "Understanding Transformer Models and their components\n",
      "Understanding the building blocks of Instruction Based LLMs \n",
      "Understanding Chat Models such as ChatML chat template  \n",
      "Natural Language Processing (NLP) Knowledge\n",
      "Machine Learning and AI Knowledge\n",
      "\n",
      "Team\n",
      "Tutors: \n",
      "Yabebal\n",
      "Emitinan\n",
      "Rehmet\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\n",
      "\n",
      "Visualization - quality of visualizations, understandability, skimmability, choice of visualization\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in future this will be CICD/CML\n",
      "Innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\n",
      "Group Work Policy\n",
      "This week, you are expected to complete the project with your assigned group. In the table below, your name is assigned to one of the groups we formed.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Instructions\n",
      "The rapidly evolving landscape of LLMs benefitted from the unprecedented scales of model size and training data producing models with strong capabilities, including  reasoning and learning from experience at levels surpassing humans’. \n",
      "\n",
      "However, due to the high imbalance in training data (text sources from the internet), English dominates in these models. Models are not as proficient in other languages, especially low-resource languages that are absent from the multilingual training corpora. \n",
      "\n",
      "Collecting large-scale data for a  low-resource language and retraining an LLM can be prohibitively expensive due to computational and data collection costs. A better approach is transfer learning; transferring an LLM’s capabilities from English to a non-English language through further pre-training and fine-tuning.\n",
      "\n",
      "As part of this challenge, you are required to do the following tasks \n",
      "Understand the LLM landscape as of Jan 2024\n",
      "Understand the building blocks of \n",
      "LLM base models (encoder only, encoder-decoder, decoder only)\n",
      "GPU memory needs (15-20GB, 20-80GB, >80GB), Numbers of GPUs, and time to full pretraining and finetuning.\n",
      "How to finetune\n",
      "Instruct finetuning\n",
      "Chat finetuning\n",
      "Understand the key components of LLM Training and Finetuning\n",
      "Pre-training: self-supervised learning predicting the next word in a given context\n",
      "Supervised fine tuning (SFT)\n",
      "Parameter-efficient Tuning (PEFT)\n",
      "Low-Rank Adaptation (LoRA)  \n",
      "Overview of best contender open source LLM models and their variations\n",
      "Mistral:  7B, 8x 7b, \n",
      "Llama 2/3: 7b\n",
      "Falcon: 7b\n",
      "Stable AI 2:  1.6B\n",
      "OpenLLama: 3B, 7B \n",
      "Explore huggingface documentation for inference and finetuning \n",
      "Test hugging face embedding examples on your local machine tasks\n",
      "Test hugging face small LLM models on your local machine\n",
      "Test hugging face modules for \n",
      "Data loading, preprocessing, batching, and tokenizing \n",
      "Loading quantized models (BitsAndBytes)\n",
      "Applying parameter-efficient finetuining (PEFT) \n",
      "Applying LoRA \n",
      "General techniques to reduce memory and finetune efficiently with a optimal tradeoff among, memory,  speed,  and accuracy\n",
      "Understand and Prepare the collected data for finetuning \n",
      "Explore provided data as well as what you can find in the web\n",
      "Prepare data to be ingested in your instruction-finetuning pipeline\n",
      "Prepare evaluation datasets to benchmark your finetuned model with baseline OpenAI/Huggingface deployed models\n",
      "Select an open-source LLM model and finetune it \n",
      "\t\n",
      "Task 1: Literature Review & Hugging face ecosystem \n",
      "In this task you are expected to review basic concepts and methods used to perform further pre-training and fine-tuning of a LLM:\n",
      "\n",
      "Get good understanding of the following concepts and techniques relevant to LLMs\n",
      "Definitions of key terms and concepts\n",
      "hackerllama - The Llama Hitchiking Guide to Local LLMs (osanseviero.github.io)\n",
      "Background knowledge on LLMs: \n",
      "Introduction to Large Language Models\n",
      "Understanding LLMs: A Comprehensive Overview from Training to Inference\n",
      "Transformer architecture (encoder, decoder, self-attention)\n",
      "Transformers made easy: architecture and data flow | by Maâli Mnasri | Opla | Medium\n",
      "How Self Attention works in Transformer\n",
      "Generative AI: The Science Behind Large Language Models - Simplified\n",
      "LLM Landscape\n",
      "Architecture: three categories: Encoder-only , Encoderdecoder and Decoder-only\n",
      "LLM Boxing • Choose your Champion\n",
      "Comparing the Best Open-Source Large Language Models | Shakudo\n",
      "library (ollama.ai)\n",
      "Embedding of the input data: Tokenization, Positional Embedding\n",
      "google/sentencepiece: Unsupervised text tokenizer for Neural Network-based text generation. (github.com)\n",
      "Test how tokenization works with OpenAI tokenizer \n",
      "Master Positional Encoding: Part I | by Jonathan Kernes | Towards Data Science\n",
      "Understanding positional embeddings in transformer models (harrisonpim.com)\n",
      "Key concepts in Fine-tuning an LLM\n",
      "Fine-Tuning Embedding Model with PEFT and LoRA\n",
      "Hosting A Text Embedding Model That is Better, Cheaper, and Faster Than OpenAI’s Solution \n",
      "\n",
      "Get familiar with Huggingface ecosystem\n",
      "Review huggingface documentation\n",
      "Hugging Face Hub documentation\n",
      "🤗 Transformers (huggingface.co)\n",
      "Templates for Chat Models (huggingface.co)\n",
      "Try some examples  on your local machine\n",
      "Building a PDF Knowledge Bot With Open-Source LLMs - A Step-by-Step Guide | Shakudo\n",
      "An Introduction to Using Transformers and Hugging Face\n",
      "How instruction finetuning works\n",
      "huggingface/alignment-handbook: Robust recipes for to align language models with human and AI preferences (github.com)\n",
      "Amharic, Yoruba, and Swahili data collection, processing, and pipeline for LLM finetuning \n",
      "Llama-2-Amharic: LLMs for Low Resource Languages | by Garri Logistics | Dec, 2023 | Medium,\n",
      "https://huggingface.co/UBC-NLP/serengeti\n",
      "https://huggingface.co/Mollel/Swahili_Gemma\n",
      "https://huggingface.co/LeroyDyer/Mixtral_AI_SwahiliTron_7b\n",
      "\n",
      "\n",
      "Task 2: Load an LLM and Use It for Inference \n",
      "This task will see you setting up your work environment, load an open source pre-trained LLM and use it to generate output for a variety of scenarios (text generation, translation, question answering, summarization ..etc).\n",
      "Set up a Huggingface account (this is required for accessing some open source models e.g. LLaMA 2, and to  upload your fine-tuned model later)\n",
      "Note about LLaMA: to get access to the model you need to\n",
      "Fill this  Meta’s Form, with the same email address you used to create your Hugging Face account. \n",
      "Visit the page of one of the LLaMA 2 available models, and accept Hugging Face’s licence terms and acceptable use policy.\n",
      "Set up your environment [GPU enabled notebooks]\n",
      "Make a choice of open source LLM to use.\n",
      "The choice of model (including the size of the model) depends on the use case and computational resource available.\n",
      "Choosing the Right Open-Source LLM for Your Needs\n",
      "Which Open Source LLM Best to FINE-TUNE ? \n",
      "Check the comprehensive list of open source/access LLMs on Hugging Face.\n",
      "[optional] You can use HuggingChat (Hugging Face's open-source chat UI for LLMs) to check a couple of LLMs (eg:  Mixtral-8x7B and Llama 2/3 model  fine-tuned for dialogue) \n",
      "Load an open source LLM from Hugging Face. The size of the model will depend on whether we use quantization\n",
      "Without model quantization:\n",
      "How to download open source LLM models from hugging face and use it locally on your machine\n",
      "Running a Hugging Face Large Language Model\n",
      "With model quantization: Model Quantization with 🤗 Hugging Face Transformers and Bitsandbytes Integration\n",
      "Inference: use the loaded LLM to generate output. Make sure to test multiple inference scenarios  (text generation, translation, question answering, summarization) and test the model’s ability to handle Amharic, Yoruba, and Swahili  language \n",
      "Hugging Face docs: Generation with LLMs\n",
      "[optional] use a pipeline for inference\n",
      "Task 3: Data preprocessing and preparation\n",
      "You may follow Llama-2-Amharic: LLMs for Low Resource Languages | by Garri Logistics | Dec, 2023 | Medium to understand the important steps of amharic data preparation for LLM finetuning. \n",
      "\n",
      "\n",
      "Suggested tasks (be creative to do more) are:\n",
      "For Amharic:\n",
      "* ['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'] with ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']\n",
      "* ['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'] with ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']\n",
      "* ['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'] with ['ሰ, 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']\n",
      "* ['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'] with ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']\n",
      "* ['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'] with ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']\n",
      "For Yoruba \n",
      "Eliminate non-Yoruba text, HTML tags, special characters, and irrelevant content.\n",
      "For Swahili\n",
      "Eliminate non-Swahili text, HTML tags, special characters, and irrelevant content.\n",
      "Task 4: Fine-Tuning the LLM\n",
      "Steps needed to fine-tune the LLM. Steps from inputting the data to model deployment. \n",
      "\n",
      "For Amharic \n",
      "Garri logistics model: iocuydi/amharic-llama-llava (github.com) \n",
      "Chinese-LLaMA-Alpaca-2 v4.0 released long context LLMs (64K) and RLHF-tuned LLMs\n",
      "facebookresearch/llama-recipes: Examples and recipes for Llama 2 model (github.com)\n",
      "alignment-handbook/scripts/README.md at main · huggingface/alignment-handbook (github.com)\n",
      "How to Fine-tune an LLM Part 3: The HuggingFace Trainer | alpaca_ft – Weights & Biases (wandb.ai) (check out part 1 & 2 as well)\n",
      "as starter.\n",
      "For Swahili\n",
      "Mollel/Swahili_Gemma\n",
      "https://huggingface.co/LeroyDyer/Mixtral_AI_SwahiliTron_7b\n",
      "https://huggingface.co/Mollel/Swahili-Alpaca-Llama-3-8b_16bit\n",
      "For Yoruba\n",
      "https://huggingface.co/UBC-NLP/serengeti\n",
      "\n",
      "\n",
      "To use the Garri logistics model:\n",
      "Accept Llama2 license on huggingface and download it like this:\n",
      "git lfs install\n",
      "git clone https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
      "Download the amharic finetune from huggingface like this:\n",
      "git lfs install\n",
      "git clone https://huggingface.co/iocuydi/llama-2-amharic-3784m\n",
      "Clone https://github.com/iocuydi/amharic-llama-llava repository\n",
      "Then inside inference/run_inf.py:\n",
      "comment the import safety_utils line\n",
      "change the MAIN_PATH to the path to folder you downloaded from step 1\n",
      "change the peft_model to the path you cloned in the step 2\n",
      "go to your llama2 folder (from step 1) and replace all the tokenizer related files with the one you find from the 2nd step\n",
      "set quanitzation=True inside the main function before the load_model function call\n",
      "Finally run the inference/run_inf.py file \n",
      "\n",
      "\n",
      "You may choose one of the followng as your base model\n",
      "Introducing Stable LM 2 1.6B — Stability AI\n",
      "Mistral 7B | Mistral AI | Open-weight models 2310.06825.pdf (arxiv.org)\n",
      "imoneoi/openchat: OpenChat: Advancing Open-source Language Models with Imperfect Data (github.com)\n",
      "tiiuae/falcon-7b · Hugging Face\n",
      "Llama 2 - Meta AI\n",
      "\n",
      "\n",
      "\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Monday: The Mechanics of LLMs\n",
      "Challenge walk through and Introduction to transformers.\n",
      "Introduction to Week Challenge (Yabebal)\n",
      "Overview of LLMs:  Their transformer architecture and main techniques (Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "Understand the project \n",
      "Get a good understanding of how LLMs work\n",
      "Tuesday: Tokenization and Vocabulary Creation\n",
      "More concepts\n",
      "Q&A session (Yabebal)\n",
      "Tokenization and Word embedding (Rehmet)\n",
      "\n",
      "Wednesday: LLMs Fine-tuning\n",
      "Get a good understanding of data preparation and LLM finetuning .\n",
      "Different types of fine-tuning a pre-trained LLM (Emtinan)\n",
      "Components of a transformer Model (Emtinan)\n",
      "\n",
      "Thursday: Inference & LLMOps \n",
      "More concepts \n",
      "Components of a transformer Model (Emtinan)\n",
      "Advanced use of Huggingface (Rehmet)\n",
      "Friday: Deployment \n",
      "More concepts \n",
      "Data Preparation for Instruction Tuning (Rehmet) \n",
      "\n",
      "Deliverables\n",
      "NOTE: Document should be a PDF stored in google drive or published blog link. DO NOT SUBMIT A LINK as PDF! If you want to submit pdf document, it should be the content of your report not a link. \n",
      "Interim Submission - Wednesday 8pm UTC\n",
      "Link to your code in GitHub\n",
      "Repository where you will be using to complete the tasks in this week's challenge. A minimum requirement is that you have a well structured repository and some coding progress is made.\n",
      "\n",
      "\n",
      "A review report of your reading and understanding of Task 1 & 2 and any progress you made in other tasks. \n",
      "Feedback\n",
      "You may not receive detailed comments on your interim submission, but will receive a grade.\n",
      "Final Submission - Saturday 8pm UTC\n",
      "Link to your code in GitHub \n",
      "Complete work  for Finetuning LLMs with Amharic, Yoruba, and Swahili (Depends on which language you chose in the previous week) data\n",
      "Complete work  for Generating texts  \n",
      "\n",
      "A blog post entry (which you can submit for example to Medium publishing) or a pdf report. . \n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "References\n",
      "Complete Beginner’s Guide to Hugging Face LLM Tools\n",
      "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA\n",
      "PEFT (Parameter-Efficient Fine-Tuning)\n",
      "Finetuning Large Language Models (LLMs) BERT\n",
      "\n",
      "Infrastructure \n",
      "Benchmarking Popular Opensource LLMs: Llama2, Falcon, and Mistral (truefoundry.com)\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Weekly Challenge_ Week 2.docx\n",
      "Extracted Text:\n",
      "\n",
      "10 Academy Cohort B - Weekly Challenge: Week 2\n",
      "Data Engineering: Data warehouse tech stack with MySQL/PostgreSQL, DBT, Airflow\n",
      "Overview\n",
      "Business Need\n",
      "You and your colleagues have joined to create an AI startup that deploys sensors to businesses, collects data from all activities in a business - people’s interaction, traffic flows, smart appliances installed in a company. Your startup helps organisations obtain critical intelligence based on public and private data they collect and organise. \n",
      "A city traffic department wants to collect traffic data using swarm UAVs (drones) from a number of locations in the city and use the data collected for improving traffic flow in the city and for a number of other undisclosed projects. Your startup is responsible for creating a scalable data warehouse that will host the vehicle trajectory data extracted by analysing footage taken by swarm drones and static roadside cameras. \n",
      "The data warehouse should take into account future needs, organise data such that a number of downstream projects query the data efficiently. You should use the Extract Load Transform (ELT) framework using DBT.  Unlike the Extract, Transform, Load (ETL), the ELT framework helps analytic engineers in the city traffic department setup transformation workflows on a need basis.  \n",
      "Data\n",
      "In Downloads – pNEUMA | open-traffic (epfl.ch) or from https://zenodo.org/records/7426506 you can find a pNEUMA data: pNEUMA is an open large-scale dataset of naturalistic trajectories of half a million vehicles that have been collected by a one-of-a-kind experiment by a swarm of drones in the congested downtown area of Athens, Greece. Each file for a single (area, date, time) is ~87MB data.  \n",
      "You may refer to the following references to understand how the data is generated from video frames recorded with swarm drones.\n",
      "PIA15_poster.pdf (datafromsky.com)\n",
      "(PDF) Automatic vehicle trajectory extraction for traffic analysis from aerial video data (researchgate.net)\n",
      "You may use the following github packages to visualise and interact with the data (and obtain other similar data)\n",
      "tud-hri/travia: a Traffic data Visualization and Annotation tool (github.com)\n",
      "JoachimLandtmeters/pNEUMA_mastersproject: Written python files to work with pNEUMA dataset (github.com)\n",
      "\n",
      "Expected Outcomes\n",
      "Skills:\n",
      "Create and maintain Airflow DAGs\n",
      "Work with Apache Airflow, dbt, redash  and a DWH\n",
      "Apply ELT techniques to DWH\n",
      "Build data pipelines and orchestration workflows\n",
      "\n",
      "Knowledge:\n",
      "Enterprise-grade data engineering - using Apache and Databricks tools\n",
      "Team\n",
      "Instructors: \n",
      "Yabebal\n",
      "Emtinan\n",
      "Rehmet\n",
      "Key Dates\n",
      "Discussion on the case - 09:00 UTC time on Monday 29 Apr 2024.  Use #all-week2 to ask questions.\n",
      "Interim Submission - 8:00 PM UTC time on Wednesday 01 May 2024.\n",
      "Final Submission - 8:00 PM UTC time on Saturday 04 May 2024.\n",
      "Leaderboard for the week\n",
      "There are 100 points available for the week.\n",
      "20 points - community growth and peer support. \n",
      "30 points - presentation and reporting.\n",
      "15 points - interim submission. PDF slide or report format.     \n",
      "15 points for the final submission.  Blog entry or PDF with 5-8 pages.  \n",
      "\n",
      "50 points - Technical content\n",
      "20 points - Interim submission\n",
      "30 points - Final submission\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\n",
      "\n",
      "Visualization - the quality of visualizations, understandability, skimmability, choice of visualization\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in the future this will be CICD\n",
      "An innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\n",
      "Late Submission Policy\n",
      "Our goal is to prepare successful learners for the work and submitting late when given enough notice, shouldn’t be necessary.\n",
      "For interim submissions, those submitted 1-6 hours late will receive a maximum of 50% of the total possible grade. Those submitted >6 hours late may receive feedback, but will not receive a grade.\n",
      "\n",
      "For final submissions, those submitted 1-24 hours late, will receive a maximum of 50% of the total possible grade. Those submitted >24 hours late may receive feedback, but will not receive a grade.\n",
      "\n",
      "\n",
      "Instructions\n",
      "The fundamental tasks in this week’s challenge are the following - building data warehouse techstack\n",
      "Consisting of\n",
      "A “data warehouse” (PostgreSQL)\n",
      "An orchestration service (Airflow)\n",
      "An ELT tool (dbt)\n",
      "A reporting environment (redash)\n",
      "Set it up locally using \n",
      "fully dockerized \n",
      "\n",
      "Complete the following tasks:\n",
      "Create a DAG in Airflow that uses the bash/python operator to load the data files into your database. Think about a useful separation of Prod, Dev and Staging\n",
      "Connect dbt with your DWH and write transformations codes for the data you can execute via the Bash or Python operator in Airflow. Write proper documentation for your data models and access the dbt docs UI for presentation. \n",
      "Check additional modules of dbt that can support you with data quality monitoring (e.g. great_expectations, dbt_expectations or re-data). \n",
      "Connect the reporting environment and create a dashboard out of this data\n",
      "Write a short article about your approach and what were the most important decisions along the way\n",
      "\n",
      "Consider the following elements when doing the above tasks\n",
      "AIRFLOW: \n",
      "If you want to use templates in Airflow, what is a good way to manage metadata and variables within your DAGS? (read about context)\n",
      "Automated Alerting - what happens if the DAG is failing, e.g. a slack or email alert\n",
      "Build hard circuit breaker pipelines with dbt (e.g. if a test fails, do not update the production tables)\n",
      "dbt\n",
      "Automate the generation of dbt docs and make it available via web frontend\n",
      "Explore macros and write your own to create dynamic documentation and functions\n",
      "Automate the dbt to Airflow connection by automatically creating DAGS out of dbt metadata (see here: https://www.astronomer.io/blog/airflow-dbt-2) \n",
      "Redash\n",
      "Build a version control script system by hitting the API, download the queries and built an automated git storage process\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Monday: Introduction to Week Challenge\n",
      "Here the trainees will understand the week’s challenge.\n",
      "Introduction to Week Challenge (Yabebal)\n",
      "Data Models (kedro, data vault, star schema, database normalisation) (Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding week’s challenge\n",
      "Understanding Data Warehousing\n",
      "Ability to reuse previous knowledge\n",
      "Sharing references and content around data warehousing\n",
      "Getting familiar with data models and frameworks\n",
      "\n",
      "Tuesday: dbt Orchestration with Airflow\n",
      "Here the trainees will understand Airflow and how to use it to schedule and orchestrate dbt.\n",
      "Analytics Engineering using DBT (Emtinan)\n",
      "Scheduling and Orchestration using Airflow (Rehmet)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding directed acyclic graphs (DAGs) in Airflow\n",
      "Using Airflow as a scheduler to orchestrate dbt\n",
      "Sharing references and content around dbt and airflow\n",
      "Wednesday: From Data Lakehouse to BI Dashboards\n",
      "Here the trainees will understand the different data warehouse and data lake tech stacks \n",
      "Kedro Data Layers - Data Lakehouse (Dibora)\n",
      "Building Dashboards using Redash (Abel)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding Data Warehouse, Data Lake, and Data Warehouse\n",
      "Understanding redash\n",
      "Sharing references and content around redash and data warehousing concepts\n",
      "Thursday: Data Models and Tools\n",
      "Here the students will understand Redash.\n",
      "Using DBT and Tableau/Looker/Microsoft BI to build BI Dashboard \n",
      "Conversation with the Data Engineering team (Betty et al.) - Adludio Team\n",
      "AWS Cloud Ecosystem for Data Engineering (Nabil et al.)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Introduction to AWS S3, Redshift, RDS, Athena, Glue\n",
      "Understanding Amazon Athena (managed presto) & Amazon Glue (managed HIve)\n",
      "Sharing references and content around Snowflakes, Databricks Data Lakes, Google Big Query, Amazon Redshift and other  data warehousing and data lake technologies.\n",
      "Learning the data engineering tools ecosystem\n",
      "Sharing references and content around redash and data warehousing concepts\n",
      "TBD: Data models, tools, and frameworks\n",
      "ELT vs ETL\n",
      "Analytics Engineering with DBT \n",
      "Data Models for scalable data warehouse\n",
      "Data Lakes vs Data Warehouse: Tools and principles \n",
      "Snowflake \n",
      "Amazon Athena (managed presto) & Amazon Glue (managed HIve)\n",
      "Databricks\n",
      "Google BigQuery\n",
      "Amazon Redshift\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Learning the data engineering tools ecosystem\n",
      "Getting familiar with data models and frameworks\n",
      "\n",
      "Submission \n",
      "Interim: Due Wednesday 01 May 20:00 UTC\n",
      "Link to your code in GitHub. You should have a screenshot folder that includes a screenshot of your data lineage from dbt\n",
      "Submit a two pages max document that shows the tech-stack flow diagram, and explanation of the different elements\n",
      "Final Due Saturday 04 May 20:00 UTC\n",
      "Link to your code in GitHub. Your readme should contain the link to your deployed dbt data warehouse documentation. You should also have a screenshot folder that includes a screenshot of the data view you built\n",
      "A blog or report explaining the process you followed to build the tech stack. What are the challenges? What can be improved with more time?\n",
      "\n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "\n",
      "References\n",
      "Data Warehouse, Data Models, and Data Tools\n",
      "Data Warehouse Testing 101 | Panoply\n",
      "Building a Data Vault (matillion.com)\n",
      "DataHub Open Source Metadata Platform\n",
      "Modern Data Warehouses: Functions, Architecture, & Examples | Estuary\n",
      "dbt:\n",
      "General Information:\n",
      "Installing dbt https://docs.getdbt.com/dbt-cli/installation/#pip\n",
      "dbt(Data Build Tool) Tutorial · Start Data Engineering\n",
      "dbt - Package hub (getdbt.com)\n",
      "Introduction Videos on dbt https://www.youtube.com/playlist?list=PLy4OcwImJzBLJzLYxpxaPUmCWp8j1esvT\n",
      "Redshift config; https://docs.getdbt.com/reference/resource-configs/redshift-configs/\n",
      "Docs from Gitlab: https://about.gitlab.com/handbook/business-ops/data-team/platform/dbt-guide/\n",
      "CLI command reference: https://docs.getdbt.com/reference/dbt-commands/\n",
      "Basic Introduction to dbt https://www.kdnuggets.com/2021/07/dbt-data-transformation-tutorial.html\n",
      "Articles:\n",
      "https://medium.com/the-telegraph-engineering/dbt-a-new-way-to-handle-data-transformation-at-the-telegraph-868ce3964eb4\n",
      "https://medium.com/hashmapinc/dont-do-analytics-engineering-in-snowflake-until-you-read-this-hint-dbt-bdd527fa1795\n",
      "Repo Examples:\n",
      "https://github.com/mattermost/mattermost-data-warehouse\n",
      "https://gitlab.com/gitlab-data/analytics/-/tree/master/\n",
      "How to structure repo's \n",
      "https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355\n",
      "https://discourse.getdbt.com/t/should-i-have-an-organisation-wide-project-a-monorepo-or-should-each-work-flow-have-their-own/666/2\n",
      "https://discourse.getdbt.com/t/how-to-configure-your-dbt-repository-one-or-many/2121\n",
      "https://medium.com/photobox-technology-product-and-design/practical-tips-to-get-the-best-out-of-data-building-tool-dbt-part-1-8cfa21ef97c5\n",
      "\n",
      "Airflow:\n",
      "https://livebook.manning.com/book/data-pipelines-with-apache-airflow/chapter-1/v-6\n",
      " https://www.linkedin.com/in/marclamberti/ \n",
      "\n",
      "Docker: \n",
      "https://www.youtube.com/watch?v=fqMOX6JJhGo\n",
      "https://docker-curriculum.com/#docker-images\n",
      "\n",
      "Redash:\n",
      "https://github.com/dwyl/learn-redash\n",
      "https://fitdevops.in/how-to-setup-redash-dashboard-on-ubuntu\n",
      "Virtual environments:\n",
      "https://www.ianmaddaus.com/post/manage-multiple-versions-python-mac/\n",
      "https://www.codeblocq.com/2016/01/Search-through-history-in-OSX-terminal/\n",
      "https://janakiev.com/blog/jupyter-virtual-envs/\n",
      "https://medium.com/@blessedmarcel1/how-to-install-jupyter-notebook-on-mac-using-homebrew-528c39fd530f\n",
      "\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Peer Mentorship - W1.docx\n",
      "Extracted Text:\n",
      "10 Academy cA: Week 1\n",
      "Career Exercise 2 \n",
      "Peer Mentorship\n",
      "\n",
      "Due Date: Saturday, 27th April 2024, 8PM UTC\n",
      "Background\n",
      "Highlighting the critical significance of intentional teamwork within any organisation is essential. Regardless of the profession you pursue, teamwork remains indispensable. With the increasing adoption of remote and hybrid work models, it's crucial to navigate digital interactions with colleagues over different platforms. Collaborating with peers/ workmates fosters mutual growth and enhances professional development, contributing to collective success within the organisation. \n",
      "\n",
      "The objective of this exercise is to gain a comprehensive understanding of the role and practice of peer mentorship as well as the importance of collaboration in a remote work setting. \n",
      "\n",
      "Guidelines:\n",
      "\n",
      "This exercise is for you to practise peer mentorship with one of your colleagues. You have been paired with one of one of your colleagues for this exercise. The list can be found here.\n",
      "Using the reference material below as additional insight and guidelines, get a clear definition of who a peer mentor is and how peer mentorship is practised. \n",
      "You are supposed to meet your peer via Google meet. Follow the instructions in the task section below to understand how you will navigate that meeting.\n",
      "\n",
      "\n",
      "Before the meeting:\n",
      "Do a quick search about your peer via LinkedIn or Google to have some basic information (in order to get to know them a little). Be careful to respect their digital privacy and stick to professional platforms only. This little research on your peer on Linkedin or the internet could help guide your choice of questions to ask.\n",
      "Prepare a list of 5 tailored questions to ask during the meeting to gather insights into the peer's tech background, experience and challenges in their 10 Academy’s journey so far, and any interesting facts about them. \n",
      "Reach out to them and schedule a Google Meet session on the time that is convenient to both of you. \n",
      "\n",
      "During the meeting;\n",
      "Introduce yourselves, demonstrate curiosity, and inquire about the colleague's background and interests. \n",
      "Get to know your peer’s strengths and weaknesses. Keep an open-minded conversation and consider the list of questions and insight areas you’ve mentioned above. See if you can find mutual ways to guide each other during the training because this will be your accountability partner during the training. \n",
      "Take a screenshot of both of you during the call with your videos on.\n",
      "\n",
      "Task:\n",
      "\n",
      "After your session with your peer, we would like you to draft a report documenting the exercise from your perspective. Your report should be a PowerPoint of 6 slides [Respect the number of slides.  \n",
      "\n",
      "Your report should answer the following 7 questions:\n",
      "What challenges did you have before and during the preparation of your meeting? How did you overcome these challenges?\n",
      "Write down a short bio of your peer according to how they introduced themselves. \n",
      "List of the 5 questions you asked your peer and their answers to them.\n",
      "List of 5 questions your peer asked you.\n",
      "What are 5 things you learnt or benefited from this exercise and how they might benefit your career in future?\n",
      "What is your CTA (Call to Action)? (Did you exchange contact and social media handles? Did you schedule a subsequent meeting? Did you agree on frequent checkups?)\n",
      "On your last slide, attach a screenshot of you both with your cameras on.\n",
      "\n",
      "Usefulness in real life\n",
      "Understanding how to work well with others is really important in any job. No matter what you do, teamwork matters. Especially now, with more people working from home or in a mix of office and remote settings, knowing how to talk and collaborate online is key. This activity is all about learning from each other and helping each other grow. By teaming up with a colleague, you'll get to share experiences and support each other in your work. It's like having a buddy to learn and grow with. Plus, you'll learn how to use tools like Google Calendar and Google Meet to schedule and have online meetings. It's a chance to get better at working together, which is super useful for your career.\n",
      "\n",
      "Rubrics: \n",
      "\n",
      "Preparation Challenges:  This question aims to evaluate the trainee's ability to recognize and navigate obstacles encountered in the preparation phase of the peer mentorship meeting. Grading will focus on their identification of challenges, problem-solving approach, and reflection on solutions implemented.\n",
      "\n",
      "Peer Short Bio: This question assesses the trainee's capacity to synthesise information and communicate it clearly, demonstrating active listening skills and effective summarization techniques. Grading will focus on whether the trainee offered a brief yet comprehensive overview of the peer's background, focusing on relevant details, and also evaluate the clarity and organisation of the peer introduction, ensuring that essential details are effectively communicated.\n",
      "\n",
      "Questions Asked and Answers: This question focuses on the quality of the interaction between the trainee and the peer, assessing the effectiveness of the trainee's questions and the peer's responses in facilitating constructive dialogue and knowledge sharing. Grading will focus on  Evaluating if the trainee listed 5 questions to ask their peer. These questions should show ability to gain valuable insights from the peer. And also look for the presence of the answers provided in regards the asked questions.\n",
      "\n",
      "List of questions from the peer: In this question, the trainee is expected to document 5 questions asked by their peer about them during the meeting, demonstrating accuracy, relevance, and completeness in their response. Grading will focus on that.\n",
      "\n",
      "Learnings from this exercise: In this question, the trainee is expected to reflect on the learning outcomes and benefits of the peer mentorship exercise, and articulate how these insights can positively impact their future career development with clarity and specificity. Grading will focus on Assessing the depth of reflection, evaluating the trainee's ability to articulate how the insights gained from the exercise can benefit their career development in the future, and the clarity and conciseness of the trainees answer.\n",
      "\n",
      "Call to Actions: In this question, grading will focus on the trainee's proactive approach in establishing ongoing communication and collaboration with their peer is evaluated based on their initiative, clarity of communication, and emphasis on continued collaboration. \n",
      "\n",
      "Screenshot! Grading will check the presence of the meeting screenshot in your slide.\n",
      "\n",
      "\n",
      "\n",
      "Important Links\n",
      "\n",
      "Mentoring Alternatives: The Role of Peer Relationships \n",
      "What is Peer Mentoring\n",
      "SKILLS FOR SUCCESSFUL MENTORING:\n",
      "How to be a peer mentor \n",
      "How to build a successful mentoring relationship.\n",
      "8 Tips for an amazing Mentor relationship.\n",
      "How to build a great relationship with a mentor\n",
      "\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Leadership - W5.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 5\n",
      "Careers - Exercise 2\n",
      "\n",
      "Leadership\n",
      "\n",
      "Due Date: May 25, 2024. 8:00 PM UTC\n",
      "\n",
      "Background\n",
      "Have you ever wondered what makes a truly great leader? We often picture powerful figures who have shaped history, from revolutionary leaders like Gandhi and Martin Luther King Jr. to influential business titans. But what exactly sets these individuals apart? Why do some leaders inspire unwavering devotion while others struggle to gain traction?\n",
      "\n",
      "At its core, leadership is about influencing others to achieve a shared goal. As leaders, we inspire and guide our teams to navigate change and accomplish the organisation's objectives. \n",
      "\n",
      "Task A\n",
      "As a leader, it's essential to recognize and acknowledge your strengths and weaknesses to effectively manage and develop your team. Reflecting on past experiences with ineffective leaders can help you identify traits to avoid and areas for personal growth.\n",
      "Think about the least favourite leader you've ever had the experience of working with. This could be a manager, supervisor, or team lead.\n",
      "Exercise\n",
      "Who was the least favourite leader you ever had? Describe their position, behaviour, and any notable characteristics.\n",
      "What did they do to be your least favourite leader? Identify specific actions, decisions, or behaviours that made them ineffective .\n",
      "Do you resonate with any of the behaviours your least favourite leader has? Highlight 3 weaknesses you believe you have as a leader.\n",
      "For each of the weaknesses identified, explain how you aim to improve on them as a leader.\n",
      "\n",
      "Task B\n",
      "You are the project manager at NovaTech, a software development company. Your team has been tasked with developing \"Project Phoenix,\" a critical new product that will determine the company's future in the competitive tech market. \n",
      "Project Phoenix launch deadline is three months away, and the company's stakeholders are eagerly awaiting its success.\n",
      "Your team consists of diverse individuals with varying levels of experience:\n",
      "John (leaving in two weeks): A seasoned developer and key team member with in-depth knowledge of the project's core component. His departure will leave a significant gap in expertise..\n",
      "Aisha: A new team member with a background in emerging technologies. She's suggested using a different technology, \"EchoStack,\" which she's familiar with, but it's different from the team's usual process.\n",
      "Mark: A senior developer with experience in software development. He expressed concerns about the feasibility of Aisha’s proposed approach to the project.\n",
      "Raj: A mid-level developer with experience in software design patterns. He's been working on the project's UI components.\n",
      "Lena: A junior developer who's been assisting with testing and debugging.\n",
      "David: A Quality Assurance (QA) engineer responsible for ensuring the product meets the required quality standards.\n",
      "During the team meeting on Monday, John announced his unexpected departure, leaving the team with a significant knowledge gap (remember he’s the one with knowledge of the project's core component) and added workload. John's expertise will be sorely missed. Aisha's suggestion to use EchoStack has sparked debate, as it would require significant changes to the project's architecture.Mark has expressed concerns about Aisha’s proposed approach, citing potential risks and delays. \n",
      "As the project manager, it's your responsibility to:\n",
      "Address the knowledge gap left by John's departure\n",
      "Resolve the disagreement between Mark and Aisha\n",
      "Ensure the project stays on track and meets the immovable deadline\n",
      "Motivate and guide the team to overcome the challenges ahead\n",
      "\n",
      "\n",
      "Exercise\n",
      "Explain five ways to ensure that John’s departure does not have a significant negative impact on the success of the project?\n",
      "Using the tips on managing people, outline a step-by-step approach you’ll use to address Mark's concerns and Aisha's suggestion?\n",
      "Which leadership style(s) will you use to motivate and guide the team to ensure the project stays on track and meets the deadline? Explain why you chose that style(s) giving examples of occasions where you’ll use them.\n",
      "\n",
      "Submission\n",
      "Your responses should be on a maximum of 10 slides PPT. Convert it into PDF and submit the link on Tenx.\n",
      "\n",
      "\n",
      "Rubrics\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Weekly Challenge_ Week 5.docx\n",
      "Extracted Text:\n",
      "\n",
      "\n",
      "10 Academy Cohort B - Weekly Challenge: Week 5\n",
      "Scalable Data Warehouse for LLM Finetuning: API Design for High Throughput Data Ingestion and RAG Retrieval\n",
      "Overview\n",
      "Business Need\n",
      "Roots Tech Solutions is committed to enhancing its Natural Language Processing (NLP) capabilities for multiple African languages, particularly for Swahili, Yoruba, and Amharic languages. As part of this initiative, the company aims to develop a comprehensive data corpus to support various NLP applications, such as semantic search, content generation, chatbot support, sentiment analysis, speech recognition, and more.\n",
      "The ability to process and understand Swahili, Yoruba, and Amharic text/audio accurately is critical for Roots Tech Solutions to develop innovative and competitive products. The current lack of extensive, high-quality text/audio datasets for these languages is a significant bottleneck. By collecting a vast amount of  text/audio dataset from diverse online sources, including news websites, blogs, and social media platforms, the company can overcome this challenge.\n",
      "The collected data will undergo cleaning and processing to ensure its quality and relevance. It will be stored in a structured database, making it easily accessible for various NLP tasks. Additionally, APIs will be developed to facilitate seamless integration and querying of the dataset, enabling the company to leverage this resource effectively.\n",
      "This project is expected to significantly enhance Roots Tech Solutions' NLP capabilities, enabling the development of sophisticated African languages processing tools and applications, thereby providing a competitive edge in the technology market. \n",
      "Data\n",
      "You will be collecting the data from various data sources.\n",
      "Expected Outcomes\n",
      "Skills:\n",
      "Data Collection and Web Scraping:\n",
      "Proficiency in web scraping techniques using tools like BeautifulSoup, Scrapy, and Selenium.\n",
      "Expertise in identifying and extracting data from various online sources, including news websites, blogs, and social media platforms.\n",
      "Programming and Development Skills:\n",
      "Proficiency in Python and Javascript (React) programming languages\n",
      "Proficiency in SQL \n",
      "Experience in developing APIs using frameworks like Flask or Django for data access and integration.\n",
      "Proficiency in designing database schemas and managing structured data storage.\n",
      "Data Processing and Cleaning\n",
      "SQL and Database Management  \n",
      "Experience in deploying complex software package using Docker and docker-compose\n",
      "UI/UX Design\n",
      "Knowledge:\n",
      "Natural Language Processing (NLP) Knowledge:\n",
      "Use of vector databases\n",
      "Machine Learning and AI Knowledge\n",
      "Team\n",
      "Instructors: \n",
      "Yabebal\n",
      "Natnael\n",
      "Emtinan\n",
      "Rehmet\n",
      "Key Dates\n",
      "Discussion on the case - 9:00 UTC time on 20 May 2024.  Use #all-week-3 to ask questions.\n",
      "Interim Submission - 8:00 PM UTC time on Wednesday 22 May 2024.\n",
      "Final Submission - 8:00 PM UTC time on Saturday 25 May 2024\n",
      "Leaderboard for the week\n",
      "There are 100 points available for the week.\n",
      "20 points - community growth and peer support. \n",
      "\t13 points - technical public and group-based RC channels\n",
      "Total number of messages (5)\n",
      "Total number of Mentions (3)\n",
      "Total number of DM connections (5) \n",
      "\t7 points - community activities\n",
      "Number of messages in non-technical channels (4)\n",
      "On-time presence in Gmeet sessions (3) \n",
      "30 points - presentation and reporting.\n",
      "\t15 points - interim submission. PDF\n",
      "    \n",
      "\t15 points for the final submission.  Blog entry or PDF with 5-8 pages.  \n",
      "50 points - Technical content\n",
      "\t20 points - Interim submission\n",
      "Github link submission (20)\n",
      "\n",
      "30 points - Final submission \n",
      "\n",
      "Github Link submission (25)   \n",
      "\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\n",
      "Visualization - the quality of visualizations, understandability, skimmability, choice of visualization\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in the future this will be CICD\n",
      "An innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\n",
      "Group Work Policy\n",
      "This week, you are expected to complete the project with your assigned group. In the table below, your name is assigned to one of the groups we formed.\n",
      "Please check out this document for a guideline on how to connect to your cloud machine.\n",
      "\n",
      "\n",
      "Late Submission Policy\n",
      "Our goal is to prepare successful learners for a global level job. At work, deadlines are sometimes very strict - either you do it before the deadline or the company loses a substantial opportunity.  Moreover, the late communication behaviour (submission in 10 Academy can be considered as progress communication to team leads), blinds team leads and CEOs and is very determinantal in hindering the success of the company.\n",
      "We have set our late submission as follows\n",
      "Submissions are accepted only within the 12 hrs window - 17:00 UTC - 7:00 UTC  of the submission deadline\n",
      "Frequently late submissions (exceeding 6 total late submissions) will disqualify a person from the list of trainees 10 Academy recommends to partner employers.\n",
      "Badges will be rewarded for the cumulative on-time appearances (gmeet calls, on-time assignment submissions, and other places where being on-time is important) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Possible Work Plan\n",
      "Decisions:\n",
      "Select group lead and other essential personals to facilitate efficient team work\n",
      "Select the language you will focus your effort to collect data for. The options are:\n",
      "Swahili\n",
      "Yoruba\n",
      "Amharic\n",
      "Define the tech-stacks for your pipeline\n",
      "\n",
      "Work Plan\n",
      "Within your group, plan how you divide the work to group members\n",
      "Using Figma or similar tool, design your tech-stack and how data flows in your pipeline  \n",
      "Stage 1: Initial Data Collection and Storage\n",
      "- Objective: Establish foundational capabilities for collecting, storing, and accessing text data.\n",
      "- Tools: Scrapy, BeautifulSoup, Selenium, MongoDB/PostgreSQL.\n",
      "- Implementation:\n",
      "Identify and list potential data sources such as news websites, blogs, and social media.\n",
      "Develop web scraping scripts using Scrapy, BeautifulSoup, and Selenium to collect text data.\n",
      "Design and implement a database schema in PostgreSQL/MongoDb for storing the collected text data.\n",
      "Store the raw scraped data in the database.\n",
      "\n",
      "Stage 2: Data processing\n",
      "- Objective: Clean, preprocess, and annotate the collected text data to ensure high quality for NLP applications.\n",
      "- Implementation:\n",
      "Develop Python scripts to clean and preprocess the text data (e.g., remove HTML tags, and special characters).\n",
      "Filter data where possible to minimize data contamination by english or other languages that are not your focus. You may also consider creating a separate data table/category for english rich texts.\n",
      "Store the cleaned and processed data back into the database.\n",
      "\n",
      "Stage 3: API Development for Data Access\n",
      "- Objective: Develop APIs to provide easy access to the collected and processed text data.\n",
      "- Implementation:\n",
      "Develop RESTful APIs using Flask or FastAPI to enable querying and retrieving data from the database.\n",
      "Implement endpoints for searching and filtering text data based on keywords and metadata.\n",
      "Ensure efficiency in handling large-scale data access requests.\n",
      "\n",
      "Stage 4: Automation & Stream Processing \n",
      "- Objective: \n",
      " Implement an automated pipeline to ensure continuous data collection, cleaning, processing, storage, and access.\n",
      "- Implementation:\n",
      "Setup workflow automation using Apache Airflow\n",
      "Define workflow DAG\n",
      "Containerize the workflow with Docker\n",
      "Automate deployment and monitoring\n",
      "\n",
      "Handle data streams using a streaming processing library\n",
      "- Implementation:\n",
      "Use the Faust library to setup data producer and consumer \n",
      "Measure the speed with which your pipeline can consume data in async mode\n",
      "Locust - A modern load testing framework\n",
      "\n",
      "\n",
      "\n",
      "Task 1: Data Collection and Storage\n",
      "Identify data sources:\n",
      "Research and list potential sources such as news websites, blogs, social media platforms, online forums, and digital libraries.\n",
      "Prioritize sources based on the quality and volume of content available.\n",
      "Set Up Development Environment\n",
      "Install necessary tools and libraries (e.g., Scrapy, BeautifulSoup, Selenium).\n",
      "Set up version control with Git and create a repository on GitHub.\n",
      "By using Scrapy, BeautifulSoup, and Selenium set up web scraping scripts\n",
      "Design an SQL/NoSQL schema for the raw data.\n",
      "Store raw data.\n",
      "\n",
      "Task 2: Data processing \n",
      "Retrieve the raw text data stored in PostgreSQL/MongoDb\n",
      "Normalize Text\n",
      "Remove punctuation, and normalize whitespace.\n",
      "Remove HTML Tags and Special Characters\n",
      "Store the cleaned data.\n",
      "Task 3: API and Frontend Development for Data Access\n",
      "Develop APIs and a frontend interface to provide easy access to the collected and processed data.\n",
      "Design API Endpoints\n",
      "Define the endpoints needed for data access (e.g., search, filter, retrieve specific data).\n",
      "Implement API Using Flask/FastAPI\n",
      "Create the API application with Flask or FastAPI.\n",
      "Develop the Frontend Interface Using React\n",
      "Create a React application to interact with the API and display the data.\n",
      "Create components for displaying data\n",
      "Implement functionalities like\n",
      "Search\n",
      "Filter\n",
      "Retrieve specific data\n",
      "Task 4: Data Annotation\n",
      "Annotate the subset of the data to create labeled datasets for various Natural Language Processing (NLP) tasks and Supervised LLM finetuning, such as named entity recognition, sentiment analysis, and text classification.\n",
      "Set up annotation tools\n",
      "Prepare data for annotation\n",
      "Prepare the cleaned and preprocessed text data for annotation.\n",
      "Format the data appropriately for the annotation tool.\n",
      "Perform annotations\n",
      "Use Prodigy to annotate the text data.\n",
      "Validate annotations\n",
      "Ensure the quality and consistency of annotations.\n",
      "Store Annotated Data\n",
      "Store the annotated data for use in NLP model training.\n",
      "Task 5: Automation\n",
      "Set Up Apache Airflow for workflow automation\n",
      "Install and configure Apache Airflow to manage and orchestrate the different stages of the pipeline.\n",
      "Define workflow DAG (Directed Acyclic Graph)\n",
      "Create a DAG to define the sequence of tasks for data collection, cleaning, processing, and storage.\n",
      "Containerize the Workflow with Docker\n",
      "Create Dockerfiles for each component of the pipeline (data collection, cleaning, API).\n",
      "Create a docker-compose.yml file for orchestration\n",
      "Use Docker Compose to define and manage the multi-container application.\n",
      "Implement CI/CD Pipeline with GitHub Actions\n",
      "Set up GitHub Actions to automate testing, building, and deployment of the Docker images.\n",
      "Automate Deployment and Monitoring\n",
      "Set up monitoring tools like Prometheus and Grafana to track the performance and health of the pipeline.\n",
      "Task 6: Blog Reporting\n",
      "Write a blog-like report that details the process followed, the challenges faced, and lessons learned from this week’s challenge.\n",
      "N.B for reporting\n",
      "Your report should start with the Introduction, the overall body of your report, and then a Conclusion.\n",
      "\n",
      "\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Monday: Project Overview and Data Collection Techniques\n",
      "Introduction to Week Challenge (Yabebal)\n",
      "Web Scraping and  Data Collection Techniques(Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding week’s challenge\n",
      "Understanding Data Collection Techniques\n",
      "Understanding web scraping\n",
      "Ability to reuse previous knowledge\n",
      "Tuesday: Data Cleaning and Annotation\n",
      "Data preprocessing and cleaning for Amharic, Swahili, and Yoruba text.(Rehmet)\n",
      "Data annotation.(Rehmet)\n",
      "Wednesday: API and Frontend Development \n",
      "Develop APIs for data access.(Rehmet)\n",
      "Frontend development using react.(Rehmet)\n",
      "Thursday: Automation and Orchestration\n",
      "Automating the entire pipeline(Emtinan)\n",
      "Containerizing the application using Docker.(Emtinan)\n",
      "Friday: Monitoring\n",
      "Introduction to monitoring tools (Prometheus and Grafana).(Emtinan)\n",
      "Submission \n",
      "Interim: Due Wednesday 22 May 20:00 UTC\n",
      "A PDF report with an overview of methodologies and tools used for data collection, including: \n",
      "Detailed comparison between web scraping tools used.\n",
      "\n",
      "Github link submission that demonstrates:\n",
      "A working data collection script.\n",
      "Database schema design.\n",
      "Data loading to the database.\n",
      "Work in progress for the front end.\n",
      "Work in progress for backend API.\n",
      "\n",
      "\n",
      "Feedback\n",
      "You may not receive detailed comments on your interim submission but will receive a grade.\n",
      "Final: Due Saturday 25 May 20:00 UTC\n",
      "PDF document (to be published) or a published Blog link detailing the process followed. This should include:\n",
      "The business objective of the project\n",
      "The project design \n",
      "The tech-stack used\n",
      "The methodologies followed\n",
      "The challenges faced\n",
      "The results obtained\n",
      "The lessons learned\n",
      "Limitations and future plans\n",
      "\n",
      "Github link submission that includes the following\n",
      "Data Collection Scripts\n",
      "Data Cleaning and Preprocessing Code\n",
      "API and Frontend Code\n",
      "Example annotations and how they are stored back into the database.\n",
      "Dockerfile(s) for containerizing the different components of the project.\n",
      "docker-compose.yml for orchestrating multi-container applications.\n",
      "Bash/Python/Makefile scripts for automating the installation and setup process.\n",
      "Continuous Integration and Continuous Deployment (CI/CD)\n",
      "Logging\n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "\n",
      "References\n",
      "Key References\n",
      "https://www.selenium.dev/\n",
      "https://scrapy.org/\n",
      "https://beautiful-soup-4.readthedocs.io/en/latest/\n",
      "https://abe2g.github.io/am-preprocess.html\n",
      "https://data.mendeley.com/datasets/p74pfhz3yx/1\n",
      "https://prometheus.io/\n",
      "https://airflow.apache.org/\n",
      "https://prodi.gy/\n",
      "https://medium.com/@swalperen3008/what-is-dockerize-and-dockerize-your-project-a-step-by-step-guide-899c48a34df6\n",
      "https://grafana.com/docs/grafana/latest/setup-grafana/set-up-grafana-monitoring/\n",
      "\n",
      "\n",
      "\n",
      "File: cB - 10 Academy - Careers - Week 2 - Tools for Remote Work.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 2\n",
      "\n",
      "Careers - Challenge 1\n",
      "\n",
      "Tools for Remote Work\n",
      "\n",
      "Submission Deadline: Saturday, 04th May 2024, 8pm UTC\n",
      "\n",
      "Background\n",
      "What is Remote work ?\n",
      "Remote work is the practice of having employees carry out their duties away from a central office. Examples of such places include:\n",
      "A worker's home,\n",
      "Private office, \n",
      "Shared workspace, or \n",
      "any other location besides the typical corporate campus or office building.\n",
      "Onboarding: The term \"onboarding\" describes the procedures used to integrate new hires and employees into the company. In addition to learning about the organisation's structure, culture, vision, mission, and values, it also contains activities that help new hires complete the first new-hire orientation process.\n",
      "Why remote work?\n",
      "Employees can completely customise their working setup. \n",
      "May assist employees with disabilities.\n",
      "Greater talent pool for corporations, with nearly no regional restrictions. \n",
      "Employees (as well as employers) save money and time travelling.\n",
      "Employee productivity can increase with higher autonomy and fewer interruptions at work. \n",
      "The working environment can be entirely customised by employees.\n",
      "Companies and organisations are utilising digital management tools and services to assist them manage their work as remote work becomes more prevalent on a global scale. These are a handful of the most common remote work tools and applications:\n",
      "Google calendar\n",
      "Slack\n",
      "Notion\n",
      "Trello\n",
      "Google Calendar: Google Calendar is used for scheduling and organising events, appointments, and tasks, facilitating efficient time management and coordination.\n",
      "Notion is a project-management and note-taking software. It was designed to help companies and organisations coordinate deadlines, objectives, and assignments for the sake of efficiency and productivity.\n",
      "Slack is termed a “digital headquarters”. With remote work steadily becoming the norm, Slack assists teams by organising different groups/teams/projects into workspaces, or “channels”. This helps users to move between tasks, projects, and groups easily, negating the confusion of having all communication in one workspace. Slack also allows users to send direct messages to one another, and users can send files, audio/voice messages, images, gifs, videos, and can access internet calls.\n",
      "Trello is a web-based project management and collaboration tool that uses a card-based system to help individuals and teams organize tasks, projects, and workflows in a visual and flexible way.\n",
      "\n",
      "Task:\n",
      "Your company has moved to a different location and your team manager has tasked you with setting up the office workflow tools to assist with onboarding a new colleague in your team who has never used these tools before. The workflow tools you have to set up are: Slack, Notion, Google Calendar, and Trello.\n",
      "\n",
      "Task 1: Imagine that Pascaline is the new member joining your team.  Follow the below instructions and answer the question. \n",
      "\n",
      "On Google calendar:\n",
      "Access your Google Calendar.\n",
      "Create a new calendar specifically for \"Onboarding Meeting - Pascaline\"\n",
      "Schedule a weekly check in team meeting, and invite the new team member. The team member’s Email is: pascaline@10academy.org\n",
      "In the description part, add an important description of what that weekly meeting will be about in general. \n",
      "Set up reminders for that weekly team meeting. \n",
      "Take a screenshot of your Google Calendar showing the scheduled events. \n",
      "\n",
      "On Slack:\n",
      "Create a new Slack workspace named “Onboarding New Member”, and create 3 new channels, in addition to the ones which Slack auto-creates. \n",
      "Send Pascaline an invite link, inviting them to join that Slack workspace. \n",
      "Post a welcome message in the channel introducing the purpose of the slack workspace and its objectives. \n",
      "Initiate a discussion about their experience so far in your company and ask for their input.\n",
      "Take a screenshot of the Slack channel with the introductory message and discussion visible.\n",
      "\n",
      "On Notion:\n",
      "Set up a task board in Notion using the Kanban format. On this task board, you should list 5 key exercises you have completed for the training at 10 Academy in Week 0 and Week 1, along with the key feedback you have received from your tutors. \n",
      "Link your Notion task board to the Slack workspace you have created. You can do this using the Slack app directory. Please choose the channel that Pascaline has joined, to link your Notion account to. \n",
      "Using your Notion account, create a public page for the task view, and provide this link in the Slack channel. \n",
      "Take a screenshot of the Task board you created above. \n",
      "\n",
      "Trello:\n",
      "Create a new Trello board named \"Onboarding process\"\n",
      "Set up columns on the board for \"To Do,\" \"In Progress,\" \"Review,\" and \"Completed.\"\n",
      "Create task cards for the onboarding week and tasks in the \"To Do\" column. In your to do column you should have the following 3 tasks: Introduction to the company and job description, Company platform tour, Introduction to current projects. \n",
      "Move one task card to the \"In Progress\" column.\n",
      "Move another task card to the “Review” column.\n",
      "Take a screenshot of the Trello board with the task cards visible.\n",
      "\n",
      "After completing those tasks on Google calendar, slack, notion and trello, create a google slide or PPT with the Guide on how you did each step on each of those platforms, and add a final result screenshots (The ones you took after every task) at the end of each Guide. \n",
      "\n",
      "Note: \n",
      "The Guide should be clear that a new member, Pascaline, can follow to do the same tasks as you did.\n",
      "The google slides or PPT title should be “Guidance on Remote work Tools”. The slides  should be simple, clean and professional - bullet points are fine.  The goal would be for this slide deck to be ready to use in a real-world work environment. \n",
      "Use a maximum of 6 slides for this Task 1.\n",
      "\n",
      "Task 2: \n",
      "Write a Step-by-step guide showing your new members how to embed a new task in your Notion kanban board, and move it from backlog, to active to complete. Add the guide in the Google slide you created in Exercise 1. \n",
      "Note: Maximum slides for this second exercise is 3. \n",
      "\n",
      "Task 3:\n",
      "Write a brief guide explanation showing the new members how to add a new member to their workspace on Slack. Add the guide in the Google slide you created in Exercise 1. \n",
      "Note: Maximum slides for this third question is 1.\n",
      "\n",
      "Task 4: \n",
      "Provide a guide on how to embed apps into Notion, such as Google, Figma, or Youtube, focussing on those that you think would be useful to 10 Academy training.\n",
      "Note: Maximum slides for this third question is 1.\n",
      "\n",
      "Submission: On Tenx.\n",
      "For this exercise, you have been provided with links which will direct you to the information you need in order to complete the above exercise. Please note, however, that the exercise cannot be completed based on the information in these links alone.\n",
      "\n",
      "Usefulness in real life:\n",
      "This exercise prepares you for remote work, as you will have to create a realistic onboarding solution for possible future colleagues who have never worked remotely before. As more and more people start shifting to remote work completely, it will be important for you to understand the most common remote tools, how they work, and how to easily explain their uses to others\n",
      "\n",
      "Marking Rubric:\n",
      "\n",
      "Google Calendar Setup (40 points): You accurately created a new calendar and scheduled a weekly check-in meeting with reminders. Clear documentation with screenshots was provided.\n",
      "Slack Workspace Setup (10 points): You successfully created a new Slack workspace, invited new members, and introduced the workspace's objectives with an engaging discussion.\n",
      "Notion Task Board (10 points): You effectively set up a Notion task board with Kanban format, listed exercises and feedback, integrated it with Slack, and provided a public link within the Slack channel.\n",
      "Trello Board Setup (10 points): You created a Trello board with the required columns and task cards, correctly managed task cards, and provided a clear screenshot of the board.\n",
      "Google Slides Presentation (10 points): The Google Slides presentation was well-structured, clear, and professional. It included step-by-step guidance for each platform and final result screenshots.\n",
      "Task 2 - Notion Task Management Guide (20 points): The guide for Notion task management was clear and accurate, integrated into the Google Slides presentation.\n",
      "Task 3: Adding New Members to Slack (20 points): The guide for adding new members to Slack was clear, concise, and integrated into the Google Slides presentation.\n",
      "Task 4: The guide on how to embed apps into Notion. (20 points)\n",
      "\n",
      "\n",
      "\n",
      "File: W0 - Careers Exercise - CV Submission-day2.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 0\n",
      "Careers - Exercise 1\n",
      "\n",
      "CV\n",
      "\n",
      "First submission deadline: Tuesday, 9th April 2024, 8 pm UTC\n",
      "\n",
      "Second resubmission deadline: Saturday, 13th April 2024, 8pm UTC\n",
      "Exercise\n",
      "Submit your CV by carefully following the instructions and requirements\n",
      "listed below. \n",
      "\n",
      "The following link provides more information and tips on constructing a CV: CV writing tips.\n",
      "\n",
      "Requirements: \n",
      "1 page CV in PDF format \n",
      "\n",
      "Your email address, phone number, and address should be listed right at the top. \n",
      "\n",
      "Provide a 50-word summary of yourself. This concise introduction provides the hiring team with information about you, your key qualifications, accomplishments, and experience. It must be brief and pertinent to the job for which you are seeking. \n",
      "\n",
      "List all of your most important technical skills and soft skills.\n",
      "Be careful not to list too many skills. \n",
      "Limit yourself to skills most relevant to your application.\n",
      "Examples of technical skills are proficiency in Python, SQL, C++, etc.\n",
      "Examples of soft skills include Communication,  Teamwork, Problem-solving, Time management, Critical thinking, Decision-making and Organisational skills.   \n",
      "Consider how best to make this easy for an employer to skim and understand what you are capable of delivering, by organising into relevant sections.\n",
      "\n",
      "List your education in chronological order (starting with the most recent educational achievement attained).  For each educational experience, include the name and location of the institution, year(s) of study, expected date of completion (if applicable) and title or certificate attained. If there are more than 3 educational experiences, highlight only those which are relevant to the position you are applying for. These might include courses in Mathematics, design, algorithms, statistics, Data Science,etc. \n",
      "\n",
      "Use digits instead of spelled-out numbers where necessary.\n",
      "\n",
      "Using Bock’s rule, describe your experience well. \n",
      "\n",
      "See CV template example here: Sample CV Template\n",
      "\n",
      "Other Checklist Includes \n",
      "Accurate contact information (e.g.: include country code to your phone number)\n",
      "Include a link to an online portfolio that expands on your experiences, projects, achievements, etc. \n",
      "Ensure all links (LinkedIn, portfolio, email, etc.) are clickable\n",
      "Take note of international naming conventions (first name last name)\n",
      "Relevant and targeted experience \n",
      "Proofread the document to confirm there are no spelling mistakes\n",
      "Use a consistent and readable font type and size\n",
      "Do not include any extra fancy formatting\n",
      "Minimal use of colours\n",
      "Be clear and concise; keep your CV to 1 page, since recruiters may not have time to review more than 1 page. \n",
      "Saved and submitted as a PDF.\n",
      "\n",
      "Support, Meeting and Tutorials\n",
      "On Tuesday, 9th April 2024, there will be a tutorial for this exercise. Please get in touch with Pascaline Iyodusenga on Slack or during the tutorial session if you need assistance or have any queries. \n",
      "Marking Rubric\n",
      "Content Relevance and Clarity:\n",
      "Personal Information: Check if the CV includes the candidate's full name, phone number, email address, and physical address (optional).\n",
      "Professional Summary: Evaluate the professional summary is a 50 words brief description of themselves in relation to what they can do and concepts and tools they are familiar with. The professional summary should serves a an introduction to the trainee's CV and shows an overview of a trainees’ background as well career aspirations. \n",
      "Skills: Ensure that the CV lists relevant skills, both technical and soft skills.\n",
      "Work Experience: Verify the presence of detailed descriptions for each job position held, including job title, company name, dates of employment, and a concise overview of key responsibilities and achievements (quantify with data whenever possible). The list of experiences should be in choronological order.\n",
      "Education: Check if the CV includes relevant educational qualifications, a chronological list of degrees, including institution name, degree name, major/minor (if applicable), and graduation year. Note that Expected graduation date can be included if applicable.\n",
      "Licence & Certifications. This is optional, but check a if relevant certifications are listed in reverse-chronological order\n",
      "\n",
      "\n",
      "\n",
      "Professionalism & Formating \n",
      "Layout and Structure: Evaluate the CV's organization, including clear section headers (e.g., Education, Work Experience, Skills) and a logical flow of information.\n",
      "Font and Style: Check for consistency in font type, size, and formatting throughout the document.\n",
      "Spelling and Grammar: Identify and flag any spelling or grammatical errors, ensuring a polished final product.\n",
      "Length: Assess if the CV is appropriately concise while still providing sufficient detail, typically aiming for one to two pages in length.\n",
      "Professional Appearance: Look for the Overall layout and design that convey professionalism and attention to detail.\n",
      "\n",
      "\n",
      "Note: Individual feedback given.\n",
      "Usefulness in real life\n",
      "A good CV is the foundation of a successful career launch. A properly outlined CV shows both your past accomplishments and your potential for future success.\n",
      "Submission\n",
      "Upload a PDF on Tenx.\n",
      "\n",
      "\n",
      "File: groups.docx\n",
      "Extracted Text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Week 1 Challenge.docx\n",
      "Extracted Text:\n",
      "10 Academy Cohort B - Weekly Challenge: Week 1 \n",
      "User Analytics in the Telecommunication Industry - Overview\n",
      "Situational Overview (Business Need)\n",
      "You are working for a wealthy investor that specialises in purchasing assets that are undervalued.  This investor’s due diligence on all purchases includes a detailed analysis of the data that underlies the business, to try to understand the fundamentals of the business and especially to identify opportunities to drive profitability by changing the focus of which products or services are being offered.\n",
      "\n",
      "Your last role with this investor saw you do a rich analysis of a delivery company and you helped to identify that delivery to university students was the most profitable route to follow, and your analysis helped the investor purchase this delivery company and ramp up profits by 25% within 6 months through focussing on the most profitable aspect of the business.  This was driven by university students always being hungry, awake at all hours, willing to purchase from a limited food menu and tending to live within a small geographical area.\n",
      "\n",
      "The investor is interested in purchasing TellCo, an existing mobile service provider in the Republic of Pefkakia.  TellCo’s current owners have been willing to share their financial information but have never employed anyone to look at their data that is generated automatically by their systems.\n",
      "\n",
      "Your employer wants you to provide a report to analyse opportunities for growth and make a recommendation on whether TellCo is worth buying or selling.  You will do this by analysing a telecommunication dataset that contains useful information about the customers & their activities on the network. You will deliver insights you managed to extract to your employer through an easy to use web based dashboard and a written report. \n",
      "Data\n",
      "We have sourced the data from a month's aggregation of xDR records. \n",
      "The description for attributes can be found here\n",
      "This data should be extracted from a PostgreSQL database, and we've included both the database schema and the corresponding SQL file here.  \n",
      "Learning Outcomes\n",
      "Understanding and reasoning the business context. Thinking about suitable analysis that matches the business need. Thinking about clients and their interests.\n",
      "Understanding the data provided and extract insight. You will have to explore different techniques, algorithms, statistical distributions, sampling, and visualisation techniques to gain insight.\n",
      "Understand the data structure and algorithms used in EDA and machine learning pipelines\n",
      "Building a dashboard to explore data as well as to communicate insight. Advanced use of modules such as plotly, seaborn, matplotlib etc. to build descriptive visualisations. Reading through the modules documentation to expand your skill set.\n",
      "Thinking about statistical distributions, sampling, bias, overfitting, correlations.\n",
      "Modular and object oriented python code writing. Python package building. \n",
      "Competency Mapping\n",
      "The tasks you will carry out in this week’s challenge will contribute differently to the 11 competencies 10 Academy identified as essential for job preparedness in the field of Data Engineering, and Machine Learning engineering. The mapping below shows the change (lift) one can obtain through delivering the highest performance in these tasks.   \n",
      "\n",
      "\n",
      "\n",
      "Team\n",
      "Tutors: \n",
      "Yabebal\n",
      "Emtinan \n",
      "Rehmet\n",
      "Natnael\n",
      "\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points for the leaderboard score.\n",
      "\n",
      "Visualisation - quality of visualisations, understandability, skimmability, choice of visualisation\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in future this will be CICD\n",
      "Innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine Learning Engineer toolbox.\n",
      "Group Work Policy\n",
      "This submission is to be done individually. Collaborative learning is encouraged, but each person must have his or her own submissions.\n",
      "Late Policy\n",
      "Our goal is to prepare successful trainees for the work and submitting late, when given enough notice, shouldn’t be necessary.\n",
      "\n",
      "For interim submissions, those submitted 1-6 hours late will receive a maximum of 50% of the total possible grade.  Those submitted >6 hours late may receive feedback, but will not receive a grade.\n",
      "\n",
      "For final submissions, those submitted 1-24 hours late, will receive a maximum of 50% of the total possible grade. Those submitted >24 hours late may receive feedback, but will not receive a grade.\n",
      "\n",
      "When calculating the leaderboard score:\n",
      "From week 4 onwards, your lowest week’s score will not be considered.\n",
      "From week 8 onwards, your two lowest weeks’ scores will not be considered. \n",
      "\n",
      "Instructions\n",
      "\n",
      "At the end of this week you are expected to to have a complete project that has\n",
      "Reusable code for data preparation and cleaning.\n",
      "Estimated code complexity (running time and memory size order of magnitude estimate) for the key part of your code. To do so you would need to explicitly identify and profile the data structures and algorithms in your code.\n",
      "Code connected using scikit pipeline or other form of chaining multiple EDA steps  \n",
      "Beautiful and insightful Streamlit dashboard that shows your findings.\n",
      "SQL database as feature store which can be used to store selected features for dashboard visualisation and model training.\n",
      "Your project folder should mirror as close as possible the example here. In particular\n",
      "Code is installable via pip\n",
      "Has unit tests with good test coverage\n",
      "Has CI/CD setup - using Github Actions\n",
      "Has Dockerfile to build it as docker image\n",
      "Python codes are written in the style and structure of Streamlit python source code - reading and understanding source codes of well-known open source packages will help you learn advanced python programming.\n",
      "\n",
      "The global objective is divided into 4 sub-objectives \n",
      "User Overview analysis\n",
      "User Engagement analysis\n",
      "User Experience analysis\n",
      "User Satisfaction analysis\n",
      "Task 1 - Report on Streamlit understanding\n",
      "Streamlit Source Code Overview: Provide a one-page comprehensive overview of Streamlit source code structure. Your report should emphasise on \n",
      "How the python source code is structured\n",
      "The different advanced python programming techniques used in the code base \n",
      "How unit and integration tests are written\n",
      "What extra packages are used - check the requirements.txt file\n",
      "How doc strings, logging,  and error handling  are written\n",
      "How @property and other builtin and custom decorators are used in the source code\n",
      "Any other observations that interested you.\n",
      "Identifying the data structure and algorithm used in the key component of the data loading part of the streamlit package. \n",
      "Task 2 - User Overview analysis \n",
      "\n",
      "The lifeblood of any business is its customers. Businesses are always finding ways to better understand their customers so that they can provide more efficient and tailored solutions to them. \n",
      "Exploratory Data Analysis is a fundamental step in the data science process. It involves all the processes used to familiarise oneself with the data and explore initial insights that will inform further steps in the data science process.\n",
      "\n",
      "It is always better to explore each data set using multiple exploratory techniques and compare the results. The goal of this step is to understand the dataset, identify the missing values & outliers if any using visual and quantitative methods to get a sense of the story it tells. It suggests the next logical steps, questions, or areas of research for your project.\n",
      "\n",
      "Start by applying your streamlite understanding to prepare your code with modular design, best practices in coding.\n",
      "\n",
      "For the actual telecom dataset, you‘re expected to conduct a full User Overview analysis & the following sub-tasks are your guidance: \n",
      "Start by identifying the top 10 handsets used by the customers.\n",
      "Then, identify the top 3 handset manufacturers\n",
      "Next, identify the top 5 handsets per top 3 handset manufacturer\n",
      "Make a short interpretation and recommendation to marketing teams\n",
      "\n",
      "In telecommunication, CDR or Call Detail Record is the voice channel and XDR is the data channel equivalent. So here, consider xDR as data sessions Detail Record. In xDR, user behaviour can be tracked through the following applications:  Social Media, Google, Email, Youtube, Netflix, Gaming, Other. \n",
      " \n",
      "Task 2.1 - Your employer wants to have an overview of the users’ behaviour on those applications.   \n",
      "Aggregate per user the following information in the column  \n",
      "number of xDR sessions\n",
      "Session duration\n",
      "the total download (DL) and upload (UL) data\n",
      "the total data volume (in Bytes) during this session for each application\n",
      "\n",
      "Task 2.2 - Conduct an exploratory data analysis on those data & communicate useful insights. Ensure that you identify and treat all missing values and outliers in the dataset by replacing by the mean of the corresponding column.\n",
      "You’re expected to report about the following using  python script and slide  :\n",
      "Describe all  relevant variables and associated data types (slide). \n",
      "Analyze the basic metrics (mean, median, etc) in the Dataset (explain) & their importance for the global objective.\n",
      "Conduct a Non-Graphical Univariate Analysis by computing dispersion parameters for each quantitative variable and provide useful interpretation. \n",
      "Conduct a Graphical Univariate Analysis by identifying the most suitable plotting options for each variable and interpret your findings.\n",
      "Bivariate Analysis – explore the relationship between each application & the total DL+UL data using appropriate methods and interpret your findings. \n",
      "Variable transformations – segment the users into top five decile classes based on the total duration for all sessions and compute the total data (DL+UL) per decile class. \n",
      "Correlation Analysis – compute a correlation matrix for the following variables and interpret your findings: Social Media data, Google data, Email data, Youtube data, Netflix data, Gaming data, Other data \n",
      "Dimensionality Reduction – perform a principal component analysis to reduce the dimensions of your data and provide a useful interpretation of the results (Provide your interpretation in four (4) bullet points-maximum). \n",
      "Task 3 - User Engagement analysis\n",
      "As telecom brands are the data providers of all online activities, meeting user requirements, and creating an engaging user experience is a prerequisite for them. Building & improving the QoS (Quality of Service) to leverage the mobile platforms and to get more users for the business is good but the success of the business would be determined by the user engagement and activity of the customers on available apps. \n",
      "\n",
      "In telecommunication, tracking the user activities on the database sessions is a good starting point to appreciate the user engagement for the overall applications and per application as well. If we can determine the level of engagement of a random user for any application, then it could help the technical teams of the business to know where to concentrate network resources for different clusters of customers based on the engagement scores.\n",
      "\n",
      "In the current dataset you’re expected to track the user’s engagement using the following engagement metrics: \n",
      "sessions frequency \n",
      "the duration of the session \n",
      "the sessions total traffic (download and upload (bytes))\n",
      "\n",
      "Task 3.1 - Following the above, perform the following tasks:\n",
      "Aggregate the above metrics per customer id (MSISDN) and report the top 10 customers per engagement metric \n",
      "Normalize each engagement metric and run a k-means (k=3) to classify customers in three groups of engagement. \n",
      "Compute the minimum, maximum, average & total non-normalized metrics for each cluster. Interpret your results visually with accompanying text explaining your findings.\n",
      "Aggregate user total traffic per application and derive the top 10 most engaged users per application\n",
      "Plot the top 3 most used applications using appropriate charts.  \n",
      "Using k-means clustering algorithm, group users in k engagement clusters based on the engagement metrics: \n",
      "What is the optimized value of k (use elbow method for this)?  \n",
      "Interpret your findings. \n",
      "\n",
      "Task 4 - Experience Analytics\n",
      "The Telecommunication industry has experienced a great revolution since the last decade. Mobile devices have become the new fashion trend and play a vital role in everyone's life. The success of the mobile industry is largely dependent on its consumers. Therefore, it is necessary for the vendors to focus on their target audience i.e. what are the needs and requirements of their consumers and how they feel and perceive their products. Tracking & evaluation of customers’ experience can help the organizations to optimize their products and services so that it meets the evolving user expectations, needs, and acceptance.\n",
      "\n",
      "In the telecommunication industry, the user experience is related, most of the time, to network parameter performances or the customers’ device characteristics.  \n",
      "\n",
      "In this section, you’re expected to focus on network parameters like TCP retransmission, Round Trip Time (RTT), Throughput, and the customers’ device characteristics like the handset type to conduct a deep user experience analysis. The network parameters are all columns in the dataset. The following questions are your guidance to complete the task. For this task you need a python script that includes all solutions to tasks.\n",
      "\n",
      "Task 4. 1 - Aggregate, per customer, the following information (treat missing & outliers by replacing by the mean or the mode of the corresponding variable):\n",
      "Average TCP retransmission\n",
      "Average RTT\n",
      "Handset type\n",
      "Average throughput\n",
      "Task 4.2 - Compute & list 10 of the top, bottom and most frequent:\n",
      "TCP values in the dataset. \n",
      "RTT values in the dataset.\n",
      "Throughput values in the dataset.\n",
      "Task 4.3 - Compute & report:\n",
      "The distribution of the average throughput  per handset type and provide interpretation for your findings.\n",
      "The average TCP retransmission view per handset type and provide interpretation for your findings.\n",
      "Task 4.4 - Using the experience metrics above, perform a k-means clustering (where k = 3) to segment users into groups of experiences and provide a brief description of each cluster. (The description must define each group based on your understanding of the data)\n",
      "Task 5 - Satisfaction Analysis\n",
      "Assuming that the satisfaction of a user is dependent on user engagement and experience, you’re expected in this section to analyze customer satisfaction in depth. The following tasks will guide you: \n",
      "\n",
      "Based on the engagement analysis + the experience analysis you conducted above ,\n",
      "Task 5. 1 - Write a python program to assign:\n",
      "engagement score to each user. Consider the engagement score as the Euclidean distance between the user data point & the less engaged cluster (use the first clustering for this) (Euclidean Distance)\n",
      "experience score to each user. Consider the experience score as the Euclidean distance between the user data point & the worst experience’s cluster. \n",
      "Task 5.2 - Consider the average of both engagement & experience scores as  the satisfaction score & report the top 10 satisfied customer \n",
      "Task 5.3 - Build a regression model of your choice to predict the satisfaction score of a customer. \n",
      "Task 5.4 - Run a k-means (k=2) on the engagement & the experience score . \n",
      "Task 5.5 - Aggregate the average satisfaction & experience score per cluster. \n",
      "Task 5.6 - Export your final table containing all user id + engagement, experience & satisfaction scores in your local MySQL database. Report a screenshot of a select query output on the exported table. \n",
      "Task 5.7 Model deployment tracking- deploy the model and monitor your model. Here you can use Docker or other MlOps tools which can help you to track your model’s change.  Your model tracking report includes code version, start and end time, source, parameters, metrics (loss convergence) and artefacts or any output file regarding each specific run. (CSV file, screenshot)\n",
      "\n",
      " \n",
      "\n",
      "Tutorials Schedule\n",
      "Overview\n",
      "Monday: Understanding week 1 challenge and Data Pre-processing\n",
      "Tuesday: Data Exploration and Insights communication\n",
      "Wednesday: Data modelling\n",
      "Thursday: Dashboard Development\n",
      "\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Monday: Data Pre-processing\n",
      "Here, students will understand this week's challenge and learn how to prepare data for modelling.\n",
      "\n",
      "Introduction to week1 challenge(YF)\n",
      "Going through the Streamlit source code (Rehmet)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding advanced code base\n",
      "Efficient and modular coding technique\n",
      "Understanding data in DB – connecting with DB \n",
      "Ability to help others \n",
      "Tuesday: EDA\n",
      "Here, students will learn how to understand data and communicate insights from the data.\n",
      "\n",
      "Data Extraction, Cleaning, Transforming and formatting using modular python (Emtinan)\n",
      "Working with PostgreSQL DB using SQL, Pandas, and SQLAlchemy (Emtinan And Rehmet)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Proactivity to self-learn - sharing references\n",
      "Intermediate to advanced SQL techniques \n",
      "Data Understanding and Exploration\n",
      "Wednesday: Data Modelling\n",
      "Here, students will learn how to model the data. \n",
      "\n",
      "Modelling (Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Modelling\n",
      "MLOps\n",
      "Proactivity to self-learn - sharing references\n",
      "Thursday: Dashboard Development\n",
      "Here, students will learn how to visually communicate data and insights using dashboards. \n",
      "\n",
      "Dashboard development (Rehmet)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Design Thinking\n",
      "Dashboard Design\n",
      "Proactivity to self-learn - sharing references\n",
      "\n",
      "\n",
      "Deliverables\n",
      "MAKE SURE YOUR SUBMISSION IS IN A PDF FORMAT WHEN ASKED TO UPLOAD A WORD/PPT FILE.\n",
      "Interim Submission (Due Wednesday 24.04.2024 2000 UTC)\n",
      "A PDF containing concise and comprehensive descriptions of the key data structure and algorithm you used in your code to address Task 2 and Task 3 in 1 or 2 pages. If you use pandas, scikit-learn etc. in your code, report on the data structure and algorithm used in the part of those packages you used. Comment on how long (time) and how much memory (RAM size) will it take your code if the data size grows by 10x, 1000x, 100000x, 1000000x.  Comment on the suitability of the data structure and algorithm you used for large data sets.\n",
      "Link to your GitHub repository. \n",
      "Feedback\n",
      "You may not receive detailed comments on your interim submission, but will receive a grade.\n",
      "Final Submission (Due Sat 27.04.2024 2000 UTC)\n",
      "Report for Task 1 - Streamlit source code review (1-3 pages).\n",
      "Summarise your findings from Task 2 to 5 (Customers Overview, User Engagement, Experience and Satisfaction Analysis).  Your employer demands no more than 30 slides - 1hr presentation.\n",
      "  \n",
      "Ensure that you include a title slide in the beginning and a reference slide at the end.\n",
      "Ensure that you make a recommendation to your employer on the growth potential of the company (positive or negative) based on the data.  \n",
      "Ensure that you share the data and slides with justifying your recommendation with data and graphs\n",
      "Ensure that you outline the limitations of your analysis.\n",
      "Ensure that you make a recommendation on whether your employer should purchase this company.\n",
      "\n",
      "A Github link to all your codes and a screenshot of your dashboard. Make sure to include as many screen shots as possible so that we are able to see all the functionality of your dashboard - your evaluation for the dashboard wireframe and functionality will be entirely based on the screenshots (or deployed version) you submitted. Make an effort to deploy your dashboard live in Streamlit Cloud Heroku, Netlify or any one of the free web app hosting services you can find here. \n",
      "\n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "Leaderboard for the week\n",
      "There are 100 points available for the week.\n",
      "\n",
      "20 points - community growth and peer support.  \n",
      "This includes supporting other learners by answering questions (Slack), asking good questions (Slack), participating (not only attending) daily standups (GMeet) and sharing links and other learning resources with other learners.\n",
      "\n",
      "25 points - presentation and reporting.\n",
      "\t5 points - interim submission\n",
      "\t\t2 - Evidence of clear understanding of the business context and data\n",
      "\t\t2 - Evidence of clear plan to complete the project and what is done\n",
      "       till date\n",
      "\t\t1 - Style of report \n",
      "20 points for the final submission.  This is measured through:\n",
      "4 - Style and quality of report (e.g. error free, font and format consistency)\n",
      "4 - Creative articulation, clarity of content, and objective communication  \n",
      "10 - Clear sections on \n",
      "1 - objectives of the project and the intended business value\n",
      "1 - data size, type, format and other details (e.g. missing values) \n",
      "1 - methods and algorithms used\n",
      "1 - details on pipeline, automation, (code, data, model) versioning\n",
      "2 - well produced supporting figures and graphics\n",
      "2 - result and discussion\n",
      "2 - summary of what has been achieved, its implication, and weather\n",
      "     objectives of the project are met or not and why   \n",
      "2 - Balance between being ‘full of information’ and ‘easy to understand’ \n",
      "\n",
      "20 points - dashboard code, screenshot, and cloud deployment\n",
      "\t10 points - screenshot & dashboard code submission \n",
      "\t\t2 - functionality of dashboard to address business need\n",
      "\t\t2 - multiple screenshot or live access \n",
      "\t\t2 - proof of wireframe design\n",
      "\t\t2 - CI/CD deployment\n",
      "\t10 points - dashboard code and deployment \n",
      "2 - Dockerfile to build the dashboard \n",
      "2 - Github actions and unit test\n",
      "2 - Quality and structure of code\n",
      "2 - incorporating javascript/css to enhance dashboard\n",
      "2 - sql schema of feature store database\n",
      " \n",
      "40 points - data analysis and coding\n",
      "\t15 points - interim submission\n",
      "\t\t4 - Preprocessing &  EDA  \n",
      "2 - Generating novel plots - insightful and quality plots\n",
      "2 - Frequent github commits, multiple branching, and pull request \n",
      "3 - Modularity and quality of code (including readability) \n",
      "4 - use of scikit pipeline or other pipeline approach\n",
      "\n",
      "30 points - final submission\n",
      "\t10 -  Depth of preprocessing &  EDA\n",
      "\t5   - Pipeline driven analysis \n",
      "5   - plots and notebook - insightful plots and well commented sections  \n",
      "6   - Advanced github use, modularity, and quality of code \n",
      "4   - Github actions and unit test \n",
      "\n",
      "\n",
      "References\n",
      "General references\n",
      "Exploratory Data Analysis In Python\n",
      "Non Graphical Univariate Analysis 1\n",
      "Non Graphical Univariate Analysis 2\n",
      "Univariate and Bivariate Analysis\n",
      "How to define an outlier\n",
      "How to Correlation Analysis\n",
      "How to do PCA (Video)\n",
      "Define telecoms QoS\n",
      "An Oracle Data Science Case Study in Telecom\n",
      "https://www.statology.org/deciles-in-python/\n",
      "Use cases and challenges in telecom big data analytics paper (PDF) Use cases and challenges in telecom big data analytics\n",
      "https://github.com/10-Academy-Self-Learning-Resources/Data-Understanding\n",
      "https://github.com/10-Academy-Self-Learning-Resources/DataVisualization\n",
      "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\n",
      "https://strategyanalytics.medium.com/pandas-read-excel-removed-support-for-xlsx-files-426e4acfde89\n",
      "https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html\n",
      "Design\n",
      "App Layout & Style Tips | Designing Apps for User (Part II) (streamlit.io)\n",
      "Marvel | Create your free account (marvelapp.com)\n",
      "\n",
      "\n",
      "File: Teamwork.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 5\n",
      "\n",
      "Careers - Exercise 2\n",
      "\n",
      "Teamwork\n",
      "\n",
      "Due Date: June 1st , 2024. 8:00 PM UTC\n",
      "\n",
      "\n",
      "Introduction\n",
      "\n",
      "Working as a team is an essential aspect of success in many fields, especially in the dynamic and complex world of data and AI engineering. Effective teamwork brings together individuals with unique skills, perspectives, and ideas, creating a powerful force for innovation and problem-solving.\n",
      "\n",
      "In your future careers as data, ML, and AI engineers, you will likely collaborate with various experts, including software developers, data scientists, project managers, and domain specialists. Embracing teamwork will enable you to tackle complex projects, share knowledge, and achieve results that exceed what any individual could accomplish alone. \n",
      "\n",
      "Through this exercise, you will;\n",
      "Explore the fundamentals of teamwork.\n",
      "Reflect on your collaborative experiences.\n",
      "Develop insights into maximizing team potential. \n",
      "\n",
      "Remember, employers highly value individuals who can work effectively in a team, contribute positively to the group dynamic, and inspire those around them.\n",
      "\n",
      "\n",
      "Exercise\n",
      "During weeks 3-4 at 10 Academy, you worked on a group work challenge to build a Redash chatbot add-on. For this exercise, you are required to reflect on your team’s participation in tackling the challenge, your experiences, and your contributions to the final team report/project.\n",
      "\n",
      "Note: You can choose to use any of the team projects from wk 3-6.\n",
      "\n",
      "This reflective exercise is designed to assess your team's performance and collaboration. By evaluating your past experiences, you can gain valuable insights into your team's strengths and areas for improvement, which will ultimately enhance your future project undertakings.\n",
      "\n",
      "\n",
      "Note: There are no penalties for honest reflections. Your feedback is important as it helps foster a collaborative and growth-oriented mindset within the team and beyond.\n",
      "\n",
      "\n",
      "\n",
      "Questions to reflect on:\n",
      "1. Roles, Distributions, and Contributions of Team Members\n",
      "Describe the specific roles and responsibilities of each team member in the project. \n",
      "What unique skills, expertise, or perspectives did they bring to the team? How did these contributions benefit the project’s outcome?\n",
      "Were there any imbalances in the distribution of tasks? If so, how did this affect the team’s dynamics and overall performance?\n",
      "2. Communication within the team\n",
      "What communication strategies did your team employ to stay aligned? For example, did you have daily meetings, and communicate frequently on Slack, or Github?\n",
      "How effective were these strategies in ensuring everyone was on the same page? Were there any challenges or miscommunications, and if so, how were they addressed?\n",
      "Reflect on the frequency and quality of your team’s communication. Were there any improvements or adjustments made throughout the project?\n",
      "3. Balancing strengths and weaknesses of teammates\n",
      "How did your team identify and address the strengths and weaknesses of individual members? For example, did you have a discussion about preferences and challenges during your initial meeting?\n",
      "Were tasks distributed considering varying skills within your team that played to every individual strengths? Were there opportunities for skill development in areas of weakness, and if so, how were these facilitated? \n",
      "4. Challenges and conflicts and how they fixed them\n",
      "What challenges arose within your team? For example, were there any disagreements, scheduling issues, or unexpected obstacles?\n",
      "Describe the strategies employed to resolve these challenges effectively. How did your team adapt and find solutions?\n",
      "If there were any unresolved challenges, reflect on why they persisted and propose potential solutions for future projects.\n",
      "5. Reflect on their team’s work\n",
      "Are you satisfied with the overall outcome of your previous group project? Explain why, providing specific examples of factors that contributed to your success or shortcomings. \n",
      "What insights have you gotten from this reflective process?\n",
      "How can these insights be applied to improve your team’s dynamics, communication, and collaboration in future projects?\n",
      "\n",
      "Instructions for submission:\n",
      "Each team member should submit their reflective report individually, ensuring confidentiality in their responses.\n",
      "\n",
      "As a team, come together to discuss the common themes, insights, and areas for improvement that emerged from your reflections.\n",
      "\n",
      "Collaboratively create an action plan, outlining specific steps and strategies to enhance your team's performance in your current team project. This plan should be concise, and practical, and reflect your collective commitment to continuous improvement.\n",
      "\n",
      "\n",
      "\n",
      "Deliverables\n",
      "Reflective report\n",
      "\n",
      "Each team member will submit a reflective report answering the questions above. The report should be structured according to the topics provided.\n",
      "\n",
      "Action Plan\n",
      "\n",
      "As a team, you will collectively create an action plan based on your reflections. This plan will outline specific strategies and improvements for your next group project, ensuring a more efficient and effective collaboration. \n",
      "\n",
      "\n",
      "\n",
      "Due Date:7\n",
      "Reflective slides report and action plan: June 1st 8 PM UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: Asking Good Questions Challenge - W5 - cB.docx\n",
      "Extracted Text:\n",
      "\n",
      "10 Academy cB : Week 5\n",
      "\n",
      "Careers Exercise \n",
      "\n",
      "Asking Good Questions \n",
      "\n",
      "Deadline: 25th May, 2024. 8PM UTC\n",
      "\n",
      "Introduction\n",
      "Understanding how to ask the right questions is crucial in any professional setting. This skill enhances your ability to gather essential information, solve problems effectively, and engage meaningfully with colleagues and stakeholders. The 'right' question often is not about finding a direct answer but about exploring possibilities and understanding deeper undercurrents of business operations. \n",
      "\n",
      "In this challenge, you will analyze the given various workplace-related scenarios and decide whether further questions are needed. If questioning is required, you must formulate specific, strategic questions that would be appropriate to ask in each situation.\n",
      "\n",
      "Objective:\n",
      "The goal is to develop the trainees' ability to discern when additional information is necessary and to craft questions that lead to clarity, facilitate decision-making, or reveal deeper insights into the issues presented.\n",
      "\n",
      "\n",
      "Instructions:\n",
      "The scenarios below are made of:\n",
      "\n",
      "Scenarios where you need to ask further questions to understand the situations and actions that need to be taken. \n",
      "Scenarios where you may be curious to know more even though there are no actions that need to be taken. \n",
      "Scenarios where the information given are satisfying and you don’t need to ask any further questions. \n",
      "\n",
      "\n",
      "Task\n",
      "For each scenario provided below, answer the following:\n",
      "\n",
      "Determine whether further questions need to be asked to better understand the situation and to assist in decision-making, or to satisfy your curiosity, or not.\n",
      "\n",
      "If you decide that no further questions are needed, give us 3 reasons why. \n",
      "\n",
      "If you decide that further action questions or curiosity questions are needed, write down 5 specific questions you would ask. Aim to formulate questions that are clear, purposeful, and relevant to the context of the scenario.\n",
      "\n",
      "\n",
      "NOTE: DO NOT MAKE ANY ASSUMPTIONS IN THE SCENARIOS. Consider the information provided as the only information you have to make your decision.\n",
      "\n",
      "\n",
      "Scenarios\n",
      "\n",
      "Scenario 1:\n",
      "During a team meeting, it is announced that your objective is to enhance the performance of an existing machine learning model. The meeting ended with the team discussion only focusing on general goals for improving model operations within the next quarter. \n",
      "\n",
      "Scenario 2:\n",
      "The HR department sends out a memo detailing a new company policy on remote work, which includes eligibility criteria, steps for application, tools provided by the company, expectations for remote workers, and resources for technical support. The memo is thorough and includes a FAQ section that addresses common queries and concerns. \n",
      "\n",
      "Scenario 3:\n",
      "Your team receives an email about upcoming IT maintenance that will affect several systems you use regularly. The email lists the systems but does not mention the duration of the downtime and other necessary informations.\n",
      "\n",
      "Scenario 4:\n",
      "You are assigned to integrate a new natural language processing (NLP) feature into an existing application. The project brief describes the end goals for user interaction improvements and enhanced data analysis capabilities through the NLP feature.  \n",
      "\n",
      "\n",
      "\n",
      "Scenario 5:\n",
      "You are given access to a well-documented API for a machine learning model, including detailed usage examples, a list of endpoints, expected input/output formats, and error handling instructions. The documentation also includes a changelog with updates from previous versions. \n",
      "\n",
      "Scenario 6:\n",
      "The project lead shares a detailed plan for deploying a new data pipeline. The plan includes a timeline, resource allocation, tools to be used, and a step-by-step guide for the deployment process. Additionally, there's a support contact list and a troubleshooting section addressing common issues from past deployments.\n",
      "\n",
      "Scenario 7:\n",
      "On your first day, you're given a rapid tour of the office and briefly introduced to different digital tools and platforms that the company uses—each with distinct roles in operations, communication, and project management. Your orientation session includes a quick overview of each tool by various team members, but it lacks in-depth training or guidance on how to effectively use these tools in your specific role. You're expected to start working on projects from the next day, which involves interacting with many of these platforms.\n",
      "\n",
      "Scenario 8:\n",
      "You are tasked with organizing a small departmental conference. The administration has provided you with a conference plan, session plan, timelines, clear budget, a list of preferred vendors for catering and equipment, past event feedback to guide your planning, and a checklist of logistical steps to follow, approved by the previous event coordinators.\n",
      "\n",
      "Scenario 9:\n",
      "You're deeply involved in several critical tasks: rolling out a new software system, updating major data tools, organizing a company-wide training session on data security, finalizing quarterly performance reports, and overseeing the integration of a newly acquired company's technology into existing systems. With each project demanding thorough attention and varying skills, from technical knowledge to project management, the combined pressure is immense. Recognizing the need to maintain high standards of work, you're considering the best approach to seek additional help.\n",
      "\n",
      "Scenario 10:\n",
      "The company has just announced that it will be buying another company to become bigger and offer more products. When one company buys another, they usually have to combine their teams and figure out the best way to work together. This process can affect many parts of the company, from the jobs people do to the new opportunities that might come up. During a brief meeting, the leaders explained that this acquisition means our company will have more employees and a broader range of products. They talked about how this would help us compete better in the market. \n",
      "\n",
      "\n",
      "Submission\n",
      "Make a PPT / Google slides with 12 slides maximum and convert it into PDF, then submit on Tenx. \n",
      "\n",
      "Usefulness in real life\n",
      "This exercise allows you to develop the art of being curious and the skill of asking questions. These two concepts are vital skills necessary for navigating the world of work and in your personal life. \n",
      "\n",
      "\n",
      "Rubrics:\n",
      "Scenario 1 (10 points): You need to decide whether further questions are necessary or not necessary to understand the situation and improve the model's performance. Grading will focus on the clarity of your decision and reasoning, and the formulation of good questions if required. \n",
      "\n",
      "Scenario 2  (10 points):Assess whether additional questions are needed or not needed to understand the new remote work policy fully. Grading will consider the completeness of your analysis, the justification for not needing further questions, or the relevance and clarity of the questions if you decide more information is needed.\n",
      "\n",
      "Scenario 3  (10 points): Evaluate whether additional questions are required or not required to gather necessary information about the upcoming IT maintenance. Grading will focus on the clarity of your decision-making process and the formulation of relevant questions if deemed necessary.\n",
      "\n",
      "Scenario 4  (10 points): Decide if further questions are needed or not needed to understand the scope and objectives of integrating the NLP feature. Grading will consider the justification provided for your decision and the clarity and relevance of any additional questions proposed.\n",
      "\n",
      "Scenario 5  (10 points): Assess whether additional questions are necessary or not necessary to fully comprehend the provided API documentation. Grading will focus on the completeness of your analysis and the formulation of purposeful questions if required.\n",
      "\n",
      "Scenario 6  (10 points): Analyze if further questions are needed or not needed to understand the deployment plan for the new data pipeline. Grading will consider the clarity of your reasoning and the effectiveness of any proposed questions to gain additional insights.\n",
      "\n",
      "Scenario 7  (10 points): Determine whether additional questions are required to address the lack of in-depth training on digital tools during orientation. Grading will focus on the thoroughness of your analysis and the formulation of clear and relevant questions to enhance understanding.\n",
      "\n",
      "Scenario 8  (10 points): Evaluate if further questions are necessary or not necessary to organize the departmental conference effectively. Grading will consider the justification provided for your decision and the clarity and relevance of any additional questions proposed. \n",
      "\n",
      "Scenario 9  (10 points): Analyze whether additional help is needed or not needed to manage multiple critical tasks effectively. Grading will focus on the clarity of your reasoning and the formulation of purposeful questions or strategies for seeking assistance if deemed necessary.\n",
      "\n",
      "Scenario  10  (10 points): Determine if further questions are needed or not needed to understand the implications of the company acquisition announcement. Grading will consider the completeness of your analysis and the formulation of clear and relevant questions to gain insights into the situation.\n",
      "\n",
      "\n",
      "\n",
      "File: How to use Tenx.docx\n",
      "Extracted Text:\n",
      "How to use Tenx\n",
      "\n",
      "Welcome to tenx, the platform designed specifically for trainees enrolled in 10 Academy's online education. This guide aims to assist you in navigating through the essential steps to effectively utilize the features and functionalities of tenx.\n",
      "Logging In\n",
      "Begin your journey by visiting the login page here. Enter the email you used to register for 10 Academy as both the username and password into the provided fields.\n",
      "\n",
      "After, make sure to hit ‘forgot password’ to reset your login credentials, reset link will be sent to your email.\n",
      "\n",
      "If you do not have login info, contact cohort manager Makida Shimeles.\n",
      "\n",
      "Resetting Your Password\n",
      "\n",
      "Upon login, expect a notification stating that an email has been sent to facilitate a password change. Head to your email inbox and open the email you received from 10 Academy.\n",
      "\n",
      "Inside the email, you will find a link designed for resetting your password. Click on this link to proceed.\n",
      "\n",
      "You'll be directed to a new page where you can input your desired new password. Enter it and confirm by typing it again.\n",
      "\n",
      "\n",
      "\n",
      "Accessing Your Dashboard\n",
      "\n",
      "Re-login using your newly updated password here. Once logged in, your personalized dashboard awaits you.\n",
      "\n",
      "Explore the left sidebar of your dashboard to find various links leading to different functionalities. Discover sections such as challenges, performance leaderboard, assignments, and more.\n",
      "\n",
      "\n",
      "Submitting Assignments\n",
      "\n",
      "To submit your assignments, navigate to the 'Assignments' section through the sidebar. Choose the specific assignment you wish to complete.\n",
      "\n",
      "\n",
      "Follow the prompts and instructions provided within the assignment section to submit your work as requested.\n",
      "\n",
      "\n",
      "\n",
      "File: Payment Processing Manual_.docx\n",
      "Extracted Text:\n",
      "\n",
      "\n",
      "Payment Processing Manual for 10 Academy Tuition Fees\n",
      "\n",
      "This manual provides detailed instructions for making tuition fee payments using various methods, including PayPal, US Bank Transfer, Nigerian Bank Transfer, Ethiopian Bank Transfer, International Bank Transfer, and Credit Card Transfer. Please follow the steps carefully for successful processing.\n",
      "        PayPal Payment Process\n",
      "Go to 10 Academy's PayPal profile here.\n",
      "Log in to your PayPal account.\n",
      "Enter the amount of the tuition fee and select the currency.\n",
      "Review the details and click \"Send.\"\n",
      "        US Bank Transfer Process\n",
      "Beneficiary Bank Details\n",
      "\n",
      "Beneficiary Name: 10 Academy Corp\n",
      "Account Number: 9801172556\n",
      "Type of Account: Checking\n",
      "Beneficiary Address: 1450 El Camino Real, 208, Santa Clara, CA 95050\n",
      "\n",
      "Receiving Bank Details\n",
      "\n",
      "ABA Routing Number: 084106768\n",
      "Bank Name: Evolve Bank & Trust\n",
      "Bank Address: 6000 Poplar Ave, Suite 300, Memphis, TN 38119\n",
      "        International Bank Transfer Process\n",
      "International Wire Details\n",
      "\n",
      "Receiving Bank Details\n",
      "57D Account with institution \n",
      "\n",
      "SWIFT/BIC Code: FRNAUS44\n",
      "Bank Name: First National Bankers Bank\n",
      "Bank Address: 7813 Office Park Blvd, Baton Rouge, LA, 70809, USA\n",
      "\n",
      "Beneficiary Bank Details\n",
      "59 Beneficiary customer name & address\n",
      "\n",
      "IBAN/Account Number:9801172556\n",
      "Beneficiary Name: 10 Academy Corp\n",
      "Beneficiary Address: 1450 El Camino Real, 208 Santa Clara, CA 95050 USA\n",
      "\n",
      "Reference Field\n",
      "70 Remittance information\n",
      "            084106768 with Evolve Bank and\n",
      "            Trust, 6000 Poplar Ave Ste. 300\n",
      "             Memphis, TN 38119\n",
      "         Credit Card Transfer Process\n",
      "Email us at train@10academy.org and we will send you the details on how you can process the payment.\n",
      "Ethiopian Bank Transfer Process (ETB Payments)\n",
      "            Beneficiary Name - 10 Academy\n",
      "             Bank Name - Commercial Bank of Ethiopia\n",
      "             Beneficiary Account Number - 1000589619076\n",
      "Nigerian Bank Transfer Process (NGN Payments)\n",
      "Bank Name - Guaranty Trust Bank\n",
      "Beneficiary Name - Adeyemo Oluwatosin Maryam\n",
      "Beneficiary Account Number - 0152858905\n",
      "        Important Note\n",
      "Please keep a record of your transaction for your reference.\n",
      "\n",
      "To ensure smooth processing and confirmation of your payment, we kindly request that you send a payment confirmation screenshot/link (for PayPal or Credit Card transfers) or a bank payment slip with a stamp (for bank transfers) if available. This will help us verify your payment promptly.\n",
      "\n",
      "If you have any further requests or questions, feel free to let us know!\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Intensive Training_ Week-0 Challenge Document.docx\n",
      "Extracted Text:\n",
      "\n",
      "\n",
      "\n",
      "10 Academy Intensive Training Week-0 Challenge Document\n",
      "Pre-training Assessment \n",
      "Date: 08 Apr - 12 Apr 2023\n",
      "Challenge Overview\n",
      "This week’s challenge focuses on the sentiment, topic, and reporting correlation among various global media agencies. The challenge aims to evaluate candidates for the 12-week training program in Data Engineering (DE), Generative AI Engineer (AIE), and Machine Learning Engineering (MLE). It provides applicants with a real-world experience of tasks in these domains and helps 10 Academy select suitable candidates\n",
      "Applicants who proceed to the next level by attaining an excellent performance in this week's challenge will have a clear picture of the required discipline, resilience, proactivity, talent diversity, and other essential elements of the 10 Academy training. Those that can not make it to the limited spots available will gain a clear understanding of the direction they should improve to prepare for AIE, DE & MLE job positions in the future.  Everyone will gain project experience to showcase in their professional profile.\n",
      "\n",
      "This week, therefore, is a win-win for everyone. We advise you to put your best effort to complete as many tasks as possible. We know that the number of tasks you are required to complete are a lot, and you will not have time to build intuition or to be comfortable with the new concepts and skills you are exposed to with this week’s challenge. Please note that building a deeper understanding is not the purpose for this week's project. Moreover, you may have never done or attempted to do some of the tasks before this training. If you are confused and overwhelmed, know that it is expected. \n",
      "\n",
      "The tutors, community managers, and all other teams are there to support you as best as they can. Be proactive to ask questions, provide resources that may help others, and above all persist!\n",
      "Dataset Overview: Importance of News Headline Analysis\n",
      "The data for this week's challenge is Global News Dataset. This dataset comprises news articles collected over the past few months using the NewsAPI\n",
      "You can download the global news data here. The structure of the data is as follows\n",
      "\n",
      "data.csv: \n",
      "article_id: Unique article id  \n",
      "source_id\n",
      "source_name: Source name\n",
      "author: The author of the article\n",
      "title: The headline or title of the article.\n",
      "description: A description or snippet from the article. \n",
      "url: The direct URL to the article. \n",
      "url_to_image: The URL to a relevant image for the article.\n",
      "published_at: The date and time that the article was published, in UTC\n",
      "content: The unformatted content of the article, where available. This is truncated to 200 chars\n",
      "category: Search query used to fetch data\n",
      "article: Full content of that article\n",
      "title_sentiment: Sentiment of the title\n",
      "\n",
      "You can download the domain’s location (the country where the news media headquarter that owns the domain/website is located) data here. The structure is as follows\n",
      "\n",
      "domains_location.csv:\n",
      "SourceCommonName: Common  Domain Name (bbc.co.uk, cnn.com)\n",
      "location: Country short code (US, UK, CA)\n",
      "Country: Country name\n",
      "\n",
      "You can download the 1million global website traffic data here. The structure is as follows\n",
      "\n",
      "traffic_data.csv:\n",
      "GlobalRank: Rank of the domain globally\n",
      "TldRank: Rank of the TLD (Top-Level Domain [.com, .org…..etc]) among other similar TLD (Top-Level Domain [.com, .org…..etc])\n",
      "Domain: \n",
      "TLD: TLD (Top-Level Domain [.com, .org…..etc])\n",
      "RefSubNets: The number of Referring Subnets found for this domain in the Fresh Index.\n",
      "RefIPs: The number of Referring IPs found for this domain in the Fresh Index.\n",
      "IDN_Domain: Internationalized Domain Name\n",
      "IDN_TLD: Internationalized Domain Name Top-Level Domain.\n",
      "PrevGlobalRank: Previous Global Rank.\n",
      "PrevTldRank: Previous TLD Rank.\n",
      "PrevRefSubNets: Previous number of referring subnets.\n",
      "PrevRefIPs: Previous number of referring IPs.\n",
      "Data Handling Instructions\n",
      "Do not push the data to GitHub. Add the data path to your .gitignore file to prevent accidental uploads.\n",
      "Ensure compliance with data privacy and confidentiality standards when working with the dataset \n",
      "The data for the project is in the public domain, so feel free to share your exciting findings in your preferred social media.\n",
      "Guidance for Applicants\n",
      "Win-Win Situation: This week's challenge is designed for mutual benefit. Excellent performance can lead to selection for the training program, while others gain valuable insights for future improvement.\n",
      "Task Completion: Focus on completing as many tasks as possible. The goal is exposure to various aspects, not necessarily deep understanding.\n",
      "Support System: The 10 Academy team, including tutors and community managers, is here to support you. Don't hesitate to ask questions, share resources, and persist in your efforts.\n",
      "Week's Topics Covered\n",
      "Python and Javascript Programming:\n",
      "Task-specific programming assignments.\n",
      "GitHub Commands:\n",
      "Continuous committing and repository management.\n",
      "Frameworks, Processes, and Workflows:\n",
      "Utilising CRISP-DM methodology.\n",
      "Databases:\n",
      "Working with SQL and NoSQL databases.\n",
      "Data Understanding and Exploration:\n",
      "Applying exploratory data analysis techniques.\n",
      "CI/CD:\n",
      "Understanding continuous integration and continuous deployment.\n",
      "MLOps:\n",
      "ML system process design.\n",
      "Modelling:\n",
      "Topic modelling and sentiment analysis.\n",
      "Web App Development:\n",
      "Building dashboards.\n",
      "Full Stack Development:\n",
      "Exposure to full-stack concepts.\n",
      "Server and Serverless Deployment:\n",
      "Deployment architecture and strategies.\n",
      "Note to Applicants\n",
      "Overwhelm is Expected: The challenge is designed to cover a broad range of topics. Feeling confused or overwhelmed is expected, and support is available.\n",
      "Proactivity is Key: Be proactive in asking questions, sharing resources, and collaborating with others.\n",
      "Persistence is Valued: Persistence in tackling challenges is highly valued in this learning environment.\n",
      "Starter python package\n",
      "We provide a starter python package that you may use to start working on the challenge. It has (at the time of writing this document) the following structure\n",
      "\n",
      "Network_analysis\n",
      "├── .vscode\n",
      "│   └── settings.json\n",
      "├── .github\n",
      "│   └── workflows\n",
      "│       ├── flake8_check.yml\n",
      "│       ├── unittests.yml\n",
      "│       └── docstring_tests.yml\n",
      "├── .gitignore\n",
      "├── .flake8\n",
      "├── .pre-commit-config.yaml\n",
      "├── setup.cfg\n",
      "├── Makefile\n",
      "├── pyproject.toml\n",
      "├── requirements.txt\n",
      "├── style_guide.md\n",
      "├── README.md\n",
      "├── view_tree.py\n",
      "├── docs\n",
      "├── notebooks\n",
      "│   ├── parse_slack_data.ipynb\n",
      "│   └── README.md\n",
      "├── tests\n",
      "│   ├── __init__.py\n",
      "└── src\n",
      "    ├── config.py\n",
      "    ├── __init__.py\n",
      "    ├── utils.py\n",
      "    └── loader.py\n",
      "\n",
      "\n",
      "Here's a breakdown of the different components (WARNING: we may add, edit or remove some files without updating this document. Also note that, code or config files may not be working - you should fix it by yourself or remove it if you don’t need it):\n",
      "\n",
      ".flake8: Configuration file for the Flake8 tool, which checks for code style and quality.\n",
      "requirements.txt: Lists the dependencies required to run the project. This file is commonly used with tools like pip to install project dependencies.\n",
      ".pre-commit-config.yaml: Configuration file for pre-commit hooks, which are checks that run before commits are allowed.\n",
      "Makefile: A Makefile for defining and running project tasks. It's a convenient way to encapsulate complex or repetitive tasks.\n",
      "pyproject.toml: Configuration file for build tools and project metadata. It's commonly used for projects using poetry.\n",
      "tests/: A directory for storing unit tests. The __init__.py file indicates that this directory should be treated as a Python package.\n",
      "docs/: A directory to store project documentation.\n",
      "style_guide.md: A markdown file containing the style guide for the project. Good documentation for coding styles can be useful for maintaining consistency.\n",
      "README.md: A README file containing essential information about the project. It serves as the first point of contact for anyone exploring the project.\n",
      ".gitignore: A file specifying which files and directories to ignore when pushing to version control (Git). This often includes files that are generated during runtime, build artifacts, and sensitive information.\n",
      ".github/workflows/: GitHub Actions workflow files for automating tasks like code formatting, unit testing, and docstring testing.\n",
      "setup.cfg: Configuration file for the setuptools package, often used for packaging and distribution.\n",
      ".vscode/settings.json: Configuration settings for Visual Studio Code, an integrated development environment (IDE).\n",
      "notebooks/: A directory for storing Jupyter notebooks, which are often used for exploratory data analysis (EDA) and documenting code.\n",
      "view_tree.py: A Python script or module for viewing the project tree structure.\n",
      "src/: A directory containing the source code of the project.\n",
      "config.py: Configuration file for the project.\n",
      "__init__.py: Marks the src directory as a Python package.\n",
      "utils.py: A module containing utility functions.\n",
      "loader.py: A module for loading Slack data \n",
      "Feel free to adopt or alter the structure as you see fit. \n",
      "\n",
      "Work Plan\n",
      "The following is the summary of the 5 tasks you are expected to complete this week. A step-by-step guideline will be provided during the week.\n",
      "\n",
      "In all of the tasks below the following are required performance indicators\n",
      "Ability to help others.\n",
      "Efficient and modular coding technique.\n",
      "Proactivity to self-learn - sharing references.\n",
      "\n",
      " Task 1: \n",
      "Git and GitHub\n",
      "Tasks: \n",
      "Setting up Python environment\n",
      "Git version control \n",
      "CI/CD \n",
      "Key Performance Indicators (KPIs):\n",
      "Dev Environment Setup.\n",
      "Relevant skill in the area demonstrated.\n",
      "Project Planning - EDA & Stats\n",
      "Tasks: \n",
      "Understanding CRISP-DM Framework\n",
      "Data Understanding\n",
      "Exploratory Data Analysis (EDA)\n",
      "Statistical thinking\n",
      "KPIs:\n",
      "Proactivity to self-learn - sharing references.\n",
      "EDA techniques to understand data and discover insights,\n",
      "Demonstrating Stats understanding by using suitable statistical distributions and plots to provide evidence to actionable insights gained from EDA.\n",
      "Minimum Essential To Do (if you do it better, don’t worry about sticking with this guideline) :\n",
      "Create a github repository that you will be using to host all the code for this week. You can name it like news_correlation_10ac_week0/\n",
      "Create at least one new branch called ”task-1” for your analysis of day 1\n",
      "Commit your work at least three times a day with descriptive commit message\n",
      "If you are using the starter code (which is prepared for a slack data analysis project), make sure to change every occurrence of slack (filename, function names, class names, etc.) to news. Moreover, make sure to update the code to be useful for the news data. For example \n",
      "Change SlackDataLoader to NewsDataLoader so that you can load the current data\n",
      "Move all non-plotting functions from notebooks/parse_slack_data.ipynb into src/loader.py and src/utils.py such that in the notebook you use the NewsDataLoader from src/loader.py and functions from src/utils.py for all your data loading needs. \n",
      "Write new methods and new classes to help you explore the data better\n",
      "Perform EDA analysis to answer the following questions\n",
      "Who are the top and bottom 10 \n",
      "Websites that have the largest count of news articles\n",
      "Websites with the highest numbers of visitors traffic \n",
      "Countries with the highest number of news media organisations (represented by domains in the data)\n",
      "Countries that have many articles written about them - the content of the news is about that country\n",
      "Websites that reported (the news content) about Africa, US, China, EU, Russia, Ukraine, Middle East? Note that you will need to group countries together to form the African, EU, and Middle East continents/regions.\n",
      "Websites with the highest count of positive, neutral, and negative sentiment? To do this you will need to group the data by website domain and apply descriptive statistics such as mean, median, and variance\n",
      "compare the impact of using mean/average and median, \n",
      "check the distribution of sentiments for a particular domain (select the top 10 domains by visitors traffic) amount of news reported or vs the global news sentiment distribution)\n",
      "Compare the content metadata across sites \n",
      "How similar are the raw message lengths across sites? Check the distribution among sites\n",
      "How similar are the number of words in the title across sites? Check the distribution among sites\n",
      "What is the impact of frequent news reporting and sentiment to the website’s global ranking? \n",
      "Do a 2D scatter plot where x-axis is the total number of reports by a website, y-axis is the global ranking of the site, and the color representing average/median sentiment. \n",
      "\n",
      "Task 2: \n",
      "Data Science Component Building\n",
      "Tasks: \n",
      "MLOps components\n",
      "Analysis pipeline designs\n",
      "Time Series Analysis\n",
      "Classification of Headlines into the following tags\n",
      "Breaking News\n",
      "Politics\n",
      "World News\n",
      "Business/Finance\n",
      "Technology\n",
      "Science\n",
      "Health\n",
      "Entertainment\n",
      "Sports\n",
      "Environment\n",
      "Crime\n",
      "Education\n",
      "Weather\n",
      "Other\n",
      "Topic Modelling & Sentiment Analysis.\n",
      "Predictive analysis and modelling  \n",
      "Network analysis\n",
      "KPIs:\n",
      "Understanding DS components.\n",
      "Pipeline and process-centric thinking.\n",
      "Ability to understand basic requirements and translate them into codes.\n",
      "Demonstrating ML skills and knowledge\n",
      "ML Engineering\n",
      "Tasks: \n",
      "Understanding MLOps components\n",
      "Feature Store\n",
      "Model versioning\n",
      "Model monitoring, \n",
      "Unit Testing \n",
      "CI Implementation with Github Actions\n",
      "Dockerization \n",
      "Building python packages.\n",
      "KPIs:\n",
      "Understanding of Software Engineering concepts.\n",
      "Understanding of MLOps concepts\n",
      "Demonstrating Code, Data, and Model CI/CD skill\n",
      "Minimum Essential To Do:\n",
      "Merge your day 1 branches (e.g. task-1 branch) to the main branch\n",
      "From the main branch, create at least one new branch called “task-2” to develop your analysis of Task 2\n",
      "Create at least one unit test into tests/ folder\n",
      "Summarise the different MLOps components and their use\n",
      "Answer the following questions \n",
      "Perform Keyword extraction/modelling using TF-IDF, KeyBert, YAKE,  or other similar algorithms\n",
      "How similar are keywords in the headline/title compared to keywords in the news body across sites? To do this you may need to perform TF-IDF or similar keyword identification \n",
      "Perform topic modelling. Checkout ref1 ref2 ref3\n",
      "categorise the title/content into a known set of topic categories\n",
      "Analyse topics and trends \n",
      "Which websites reported the most diverse topics?\n",
      "Analyse the topic trends. For example, plot a 2D scatter plot such that x-axis is date, y-axis is the topics, and the color represents the count of the topic in that particular date. What  are the observed trends?\n",
      "Model the events that the news articles are written about (this is the most challenging part of this project). You may follow similar methodology as this one or this one   \n",
      "you will require to associate/model the event that the article is covering. For example 500 of the news articles by 60 news media  could be about the event of a global disruption of the Meta company Apps such as Instagram). \n",
      "Cluster news articles by events \n",
      "How many events are covered in the data?\n",
      "Analyse which news sites report events the earliest?\n",
      "Which events have the highest reporting?\n",
      "What is the correlation between news sites reporting events?\n",
      "Version your ML models and their artefacts using MLFlow\n",
      "Task 3: \n",
      "PostgreSQL\n",
      "Tasks: \n",
      "Database Technologies (SQL vs NOSQL), \n",
      "Database schema design.\n",
      "Using PostgreSQL as Feature Store and load into it ML model features \n",
      "Loading data into PostgresSQL \n",
      "KPIs:\n",
      "Schema design for SQL\n",
      "Demonstrating SQL skills\n",
      "Minimum Essential To Do:\n",
      "Merge the necessary branches from task-2 into the main branch using a Pull Request (PR)\n",
      "Create at least 1-branch called task-3 to develop your work for Task 3\n",
      "Design a PostgreSQL table schema to store your ML features - the data used to create the Topic & Event Models\n",
      "Create a schema using dbdiagram.io or DbSchema to host the data features you prepared in Task 1 & 2\n",
      "Create your tables using python \n",
      "Load all the relevant features into the database\n",
      "Task 4: (Optional)\n",
      "Dashboards\n",
      "Tasks: \n",
      "Streamlit-based dashboard design\n",
      "Programming a simple React app or component (streamlit)\n",
      "KPIs\n",
      "Wireframing tools familiarity.\n",
      "Dashboard Design.\n",
      "Design thinking.\n",
      "Building dashboards with Streamlit.\n",
      "Fullstack concepts understanding using React and Python\n",
      "Minimum Essential To Do:\n",
      "Merge the necessary branches from task-3 into the main branch using a Pull Request (PR)\n",
      "Create at least 1-branch called task-4 to develop your work for Task 4\n",
      "Design a dashboard to show results from Task 1 & 2 in Figma or similar tools \n",
      "Implement the dashboard you designed using Streamlit \n",
      "Write a basic React App or Streamlit component to demonstrate your understanding of Fullstack (frontend using React, database using SQL, and backend using Python) development \n",
      "Streamlit components are built using React - see this reference\n",
      "Task 5: (Optional)\n",
      "Deployment\n",
      "Tasks: \n",
      "Streamlit or React App\n",
      "Writing at least one github action for continuous deployment (CD)\n",
      "Python Backend\n",
      "Writing at least one github action for continuous deployment (CD)\n",
      "Configure environment variables for database credentials and other sensitive information.\n",
      "PostgreSQL Database\n",
      "Initialize the PostgreSQL database by running the necessary setup scripts. Typically involves creating the initial database cluster and superuser.\n",
      "Understanding deployment\n",
      "Understanding Kubernetes (Docker Swarm or other distributed docker container based deployments)\n",
      "KPIs\n",
      "Understanding of deployment technologies\n",
      "Minimum Essential To Do:\n",
      "Merge the necessary branches from task-4 into the main branch using a Pull Request (PR)\n",
      "Create at least 1-branch called task-5 to develop your work for Task 5\n",
      "Create at least one github action file in the .github/workflow that will package your code as docker image and push it to docker hub. \n",
      "In the future you may add a step in your github actions to trigger serverless cloud deployment e.g. in AWS Lambda or other docker based deployment infrastructure\n",
      "Write a summary of your understanding of the different deployment tech stack.\n",
      "\n",
      "Deliverables:\n",
      "Monday:\n",
      "Your public Github repository link \n",
      "You should make sure that all of your code related work for this week is going to be aggregated in this repository. We will analyse your repository link to evaluate your skills and work progress.\n",
      "Tuesday:\n",
      "1-page summary of the project as you understand it.\n",
      "Github link to your main branch\n",
      "You should create at least one new branch called `task-1` for task 1 and merge your latest work with main branch.\n",
      "Wednesday:\n",
      "\n",
      "Thursday:\n",
      "3-pages report on insights and work done in the previous days.\n",
      "Friday: Changed to Saturday 8:00 PM (UTC)\n",
      "Link to deployed dashboard (or detailed screenshots). (Optional but a plus if you submit)\n",
      "GitHub Link to your main branch \n",
      "Final report - covering all week-0 work. \n",
      "Write it in the format that you could post it as a Blog in Medium.\n",
      "\n",
      "Other Considerations:\n",
      "Documentation: Encourage detailed documentation in code and report writing.\n",
      "Collaboration: Emphasise collaboration through Github issues and projects.\n",
      "Communication: Regular check-ins, Q&A sessions, and a supportive community atmosphere.\n",
      "Flexibility: Acknowledge potential challenges and encourage proactive communication.\n",
      "Professionalism: Emphasise work ethics and professional behaviour.\n",
      "Time Management: Stress the importance of punctuality and managing time effectively.\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and non-purple indicates afternoon sessions.\n",
      "\n",
      "Day 1: \n",
      "Introduction to the Challenge\n",
      "Python Environment Setup, Git and Github, CI/CD \n",
      "Project Planning & EDA - Data Science Workflow using CRISP-DM and EDA techniques \n",
      "Day 2: \n",
      "Data Science Component Building (Architecture Designs, Wifeframing, logic flow)\n",
      "Topic Modeling, Sentiment Analysis, Time Series Analysis\n",
      "ML Engineering components \n",
      "Day 3:\n",
      "\n",
      "Day 4: \n",
      "Working with SQL \n",
      "Database schema design \n",
      "Day 5:\n",
      "Building Dashboards using Streamlit\n",
      "Introduction to Fullstack programming using React and Python\n",
      "\n",
      "Leaderboard Updates\n",
      "Wednesday end of day\n",
      "Friday end of day\n",
      "\n",
      "\n",
      "References\n",
      "Highly recommended references are highlighted in bold.\n",
      "\n",
      "Relevant academic papers\n",
      "The drivers of global news spreading patterns | Scientific Reports (nature.com)\n",
      "\n",
      "CRISP-DM, topic modelling, and sentiment analysis:\n",
      "https://www.datascience-pm.com/crisp-dm-2/\n",
      "Gensim Topic Modeling - A Guide to Building Best LDA models (machinelearningplus.com)\n",
      "Beginners Guide to Topic Modeling in Python and Feature Selection (analyticsvidhya.com)\n",
      "\n",
      "Database & Dashboard design and implementation\n",
      "Get started - Streamlit Docs\n",
      "Turn Python Scripts into Beautiful ML Tools | by Adrien Treuille | Towards Data Science\n",
      "Streamlit 101: An in-depth introduction | by Shail Deliwala | Towards Data Science\n",
      "StreamLit - Data Scientists tool for developing web apps | by INSAID | Medium\n",
      "\n",
      "Python Programming:\n",
      "Object Oriented Programming \n",
      "Python Courses and Tutorials: Online and On Site (python-course.eu)\n",
      "\n",
      "Data Engineering\n",
      "What is Data Engineer: Role Description, Skills, and Background | AltexSoft\n",
      "\n",
      "Version control – Git\n",
      "What is version control | Atlassian\n",
      "Learn Git branching -- interactive way to learn Git\n",
      "Git with large files\n",
      "Which files to not track and how to not track them? | Atlassian\n",
      ".gitignore docs\n",
      "Conventional commits -- lightweight convention on top of commit messages.\n",
      "\n",
      "CI/CD\n",
      "What is Continuous Integration | Atlassian\n",
      "DevOps Pipeline | Atlassian\n",
      "7 Popular Open Source CI/CD Tools - DevOps.com\n",
      "Setting up a CI/CD pipeline on Github\n",
      "\n",
      "MLOps\n",
      "MLOps: Continuous delivery and automation pipelines in machine learning\n",
      "MLwatcher - monitoring model performanc\n",
      "\n",
      "Python Testing\n",
      "https://machinelearningmastery.com/a-gentle-introduction-to-unit-testing-in-python/\n",
      "https://docs.python-guide.org/writing/tests/\n",
      "https://realpython.com/python-testing/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: cB- Problem-Solving Skills- Wk3.docx\n",
      "Extracted Text:\n",
      "10 Academy Cohort B: Week 3\n",
      "\n",
      "Non-Technical Challenge\n",
      "\n",
      "Problem-Solving Skills \n",
      "\n",
      "Submission deadline: Saturday, May 11th, 2024, 8:00 PM UTC\n",
      "\n",
      "Scenario: \n",
      "You are a Product Manager of a tech startup, Canes Gaming Inc., and your job is filled with unexpected challenges that require your immediate attention and decision-making. Canes Gaming Inc. is a gaming company that focuses on the development and publishing of the game Sandy Crash.  The company is struggling with declining user engagement and customer retention in its mobile application. \n",
      "\n",
      "Despite an initial surge in downloads, the app is experiencing a drop-off in active users, leading to concerns about long-term sustainability and revenue generation. \n",
      "\n",
      "As the product manager, you have tasked analysts with helping you analyze the situation to identify the root causes of the declining engagement. You will then  propose actionable solutions to improve user retention based on the analysis and make decisions for your company with a way forward. \n",
      "\n",
      "The objective of this exercise is to develop and demonstrate your problem-solving skills by addressing real-world challenges faced when running a product. \n",
      "\n",
      "Summary of the findings:\n",
      "A root cause analysis was conducted by the analysts through a combination of qualitative and quantitative methods, including user surveys, interviews with key stakeholders, and analysis of app usage data. The goal was to identify the primary factors contributing to the decline in user engagement and retention and to develop actionable recommendations for addressing these issues.\n",
      "\n",
      "They settled on the following reasons:\n",
      "Misleading advertising: The app’s advertisement campaign across social media was very appealing and lured many users into downloading the app. However, the app fell short of user expectations as it lacked the features and updates that were prominently advertised. This resulted in user disappointment and eventual disengagement\n",
      "\n",
      "Marketing flaw: A lot of money was spent on advertising too soon, and it also wasn’t targeted (mindless advertising).\n",
      "\n",
      "Poor employee collaboration: There is clearly a problem with team members not collaborating well. Otherwise, what was advertised would have been the same as the app itself. \n",
      "\n",
      "Customer dissatisfaction: The rate of active users declined, even though the download rates are high. \n",
      "\n",
      "Communication problem: The team doesn’t communicate well with each other and they tend not to comprehend each other’s vision in the team.\n",
      "\n",
      "\n",
      "\n",
      "Task: \n",
      "\n",
      "As a product manager, your task is to develop 5 strategies to address the issue of misleading advertising to find out how it happened, manage it, and rebuild user trust.\n",
      "\n",
      "Outline 5 key steps to give guidance to the marketing team to ensure effective and targeted marketing practices.\n",
      "\n",
      "What 5 steps will you take to ensure the team collaboration improves?\n",
      "\n",
      "What are 5 some of the considerations you’d take to ensure customer satisfaction and retention?\n",
      "\n",
      "How will you ensure effective communication? \n",
      "(i) Within the whole team, i.e. marketing, developer, management, illustrators, etc? Provide 5 ideas.\n",
      "\n",
      "(ii)Think about how in the gaming industry, describing a game requires you to properly communicate the vision, the idea, and the feel. What 5 measures would you take to ensure everyone has the right vision in mind?\n",
      "\n",
      "Submission\n",
      "\n",
      "A report consisting of slides that you’ll present to your whole team on the way forward, answering the questions in the tasks above. \n",
      "Save your PPT as PDF before submission.\n",
      "\n",
      "\n",
      "Rubrics\n",
      "\n",
      "Understanding and Addressing Misleading Advertising: Grading will assess the clarity and effectiveness of the proposed strategies to address misleading advertising, considering how it happened, how to manage it, and how to rebuild user trust.\n",
      "\n",
      "Guidance for Effective and Targeted Marketing Practices: You are tasked with outlining key steps to guide the marketing team towards effective and targeted marketing practices. Grading will focus on the specificity, relevance, and feasibility of the outlined steps.\n",
      "\n",
      "Improving Team Collaboration: You are asked to propose steps to enhance team collaboration. Grading criteria include the comprehensiveness, feasibility, and potential impact of the suggested strategies.\n",
      "\n",
      "Considerations for Customer Satisfaction and Retention: Grading will evaluate the depth and relevance of considerations outlined to ensure customer satisfaction and retention, considering the identified root causes and potential solutions.\n",
      "\n",
      "Ensuring Effective Communication:\n",
      "\n",
      "(i) Within the Whole Team:\n",
      "You are required to provide ideas to ensure effective communication within the entire team. Grading will consider the clarity, feasibility, and inclusiveness of the suggested communication methods.\n",
      "\n",
      "(ii) Communicating Vision in the Gaming Industry:\n",
      "Grading will assess the effectiveness and relevance of measures proposed to ensure alignment on the game's vision, idea, and feel among team members, considering the unique challenges of the gaming industry.\n",
      "\n",
      "\n",
      "\n",
      "Usefulness in real-life\n",
      "The given exercise provides an opportunity to apply problem-solving skills in real-world scenarios. By addressing the challenges faced by Canes Gaming Inc., specifically the declining user engagement and retention in its mobile application, you will be able to gain insights into the complexities of managing a tech startup and devising strategic solutions to overcome obstacles.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File: cB - Careers challenge - Time Management - W2.docx\n",
      "Extracted Text:\n",
      "10 Academy cB : Week 2\n",
      "Careers - Exercise 2\n",
      "\n",
      "Time Management\n",
      "\n",
      "Due Date: Thursday, 2th May 2024, 10AM UTC\n",
      "\n",
      "Background\n",
      "Today is a typical Thursday at work, and you have a list of tasks that need to be completed before the day ends. You start your day at 8:00 am and finish at 5:00 pm. Review the tasks you need to accomplish; remember, you don't have to complete everything today, but you must finish 11 of the tasks. You can address the remaining tasks the following day.\n",
      "\n",
      "Series of Tasks\n",
      "1. Attend the daily stand-up meeting at 8:00 am, which lasts for 30 minutes.\n",
      "2. Fix a bug for a client who has been complaining for over a week.\n",
      "3. Train an intern who has encountered a blocker in their code that’s hindering them to continue their work.\n",
      "4. Onboard a new team member who started on Monday and is still unclear about their responsibilities.\n",
      "5. Meet with the marketing team to share the data they requested last week and need to use them today.\n",
      "6. Submit the management update report for yesterday's deployment.\n",
      "7. Attend a one-hour webinar relevant to your current projects, although the recording will be available the following day.\n",
      "8. Prepare a 30-minute presentation for a stakeholder meeting scheduled for 2:00 pm.\n",
      "9. Your colleagues requested to have lunch with you by 12:00 pm.\n",
      "10. Respond to emails from other departments requesting technical support.\n",
      "11. Participate in an online conference call with a potential software vendor at 1:00 PM (note that you are not presenting).\n",
      "12. Check in call with your remote team members about their progress on various tasks.\n",
      "13. Coordinate with the QA (Quality Assurance) team to test new features added last week.\n",
      "14. Schedule a team meeting for next week to discuss upcoming project milestones.\n",
      "15. Analyse user feedback on a newly deployed app received through the customer support portal.\n",
      "16. Plan and organise the team's participation in an upcoming tech conference that is happening in two weeks.\n",
      "\n",
      "Exercise\n",
      "Distribute your chosen 11 tasks into 3 columns; High Priority, Medium Priority and Low Priority and then explain why you put a certain task in that priority column. \n",
      "Plan Your Day: Using Google Calendar, schedule each task of those 11 taks, allocating specific today’s time blocks (8am to 5pm) based on their priority and deadline. Then, take a screenshot of the schedule and add it in your PPT.\n",
      "You have the remaining 5 tasks which you decided to not work on today. Please explain why you chose to not work on each one of them today. \n",
      "From the time management strategies shared in the Tutorial, which one did you choose to use while doing this exercise, and why?\n",
      "What reflection do you have on your experiences from this exercise, particularly focusing on how you managed your time during the day. \n",
      "\n",
      "Submission\n",
      "Create a 7 slides maximum presentation containing the answers to the exercise above, then convert it to a PDF format for submission on Tenx. \n",
      "\n",
      "Note: While submitting on Tenx, Please submit a PDF format of your presentation.\n",
      "Rubrics\n",
      "Task Prioritisation: In this question, trainees are required to categorize the given tasks into three priority levels: high, medium, and low. Grading will focus on whether they justified their decisions based on factors such as urgency, importance, and deadlines, demonstrating strategic thinking and decision-making skills.\n",
      "\n",
      "Task Allocation on Google calendar: Trainees are required to use Google Calendar to schedule each of the 11 chosen tasks into specific today’s time blocks, considering their priority and deadline. Grading will look on if the schedule is realistic, well-organized, and clearly labeled for easy reference.\n",
      "\n",
      "Strategic Decision Making: Trainees are asked to explain why they chose not to work on each of the remaining 5 tasks on the given day. Grading will focus on their justification of their decisions based on strategic considerations, task dependencies, and overall priorities, demonstrating effective decision-making and communication skills.\n",
      "\n",
      "Time Management Strategy: Trainees are required to identify and justify the time management strategy they chose to use during the exercise. Grading will look at whether they explained how this strategy was applied and its effectiveness in managing their time effectively throughout the task prioritization and scheduling process.\n",
      "\n",
      "Reflection on Time Management: Trainees are asked to reflect on their experiences managing their time during the exercise, focusing on insights gained, strengths and weaknesses identified, and implications for future time management practices. Grading will look on whether they provided thoughtful reflections that demonstrate self-awareness and a commitment to continuous improvement.\n",
      "\n",
      "\n",
      "\n",
      "Usefulness in life\n",
      "Effective time management is essential for meeting deadlines, prioritising tasks, and maintaining productivity without feeling overwhelmed. By engaging in this exercise, trainees learn to allocate their time wisely, handle multiple tasks, and respond flexibly to unexpected challenges. Additionally, these skills are transferable across various domains beyond work, including personal life management, where balancing multiple responsibilities is key. Therefore, this will serve as a practical tool for developing competencies that improve organisational outcomes and personal effectiveness in managing daily demands.\n",
      "\n",
      "\n",
      "\n",
      "File: 10 Academy Cohort B - Weekly Challenge_ Week - 7.docx\n",
      "Extracted Text:\n",
      "\n",
      "10 Academy Cohort B\n",
      "Weekly Challenge: Week 7\n",
      "Precision RAG: Prompt Tuning For Building Enterprise Grade RAG Systems\n",
      "\n",
      "Business objective  \n",
      "PromptlyTech is an innovative e-business specializing in providing AI-driven solutions for optimizing the use of Language Models (LLMs) in various industries. The company aims to revolutionize how businesses interact with LLMs, making the technology more accessible, efficient, and effective. By addressing the challenges of prompt engineering, the company plays a pivotal role in enhancing decision-making, operational efficiency, and customer experience across various industries. PromptlyTech's solutions are designed to cater to the evolving needs of a digitally-driven business landscape, where speed and accuracy are key to staying competitive.\n",
      "The company focuses on key services: Automatic Prompt Generation, Automatic Evaluation Data Generation, and Prompt Testing and Ranking.\n",
      "1. Automatic Prompt Generation Service:\n",
      "This service streamlines the process of creating effective prompts, enabling businesses to efficiently utilize LLMs for generating high-quality, relevant content. It significantly reduces the time and expertise required in crafting prompts manually.\n",
      "2. Automatic Evaluation Data Generation Service:\n",
      "PromptlyTech’s service automates the generation of diverse test cases, ensuring comprehensive coverage and identifying potential issues. This enhances the reliability and performance of LLM applications, saving significant time in the QA(Quality Assurance) process.\n",
      "3. Prompt Testing and Ranking Service:\n",
      "PromptlyTech’s service evaluates and ranks different prompts based on effectiveness, helping Users to get the desired outcome from LLM. It ensures that chatbots and virtual assistants provide accurate, contextually relevant responses, thereby improving user engagement and satisfaction.\n",
      "Background Context\n",
      "\n",
      "In the evolving field of artificial intelligence, Language Models (LLMs) like GPT-3.5 and GPT-4 have become crucial for various applications. Their effectiveness, however, heavily depends on the quality of the prompts they receive, leading to the emergence of \"prompt engineering\" as a key skill.\n",
      "\n",
      "Prompt engineering is the craft of designing queries or statements to guide LLMs to produce desired outcomes. The challenge lies in the sensitivity of these models to prompt nuances, where slight variations can yield vastly different results. This poses a significant hurdle for users, especially in business contexts where accuracy and relevance are paramount.\n",
      "\n",
      "The need for simplified, efficient prompt engineering is clear. Automating and optimizing this process can save time, enhance LLM productivity, and make advanced AI capabilities more accessible to a broader range of users. The tasks of Automatic Prompt Generation, Evaluation Data Generation, and Prompt Testing and Ranking are aimed at addressing these challenges, streamlining the prompt engineering process for more effective use of LLMs.\n",
      "Learning Outcomes\n",
      "Skills Development\n",
      "Prompt Engineering Proficiency: Gain expertise in crafting effective prompts that guide LLMs to desired outputs, understanding nuances and variations in language that impact model responses.\n",
      "Critical Analysis: Develop the ability to critically analyze and evaluate the effectiveness of different prompts based on their performance in varied scenarios.\n",
      "Technical Aptitude with LLMs: Enhance technical skills in using advanced language models like GPT-4 and GPT-3.5-Turbo, understanding their functionalities and capabilities.\n",
      "Problem-Solving and Creativity: Cultivate creative problem-solving skills by generating innovative prompts and test cases, addressing complex and varied objectives.\n",
      "Data Interpretation: Learn to interpret and analyze data from test cases and prompt evaluations, deriving meaningful insights from performance metrics.\n",
      "\n",
      "Knowledge Acquisition\n",
      "Understanding of Language Models: Acquire a deeper understanding of how LLMs function, including their strengths, limitations, and the principles behind their responses.\n",
      "Insights into Automated Evaluation Data Generation: Gain knowledge about the methodology and importance of creating test cases for evaluating prompt effectiveness.\n",
      "ELO Rating System and its Applications: Learn about the ELO rating system used for ranking prompts, understanding its mechanics and relevance in performance evaluation.\n",
      "Prompt Optimization Strategies: Understand various strategies for refining and optimizing prompts to achieve better alignment with specific goals and desired outcomes.\n",
      "Industry Best Practices: Familiarize with the best practices in prompt engineering within different industries, learning about real-world applications and challenges.\n",
      "\n",
      "Team\n",
      "Tutors: \n",
      "Yabebal\n",
      "Emtinan\n",
      "Rehmet\n",
      "Badges\n",
      "Each week, one user will be awarded one of the badges below for the best performance in the category below.\n",
      "\n",
      "In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\n",
      "\n",
      "Visualization - quality of visualizations, understandability, skimmability, choice of visualization\n",
      "Quality of code - reliability, maintainability, efficiency, commenting - in future this will be CICD/CML\n",
      "Innovative approach to analysis -using latest algorithms, adding in research paper content and other innovative approaches\n",
      "Writing and presentation - clarity of written outputs, clarity of slides, overall production value\n",
      "Most supportive in the community - helping others, adding links, tutoring those struggling\n",
      "\n",
      "The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\n",
      "\n",
      "Group Work Policy\n",
      "Everyone has to submit all their work individually. \n",
      "Instruction: Automatic Prompt Engineering\n",
      "Fundamental Tasks\n",
      "The core tasks for this week’s challenge in Automatic Prompt Engineering are outlined below:\n",
      "\n",
      "Understand Prompt Engineering Tools and Concepts: Gain a thorough understanding of the tools and theoretical concepts involved in prompt engineering for Language Models (LLMs).\n",
      "\n",
      "Familiarize with Language Models: Learn about the capabilities and functionalities of advanced LLMs like GPT-4 and GPT-3.5-Turbo.\n",
      "\n",
      "Develop a Plan for Prompt Generation and Testing: Create a comprehensive plan that outlines the approach for automated prompt generation, test case creation, and prompt evaluation.\n",
      "\n",
      "Set Up a Development Environment: Prepare a suitable development environment that supports the integration and testing of LLMs in the prompt engineering process.\n",
      "\n",
      "Design User Interface for Prompt System: Plan and initiate the development of a user-friendly interface for prompt input, refinement, and performance analysis.\n",
      "\n",
      "Plan Integration of LLMs: Strategize the integration of LLMs into the prompt system for automated generation and testing.\n",
      "\n",
      "Build and Refine Prompt Generation System: Develop the automated prompt generation system, ensuring it aligns with user inputs and objectives.\n",
      "\n",
      "Develop Automatic Evaluation Data Generation System: Create a system for generating test cases that evaluate the effectiveness of prompts in various scenarios.\n",
      "\n",
      "Implement Prompt Testing and Evaluation Mechanism: Set up testing procedures using Monte Carlo matchmaking and ELO rating systems to evaluate and rank prompts.\n",
      "\n",
      "Refine and Optimize System Based on Feedback: Continuously refine the prompt generation and evaluation system based on user feedback and performance data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task 1: Review the Evolution of Automatic Prompt Engineering\n",
      "Focus on understanding the key developments in the field of automatic prompt engineering for Language Models (LLMs).\n",
      "\n",
      "Study Key Concepts and Tools:\n",
      "Understand the key components of an enterprise-grade RAG systems\n",
      "Retrieval-augmented generation (RAG): What it is and why it’s a hot topic for enterprise AI\n",
      "Advanced RAG for LLMs/SLMs\n",
      "RAG for Text Generation Processes in Businesses (check part 1, 3, & 4 as well) \n",
      "Langchain Reterivers\n",
      "Understand the need for advanced prompt engineering in building enterprise grade RAG systems\n",
      "Full Fine-Tuning, PEFT, Prompt Engineering, and RAG: Which One Is Right for You?\n",
      "Advanced Prompt Engineering - Practical Examples\n",
      "Prompt Engineering 201: Advanced methods and toolkits\n",
      "Do you agree with this article? RAG is Just Fancier Prompt Engineering\n",
      "Understand the need for evaluating RAG components\n",
      "An Overview on RAG Evaluation\n",
      "Evaluating RAG: Using LLMs to Automate Benchmarking of Retrieval Augmented Generation Systems\n",
      "Evaluating RAG Applications with RAGAs\n",
      "RAG Evaluation Using LangChain and Ragas\n",
      "RAG System: Metrics and Evaluation Analysis with LlamaIndex\n",
      "Evaluating RAG Part I: How to Evaluate Document Retrieval\n",
      "Evaluating RAG/LLMs in highly technical settings using synthetic QA generation\n",
      "Evaluating Multi-Modal RAG\n",
      "Understand the tools and techniques to automatically generate RAG evaluation data \n",
      "The Tech Buffet #16: Quickly Evaluate your RAG Without Manually Labeling Test Data\n",
      "Generating a Synthetic Dataset for RAG\n",
      "\n",
      "Learn key packages to planning, building, testing, monitoring, and deploying enterprise grade RAG system\n",
      "Iterate on LLMs faster: Measure LLM quality and catch regressions\n",
      "Building RAG-based LLM Applications for Production\n",
      "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems\n",
      "Understand the end-to-end technology stack of RAG systems\n",
      "End-to-End LLMOps Platform\n",
      "An Enterprise-Grade Reference Architecture for the Production Deployment of LLMs Using the RAG Pattern on Azure OpenAI\n",
      "Task 2: Design and Develop the Prompt Generation System\n",
      "Users can input a description of their objective or task and specify a few scenarios along with their expected outputs. \n",
      "Write or adopt sophisticated algorithms, you generate multiple prompt options based on the provided information. \n",
      "This automated prompt generation process saves time and provides a diverse range of alternatives to consider. But add evaluation metrics that check whether the generated prompt candidate aligns with the input description.\n",
      "Note that you may use the collection of prompts from danielmiessler/fabric: fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere. (github.com) to get started. You can apply RAG on prompt knowledge base. For a simple way of fetching semantically similar prompts, think how to use semantic routes\n",
      "Task 3: Implement Evaluation Data Generation and Evaluation\n",
      "To further enhance the prompt generation process, incorporate automatic Evaluation Data Generation. \n",
      "By analysing the description provided by the user,  create a set of test cases that serve as evaluation benchmarks for the prompt candidates.\n",
      "These test cases simulate various scenarios, enabling users to observe how each prompt performs in different contexts. \n",
      "The generated test cases serve as a starting point, sparking creativity and inspiring additional test cases for comprehensive evaluation.\n",
      "Task 4: Prompt Testing and Ranking\n",
      "Goals\n",
      "Comprehensive Evaluation: Provide a robust system that uses various methodologies for a thorough assessment of prompts.\n",
      "Customizable and User-Centric: Allow users to choose or customize their preferred evaluation methods.\n",
      "Dynamic and Adaptive: Ensure the system remains flexible and adaptive, capable of incorporating new ranking methodologies as they emerge.\n",
      "\n",
      "Primary Methods\n",
      "\n",
      "Monte Carlo Matchmaking: This method is used to select and match different prompt candidates against each other. The Monte Carlo method, known for its applications in problem-solving and decision-making processes, helps in optimizing the information gained from each prompt battle. By simulating various matchups, it allows the system to test the effectiveness of each prompt in different scenarios.\n",
      "ELO Rating System:  This system, which is commonly used in chess and other competitive games, rates the prompts based on their performance in the battles. Each prompt candidate is assigned a rating that reflects its success in previous matchups. The system takes into account not just the number of wins but also the strength of the opponents each prompt has defeated. This rating helps in objectively ranking the prompts based on their effectiveness.\n",
      "\n",
      "Additional Ranking and Matching Mechanisms\n",
      "TrueSkill Rating System: Ideal for scenarios involving multiple competitors, adjusting ratings based on not just wins and losses but also the uncertainty in performance.\n",
      "Glicko Rating System: Similar to ELO but with added flexibility, accounting for the volatility in a player's (or prompt’s) performance and the reliability of their rating.\n",
      "Bayesian Rating Systems: Applies Bayesian inference for a probabilistic approach to rating, considering uncertainties and contextual variations in prompt performance.\n",
      "Pairwise Comparison Methods: Involves direct comparisons between pairs of prompts, potentially integrating user preferences or expert evaluations into the ranking process.\n",
      "Categorical Ranking: Instead of a numerical rating, prompts are categorized based on performance criteria like creativity, relevance, etc., for more qualitative assessments.\n",
      "Adaptive Ranking Algorithms: Algorithms that learn and adjust over time, considering historical performance data and evolving user preferences or requirements.\n",
      "Semantic Similarity Matching: Using NLP techniques to match prompts based on semantic content, ideal for understanding nuanced differences in prompt effectiveness.\n",
      "\n",
      "You should adopt an innovative approach to prompt evaluation by utilizing Monte Carlo matchmaking and  ELO rating systems, or any alternative method to match and rank.\n",
      "Task 5: User Interface Development\n",
      "Develop a user-friendly interface for interacting with the prompt engineering system.\n",
      "UI Design: Plan and design a user interface that allows users to easily input data, receive prompts, and view evaluation results.\n",
      "UI Implementation: Develop and integrate the user interface with the backend prompt engineering system.\n",
      "Task 6: System Integration and Testing\n",
      "Integrate all components of the system and conduct comprehensive testing.\n",
      "Integrate the prompt generation, Evaluation Data Generation, evaluation, and user interface components.\n",
      "Test the entire system for functionality, usability, and performance. Refine based on feedback and test results.\n",
      "\n",
      "\n",
      "Tutorials Schedule\n",
      "In the following, the colour purple indicates morning sessions, and blue indicates afternoon sessions.\n",
      "Monday: Understanding Prompt engineering \n",
      "Here the trainees will understand the week’s challenge.\n",
      "Introduction to Week Challenge (Yabebal)\n",
      "Introduction and challenges to prompt engineering (Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding week’s challenge\n",
      "Understanding the prompt engineering\n",
      "Ability to reuse previous knowledge\n",
      "Tuesday\n",
      "RAG components (Rehmet)\n",
      "Techniques to improve R (Retrievers) in RAG (Emtinan)\n",
      "\n",
      "Key Performance Indicators:\n",
      "\n",
      "Understanding Prompt ranking \n",
      "Understanding prompt matching \n",
      "Ability to reuse previous knowledge\n",
      "\n",
      "Wednesday\n",
      "RAG Evaluation Data Generation (Rehmet)\n",
      "Understanding of prompt matching and ranking (Emtinan)\n",
      "Thursday\n",
      "RAG evaluation metrics (Emtinan)\n",
      "RAGOps - DevOps of RAG development and production deployment (Rehmet) \n",
      "\n",
      "\n",
      "Deliverables\n",
      "NOTE: Document should be a PDF stored in google drive or published blog link. DO NOT SUBMIT A LINK as PDF! If you want to submit pdf document, it should be the content of your report not a link. \n",
      "Interim Submission - Wednesday 8pm UTC\n",
      "Link to your code in GitHub\n",
      "Repository where you will be using to complete the tasks in this week's challenge. A minimum requirement is that you have a well structured repository and some coding progress is made.\n",
      "\n",
      "\n",
      "A review report of your reading and understanding of Task 1 and any progress you made in other tasks. \n",
      "Feedback\n",
      "You may not receive detailed comments on your interim submission but will receive a grade.\n",
      "Final Submission - Saturday 8pm UTC\n",
      "Link to your code in GitHub \n",
      "Complete work  for Automatic prompt generation\n",
      "Complete work  for Automatic evaluation \n",
      "Complete work for Evaluation Data Generation\n",
      "\n",
      "A blog post entry (which you can submit for example to Medium publishing) or a pdf report.\n",
      "Feedback\n",
      "You will receive comments/feedback in addition to a grade.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "References\n",
      "Meistrari didn’t see a good solution for prompt engineering, so it’s building one\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts\n",
      "Large Language Models Are Human-Level Prompt Engineers\n",
      "Prompt Engineering\n",
      "How to Create a Monte Carlo Simulation using Python\n",
      "Monte Carlo Method Explained\n",
      "What is Monte Carlo Simulation? How does it work?\n",
      "Elo Rating Algorithm\n",
      "Elo algorithm implementation in Python\n",
      "TrueSkillTM: A Bayesian skill rating system\n",
      "\n",
      "Companies doing something similar to this project\n",
      "AI Prompt Generator (promptlygenerated.com)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in extracted_documents:\n",
    "    print(f\"File: {document['file_name']}\")\n",
    "    print(f\"Extracted Text:\\n{document['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents extracted: 28\n"
     ]
    }
   ],
   "source": [
    "docx_folder = \"/home/moraa/Documents/10_academy/Week-7/data\"\n",
    "extracted_documents = extract_text_from_docx(docx_folder)\n",
    "\n",
    "num_extracted_documents = len(extracted_documents)\n",
    "print(f\"Number of documents extracted: {num_extracted_documents}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
